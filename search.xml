<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ElasticSearch学习及原理浅析</title>
    <url>/2021/05/27/database/ElasticSearch%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%8E%9F%E7%90%86%E6%B5%85%E6%9E%90/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>这篇文章我们一起来学习一下最最流行的搜索引擎 - <code>ElasticSearch</code><br>我们将学习到：</p>
<ul>
<li>ES集群、节点类型、分片</li>
<li>服务发现机制</li>
<li>选举机制</li>
<li>Docker搭建集群环境</li>
<li>基础API操作</li>
<li>ES的数据结构及文件系统</li>
<li>存储文档的过程</li>
<li>索引及搜索</li>
</ul>
<span id="more"></span>

<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16448952278198.jpg"><br>重点特性有以下几条：</p>
<ul>
<li>存储、管理数据（文档）</li>
<li>快速搜索数据</li>
<li>对于多种数据格式的高效索引</li>
<li>分布式支持高扩展性</li>
<li>弹性伸缩支持高可用性</li>
<li>TA的好搭档-Kibana</li>
</ul>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="集群概述"><a href="#集群概述" class="headerlink" title="集群概述"></a>集群概述</h3><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16448956295920.jpg"></p>
<p>单节点服务往往能干的很少，而且容错很低，特别是在大量数据的情况之下，所以为了提高服务的整体的高可用、高扩展性，一个服务往往都是一个集群。</p>
<p>而在ES的集群中，由若干个不同角色的节点组成（ES进程），一个集群有且只有一个master节点。</p>
<p>ES中的数据是由索引（Index）管理的，每一个索引相当于数据库中的表。</p>
<p>索引通过分片的方式，把数据横向分为若干分片，放在不同的节点上，进行分布式的存储。类似于数据库的分表操作。</p>
<p>分片可以设置副本，防止在宕机下的数据丢失。</p>
<h3 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h3><ul>
<li>master # 主节点</li>
<li>data # 通用数据节点</li>
<li>data_content # 数据目录节点，数据不常变化</li>
<li>data_hot # 热点数据节点，数据的生命周期</li>
<li>data_warm # 中温数据节点</li>
<li>data_cold # 冷数据节点</li>
<li>data_frozen # 封存数据节点</li>
<li>ingest # 数据摄入节点， 只用于执行预处理管道</li>
<li>ml # 机器学习节点</li>
<li>remote_cluster_client # 远程集群节点</li>
<li>transform # 转换节点<ul>
<li>转换节点会进行一种特殊操作，通过特定聚集语句计算，然后将结果写到新的索引中。如果需要使用远成集群数据，请务必在转换节点中添加remote_cluster_client；转换节点设置方法</li>
</ul>
</li>
</ul>
<h4 id="Tips："><a href="#Tips：" class="headerlink" title="Tips："></a>Tips：</h4><ol>
<li>一个集群的简单配置，需要确保有<code>mater</code>节点和<code>data</code>节点。</li>
<li>如果生产环境，且有机器学习（machine learning）任务或转换（transform）任务（<strong>CPU密集型</strong>），建议将候选的主节点（Master-eligible node）与数据节点（<code>data node</code>）、机器学习节点（<code>machine learning node</code>）和转换节点（<code>transforming node</code>）分开是很有必要的。</li>
<li>每个节点都默认为协调节点（Coordinating node），如果<code>node.roles</code>设置为<code>[]</code>那么该节点将只执行协调节点功能。</li>
</ol>
<h3 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h3><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16448967886435.jpg"></p>
<blockquote>
<p>数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。</p>
</blockquote>
<ul>
<li>提升总体数据的存储量（通过分布式）</li>
<li>提升数据可用性（通过副本）</li>
<li>数据管理的复杂度会提升</li>
</ul>
<h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449078323130.jpg"></p>
<p>假如有三个节点，那么他们应该达成共识，并全部都知道这个集群是个什么样子的。 图中是个反例。</p>
<h4 id="7-x之前之后的实现不同"><a href="#7-x之前之后的实现不同" class="headerlink" title="7.x之前之后的实现不同"></a>7.x之前之后的实现不同</h4><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449067746885.jpg"><br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449077934455.jpg"><br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449069256031.jpg"></p>
<ul>
<li>类gossip算法</li>
<li>与种子节点互相交换信息</li>
<li>达到最终的共识</li>
</ul>
<h3 id="选举选主"><a href="#选举选主" class="headerlink" title="选举选主"></a>选举选主</h3><h4 id="选举-Bully（7-x之前）"><a href="#选举-Bully（7-x之前）" class="headerlink" title="选举-Bully（7.x之前）"></a>选举-Bully（7.x之前）</h4><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449089276566.jpg"></p>
<ol>
<li>节点1向节点，节点3发送选举，并且带上自己的序号1</li>
<li>节点2，3接收到消息之后，进行序号比较，发觉自己的序号更大，向节点1返回应答消息Answer (Alive) Message，告知节点1被踢出选主序列</li>
<li>节点2向节点3发送选举请求，节点3找不到更高序号的节点发送选举请求了</li>
<li>节点3向节点2返回应答消息，节点3收不到其他节点的应答消息了</li>
<li>节点3被认为是leader，向其他节点发送Coordinator Message，选举成功的请求，将自己是master节点广播到节点1，节点2</li>
</ol>
<h4 id="选举-类Raft（7-x之后）"><a href="#选举-类Raft（7-x之后）" class="headerlink" title="选举-类Raft（7.x之后）"></a>选举-类Raft（7.x之后）</h4><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449090661855.jpg"><br>举例来说，如果node1，node2，node3进行选主</p>
<ul>
<li>如果node1当选leader，</li>
<li>但是node2发来了投票要求，那么node1无条件退出leader状态，node2选为主节点</li>
<li>但是node3也发来了投票要求，那么node2退出leader状态，node3当选主节点。<br>保证最后当选的leader为主leader</li>
</ul>
<p>相比于Raft算法，Es的选主算法有如下不同</p>
<ol>
<li>初始为 Candidate状态</li>
<li>允许多次投票，也就是每个有投票资格的节点可以投多票</li>
<li>候选人可以有投票的机会</li>
<li>可能会产生多个主节点</li>
</ol>
<h2 id="本地docker搭环境"><a href="#本地docker搭环境" class="headerlink" title="本地docker搭环境"></a>本地docker搭环境</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2.2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">cerebro:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">lmenezes/cerebro:0.9.4</span> </span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">cerebro</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;9000:9000&quot;</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">-Dhosts.0.host=http://es01:9200</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">kibana:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/kibana/kibana:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">kibana</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">ELASTICSEARCH_URL:</span> <span class="string">http://es01:9200</span></span><br><span class="line">      <span class="attr">ELASTICSEARCH_HOSTS:</span> <span class="string">http://es01:9200</span></span><br><span class="line">      <span class="attr">LOGGING_VERBOSE:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;5601:5601&quot;</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">es01:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">es01</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node.name=es01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.name=es-docker-cluster</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">discovery.seed_hosts=es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.initial_master_nodes=es01,es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;ES_JAVA_OPTS=-Xms128m -Xmx128m&quot;</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/chengpeng/docker_volume/elasticsearch/data01:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">9200</span><span class="string">:9200</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">es02:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">es02</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node.name=es02</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.name=es-docker-cluster</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">discovery.seed_hosts=es01,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.initial_master_nodes=es01,es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;ES_JAVA_OPTS=-Xms128m -Xmx128m&quot;</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/chengpeng/docker_volume/elasticsearch/data02:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">es03:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">es03</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node.name=es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.name=es-docker-cluster</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">discovery.seed_hosts=es01,es02</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.initial_master_nodes=es01,es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;ES_JAVA_OPTS=-Xms128m -Xmx128m&quot;</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/chengpeng/docker_volume/elasticsearch/data03:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">data01:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">data02:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">data03:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">elastic:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure>

<p><code>docker-compose up</code></p>
<ul>
<li>es: <a href="http://localhost:9200/">http://localhost:9200/</a></li>
<li>kinaba: <a href="http://localhost:5601/">http://localhost:5601/</a></li>
<li>cerebro: <a href="http://localhost:9000/">http://localhost:9000/</a></li>
</ul>
<h2 id="API操作"><a href="#API操作" class="headerlink" title="API操作"></a>API操作</h2><ul>
<li><p>创建索引</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUT books</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 4,</span><br><span class="line">        &quot;number_of_replicas&quot; : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">            &quot;properties&quot; : &#123;</span><br><span class="line">                &quot;name&quot; : &#123; &quot;type&quot; : &quot;text&quot; &#125;,</span><br><span class="line">                &quot;price&quot; : &#123;&quot;type&quot; : &quot;double&quot;&#125;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>新增数据</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUT books/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot; Effective Java&quot;,</span><br><span class="line">    &quot;price&quot; : 52.00,</span><br><span class="line">    &quot;message&quot; : &quot;本书介绍了在Java编程中78条极具实用价值的经验规则&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT books/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot;Effective C&quot;,</span><br><span class="line">    &quot;price&quot; : 58.5,</span><br><span class="line">    &quot;message&quot; : &quot;An Introduction to Professional C Programming&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PUT books/_doc/3</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot; : &quot;Thinking in Java&quot;,</span><br><span class="line">    &quot;price&quot; : 66.5,</span><br><span class="line">    &quot;message&quot; : &quot;Thinking in Java should be read cover to cover by every Java programmer, then kept close at hand for frequent reference. &quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询数据</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET books/_search</span><br></pre></td></tr></table></figure></li>
<li><p>搜索</p>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /books/_search?q=name:java</span><br><span class="line"></span><br><span class="line">GET /books/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;message&quot;: &quot;java&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="ES的数据结构及文件系统"><a href="#ES的数据结构及文件系统" class="headerlink" title="ES的数据结构及文件系统"></a>ES的数据结构及文件系统</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449122545087.jpg"></p>
<table>
<thead>
<tr>
<th>名称</th>
<th>文件</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/index/SegmentInfos.html">Segments File</a></td>
<td>segments_N</td>
<td>存储关于提交点的信息commit point</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50SegmentInfoFormat.html">Segment Info</a></td>
<td>.si</td>
<td>segment的元信息</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50CompoundFormat.html">Compound File</a></td>
<td>.cfs, .cfe</td>
<td>一些“虚拟”信息，少量的数据会存在这</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50FieldInfosFormat.html">Fields</a></td>
<td>.fnm</td>
<td>字段的信息</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50StoredFieldsFormat.html">Field Index</a></td>
<td>.fdx</td>
<td>字段索引的信息</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50StoredFieldsFormat.html">Field Data</a></td>
<td>.fdt</td>
<td>存储文档字段数据</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50PostingsFormat.html">Term Dictionary</a></td>
<td>.tim</td>
<td>术语词典</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50PostingsFormat.html">Term Index</a></td>
<td>.tip</td>
<td>术语索引</td>
</tr>
<tr>
<td><a href="https://lucene.apache.org/core/5_1_0/core/org/apache/lucene/codecs/lucene50/Lucene50LiveDocsFormat.html">Live Documents</a></td>
<td>.liv</td>
<td>文档存活的信息</td>
</tr>
</tbody></table>
<h2 id="存储文档的过程"><a href="#存储文档的过程" class="headerlink" title="存储文档的过程"></a>存储文档的过程</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449123445377.jpg"></p>
<ol>
<li>master节点接收请求</li>
<li>通过对_id的hash（或者路由）来盘点存储到哪一个分片</li>
<li>对应的分片本地存储数据</li>
<li>再同步给副本分片</li>
</ol>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449134143491.jpg"></p>
<ol>
<li>写入请求会将索引（Index）存放到内存区域，叫做 Index Buffer。此时的索引文件暂时是不能被ES搜索到的。</li>
<li>默认情况下 ES 每秒执行一次 Refresh 操作，将 Index Buffer 中的 index 写入到 Filesystem 中，这个也是一片内存区域。</li>
<li>ES 每次 refresh 都会生成一个 Segment，定期对 Segment 进行合并（Merge）操作，也就是将多个小 Segment 合并成一个 Segment</li>
<li>在合并完成后，会将新的 Segment 文件 Flush 写入磁盘。此时 ES 会创建一个 Commit Point 文件，该文件用来标识被 Flush 到磁盘上的 Segment。旧的 Segment 以及合并之前的小 Segment  会被从中移除</li>
</ol>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449134603831.jpg"></p>
<ol>
<li>在 ES 处理用户请求时追加 Translog，追加的内容就是对ES的请求操作。此时会根据配置同步或者异步的方式将操作记录追加信息保存到磁盘中</li>
</ol>
<h2 id="搜索（重点）"><a href="#搜索（重点）" class="headerlink" title="搜索（重点）"></a>搜索（重点）</h2><h3 id="常见索引结构"><a href="#常见索引结构" class="headerlink" title="常见索引结构"></a>常见索引结构</h3><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449758531230.png"></p>
<h3 id="倒排索引结构"><a href="#倒排索引结构" class="headerlink" title="倒排索引结构"></a>倒排索引结构</h3><h4 id="比如我们现在有一个这样的表"><a href="#比如我们现在有一个这样的表" class="headerlink" title="比如我们现在有一个这样的表"></a>比如我们现在有一个这样的表</h4><table>
<thead>
<tr>
<th>id</th>
<th>Text</th>
<th>其他字段。。。</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>Alan Alice</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Alan</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Alan</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Alan Brad</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Alice</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Alan</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Alan</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Alan Alice</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Brad</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>Brad</td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="我们现在需要查询包含Alan的所有数据"><a href="#我们现在需要查询包含Alan的所有数据" class="headerlink" title="我们现在需要查询包含Alan的所有数据"></a>我们现在需要查询包含<code>Alan</code>的所有数据</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> text <span class="keyword">like</span> <span class="string">&#x27;%Alan%&#x27;</span></span><br></pre></td></tr></table></figure>
<p>在Mysql中，这样的查询需要全表扫描，速度慢</p>
<h4 id="而在ES中"><a href="#而在ES中" class="headerlink" title="而在ES中"></a>而在ES中</h4><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449760553786.png"></p>
<ul>
<li>通过分词，将这些关键词（<code>Term</code>）提前提取出来</li>
<li>这些关键词的集合就叫做<code>Term Dictionary</code></li>
<li>每一个关键词，都有一个对应文档的列表<code>Posting List</code></li>
<li>通过FST算法，构建一个Term的索引<code>Term dict index</code></li>
</ul>
<ol>
<li>Terms Dictionary 存储 Term 的索引文件叫做 Terms Index，存储的格式是 .tip</li>
<li>Terms Dictionary 的文件存储格式为 .tim，存储了Term和对应的Postings List指针。</li>
<li>Postings List 被拆成三个文件存储：</li>
<li>.doc后缀文件：记录 Postings 的 docId 信息和 Term 的词频</li>
<li>.pay后缀文件：记录 Payload 信息和偏移量信息</li>
<li>.pos后缀文件：记录位置信息</li>
</ol>
<h4 id="通过ID查找之SkipList"><a href="#通过ID查找之SkipList" class="headerlink" title="通过ID查找之SkipList"></a>通过ID查找之SkipList</h4><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449777126594.png"></p>
<ul>
<li>如果我们要查询id&#x3D;12的文档</li>
<li>正常链表通过遍历，一个一个查询，时间复杂度是 O(n)</li>
<li>跳跃表是通过跳跃分层， 时间复杂度可以达到 O(log n)<ul>
<li>第一层， 0～15</li>
<li>第二层， 8～15</li>
<li>第三层， 12</li>
</ul>
</li>
</ul>
<h3 id="搜索数据-BKDTree"><a href="#搜索数据-BKDTree" class="headerlink" title="搜索数据-BKDTree"></a>搜索数据-BKDTree</h3><p>对于索引一些多维数据，比如 坐标，使用的是BKD-Tree来索引<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449785200616.jpg"></p>
<ul>
<li>如图上的点，我们是怎么给他们做2D平面划分的。</li>
<li>我们需要一个鉴别器<code>discriminator</code></li>
<li>简单的鉴别器就是对层级取模<ul>
<li><code>discriminator = level % N</code></li>
</ul>
</li>
<li>会得到下面的树形结构<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16449787811410.jpg"></li>
<li>多维的就是 x y z 一次类推</li>
<li>构建BKD树，就可以更好的根据多维数据来查询对应的文档了</li>
</ul>
<h2 id="ES的优化"><a href="#ES的优化" class="headerlink" title="ES的优化"></a>ES的优化</h2><h2 id="ES相关问题"><a href="#ES相关问题" class="headerlink" title="ES相关问题"></a>ES相关问题</h2><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index.html">官方文档（7.x)</a></li>
<li><a href="https://github.com/elastic/elasticsearch">Github</a></li>
<li><a href="https://zh.wikipedia.org/wiki/Elasticsearch">维基百科</a></li>
<li><a href="https://alibaba-cloud.medium.com/elasticsearch-distributed-consistency-principles-analysis-1-node-b512e2b839f8">Elasticsearch Distributed Consistency Principles Analysis (1) — Node</a></li>
<li><a href="https://juejin.cn/post/7038828692671299620">ES集群中各节点角色功能简介</a></li>
<li><a href="https://mincong.io/2020/08/22/discovery-in-elasticsearch/">Discovery in Elasticsearch</a></li>
<li><a href="https://yemilice.com/2021/06/16/elasticsearch-%E6%96%B0%E8%80%81%E9%80%89%E4%B8%BB%E7%AE%97%E6%B3%95%E5%AF%B9%E6%AF%94/">ElasticSearch-新老选主算法对比</a></li>
<li><a href="https://blog.csdn.net/weixin_43902449/article/details/112449240">Elasticsearch数据结构存储流程</a></li>
<li><a href="https://elasticsearch.cn/question/5173">elasticsearch 每个shard对应的文件含义</a></li>
<li><a href="https://www.elastic.co/cn/blog/found-dive-into-elasticsearch-storage#lucene-index-files">A Dive into the Elasticsearch Storage</a></li>
<li><a href="https://mp.weixin.qq.com/s/wms9j22YcHfb8V9CBR65zQ">Elasticsearch写入原理，一看便知！</a></li>
<li><a href="https://yemilice.com/2021/05/14/elasticsearch%E6%A3%80%E7%B4%A2%E7%9A%84%E6%A0%B8%E5%BF%83-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E8%A7%A3%E8%AF%BB/">ElasticSearch检索的核心-倒排索引解读</a></li>
<li><a href="https://yemilice.com/2021/09/09/%E8%AE%BE%E8%AE%A1%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84elasicsaerch%E7%B4%A2%E5%BC%95/">设计高可用的ElasicSearch索引</a></li>
<li><a href="https://medium.com/swlh/bkd-trees-used-in-elasticsearch-40e8afd2a1a4">BKD 树，用于 Elasticsearch</a></li>
</ul>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL事务原理</title>
    <url>/2021/08/25/database/MySQL%E4%BA%8B%E7%89%A9%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>什么是事务？！</p>
<p>一句话来说，事务是一次操作的<code>逻辑单位</code>。要不全部成功，要不全部失败。</p>
<p>它主要是用来保证<code>数据一致性</code>的问题。</p>
<span id="more"></span>

<p>比如去银行转账的操作，原来账户的扣款，和目标账户的加款。<br>这两个操作要放在一个事务里面，要不一起成功，要不一起失败。</p>
<p>如果在事务中间，发生问题，需要把已经执行了的操作<code>回滚</code>，以保证数据准确。</p>
<h2 id="事务的常见命令"><a href="#事务的常见命令" class="headerlink" title="事务的常见命令"></a>事务的常见命令</h2><ul>
<li>START TRANSACTION：开始一个事务</li>
<li>COMMIT：事务顺利完成时，提交事务</li>
<li>ROLLBACK：事务发生了异常，回滚</li>
</ul>
<p>比如我们有一张customer表，执行一下语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;zhangsan&#x27;</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;lisi&#x27;</span>;</span><br><span class="line"><span class="keyword">commit</span> ;</span><br></pre></td></tr></table></figure>

<p>再查询表，会得到：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/Prom8Z.png"><br>表示一个事务完成、提交。</p>
<p>我们再执行下面操作：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;wangwu&#x27;</span>;</span><br><span class="line"><span class="keyword">rollback</span> ;</span><br></pre></td></tr></table></figure>

<p>再查询customer表，会发现wangwu并没有被添加到表中，表中还只有两条记录。</p>
<ul>
<li>建立保存点：SAVEPOINT 保存点名称</li>
<li>删除保存点：RELEASE SAVEPOINT 保存点名称</li>
<li>回滚到特定保存点：ROLLBACK TO SAVEPOINT 保存点名称</li>
</ul>
<p>我们接着再执行下面点语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;zhao liu&#x27;</span>;</span><br><span class="line"><span class="keyword">savepoint</span> my_point;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;qian qi&#x27;</span>;</span><br><span class="line"><span class="keyword">rollback</span> <span class="keyword">to</span> <span class="keyword">savepoint</span> my_point;</span><br></pre></td></tr></table></figure>

<p>我们查询到到结果是：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/gIvWTx.png"><br><code>zhao liu</code> 成功入库了，而 <code>qian qi</code> 被回滚掉了。</p>
<p><code>savepoint</code> 保存点，可以让我们实现部分回滚。</p>
<h2 id="Transaction-四大特性：-ACID"><a href="#Transaction-四大特性：-ACID" class="headerlink" title="Transaction 四大特性： ACID"></a>Transaction 四大特性： ACID</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/NfuAJQ.png"></p>
<p>一个事务有下列四个重要到特性，简称ACID</p>
<ul>
<li>A：Atomicity 原子性。 事务里面到操作，不可分割，要不一起成功，要不一起失败。</li>
<li>C：Consistency 一致性。在事务的前后，系统的整体数据保持一致。比如说银行转账。</li>
<li>I：Isolation 隔离性。 事务之间，相互隔离，互不干扰。</li>
<li>D：Durability 永久性。 一旦数据修改完成，永久有效。</li>
</ul>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/9qUodw.png"><br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/xJ1VeA.png"><br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/jez6I1.png"><br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/vXbP4p.png"></p>
<h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><p>介绍完了ACID，我们再来重点说说ACID其中的I(Isolation)。</p>
<p>我们都知道，事务之间是隔离的<br>但是如何处理多个事务之间操作和读取同一个数据的结果，<br>我们需要仔细考虑。</p>
<p>事务隔离级别是在多个事务同时进行更改和执行查询时，<br>调整<code>性能</code>和结果的<code>可靠性</code>、<code>一致性</code>和<code>可再现性</code>之间的平衡的设置。</p>
<p>MySQL（InnoDB）提供四种事务隔离级别：</p>
<ul>
<li>read uncommitted 读未提交</li>
<li>read committed   读已提交</li>
<li>repeatable read  可重复读（MySQL默认隔离级别）</li>
<li>serializable     串行</li>
</ul>
<p>我们可以参考<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html">官方文档</a></p>
<h3 id="事务隔离级别的设置"><a href="#事务隔离级别的设置" class="headerlink" title="事务隔离级别的设置"></a>事务隔离级别的设置</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 设置全局的事务隔离级别</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> TRANSACTION LEVEL [REPEATABLE READ <span class="operator">|</span> READ COMMITTED <span class="operator">|</span> READ UNCOMMITTED <span class="operator">|</span> SERIALIZABLE];</span><br><span class="line"># 设置当前Session的隔离级别</span><br><span class="line"><span class="keyword">SET</span> SESSION TRANSACTION ISOLATION LEVEL [REPEATABLE READ <span class="operator">|</span> READ COMMITTED <span class="operator">|</span> READ UNCOMMITTED <span class="operator">|</span> SERIALIZABLE];</span><br><span class="line"># 查看当前事务隔离级别</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@transaction</span>_ISOLATION;</span><br></pre></td></tr></table></figure>

<p>我们先做一下前置的准备，<br>开启两个Session，<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/Lf8Nzf.png"></p>
<p>并查看一下当前的事务隔离级别<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/3zaxpJ.png"></p>
<p>接下来，我们一个一个看：</p>
<h3 id="未提交读（READ-UNCOMMITTED）"><a href="#未提交读（READ-UNCOMMITTED）" class="headerlink" title="未提交读（READ UNCOMMITTED）"></a>未提交读（READ UNCOMMITTED）</h3><p>未提交读，指的就是一个事务读到了另外一个事务未提交的数据。</p>
<p>这样会导致脏读。</p>
<p>我们来实验一下：</p>
<p>我们先设置两个Session的隔离级别：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;</span><br></pre></td></tr></table></figure>

<p>查看下：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/WNJBVz.png"></p>
<p>我们现在数据库当中有两条数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer;</span><br></pre></td></tr></table></figure>

<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/trxTdG.png"></p>
<p>我们在Session A中开启一个事务，并修改一条记录，但是不提交。</p>
<p>再在Session B 中查询，看会得到怎样的结果。</p>
<p>我们现在Session A 中执行以下操作：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session A</span><br><span class="line"># <span class="number">1</span>、开启事务</span><br><span class="line"><span class="keyword">start</span> transaction ;</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、修改数据</span><br><span class="line"><span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;zhangsan2&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>我们在Session B 中看下结果：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session B</span><br><span class="line"># <span class="number">3</span>、查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>此时Session A中的事务还没有提交，也就是说有回滚的可能。<br>但在Session B中查看数据， 客户名称已经从 <code>zhangsan</code> 变成了 <code>zhangsan2</code>。</p>
<p>如果Session A再进行了回滚，rollback。 这样Session B就读出了一个不存在的数据，就是脏读。</p>
<p>这是非常不安全的一种隔离级别。</p>
<h3 id="已提交读（READ-COMMITTED）"><a href="#已提交读（READ-COMMITTED）" class="headerlink" title="已提交读（READ COMMITTED）"></a>已提交读（READ COMMITTED）</h3><p>已提交读，就是读到的数据都是另外的事务已经提交过了的数据。<br>可以解决脏读的问题。</p>
<p>我们先修改下事务隔离级别：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@transaction</span>_ISOLATION;</span><br></pre></td></tr></table></figure>

<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/5fAmh8.png"></p>
<p>我们在SessionA中修改数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session A</span><br><span class="line"># <span class="number">1</span>、开启事务</span><br><span class="line"><span class="keyword">start</span> transaction ;</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、修改数据</span><br><span class="line"><span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;张飞&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>在Session B 中查看数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session B</span><br><span class="line"># <span class="number">3</span>、查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/YMiybO.png"><br>我们可以看到，客户名称还是<code>zhangsan</code>，没有变成<code>张飞</code>。</p>
<p>我们这个时候再把Session A中的事务提交</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session A</span><br><span class="line"># <span class="number">1</span>、开启事务</span><br><span class="line"># <span class="keyword">start</span> transaction ;</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、修改数据</span><br><span class="line"># <span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;张飞&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、提交事务</span><br><span class="line"><span class="keyword">commit</span> ;</span><br></pre></td></tr></table></figure>

<p>再次在Session B 中查看数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session B</span><br><span class="line"># <span class="number">3</span>、查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、再次查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/wY9JUG.png"><br>我们可以看到，客户名称已经变成了 <code>张飞</code>。</p>
<p>如果session A的事务回滚的话，我们在Session B中看到的结果还会是 <code>zhangsan</code><br>这样，我们就成功解决了脏读的问题了。</p>
<p>但是如果我们在同一个事务中，读取数据，可能会查询到不同的结果。<br>我们按照数字的顺序，执行以下SQL：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session B</span><br><span class="line"></span><br><span class="line"># <span class="number">1</span>、开启事务，并查看数据</span><br><span class="line"><span class="keyword">start</span> transaction ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 张飞</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、再次查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 关羽</span></span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、再次查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 刘备</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session A</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、修改数据（自动提交事务）</span><br><span class="line"><span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;关羽&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、修改数据（自动提交事务）</span><br><span class="line"><span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;刘备&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>我们可以看到，Session B 在同一个事务中，同样的查询语句，得出的结果是不一样的。<br>这种现象我们称之为<code>不可重复读</code>。</p>
<h3 id="可重复读（REPEATABLE-READ）"><a href="#可重复读（REPEATABLE-READ）" class="headerlink" title="可重复读（REPEATABLE READ）"></a>可重复读（REPEATABLE READ）</h3><p>有些场景，我们需要在一个事务中，查询到到数据保持一致，不管外部事务如何改变。</p>
<p>这个时候，就需要我们满足<code>可重复读</code>。</p>
<p>我们直接看效果：</p>
<p>首先修改事务隔离级别：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@transaction</span>_ISOLATION;</span><br></pre></td></tr></table></figure>

<p>再按照下列SQL的顺序，执行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session B</span><br><span class="line"></span><br><span class="line"># <span class="number">1</span>、开启事务，并查看数据</span><br><span class="line"><span class="keyword">start</span> transaction ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 刘备</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、再次查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 刘备</span></span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、再次查看数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 刘备</span></span><br><span class="line"></span><br><span class="line"># <span class="number">6</span>、提交当前事务，在查看数据</span><br><span class="line"><span class="keyword">commit</span> ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="comment">-- 张飞</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session A</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、修改数据（自动提交事务）</span><br><span class="line"><span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;关羽&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、修改数据（自动提交事务）</span><br><span class="line"><span class="keyword">update</span> customer <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;张飞&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>我们可以看到，在Session B 中，每一次查询的结果都是一样的，<br>不管实际的数据怎样的变化，即使数据已经被SessionA所改变，且已提交。</p>
<p>但是这种隔离级别同样有这自己缺陷，它会发生幻读。</p>
<p>我们看下面的场景：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="number">1</span>、开启事务，并查看数据</span><br><span class="line"># session B</span><br><span class="line"></span><br><span class="line"># <span class="number">1</span>、开启事务，并查看数据</span><br><span class="line"><span class="keyword">start</span> transaction ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">10</span>; <span class="comment">-- null</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、插入指定ID的数据</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">10</span>; <span class="comment">-- null</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">values</span> (<span class="number">10</span>, <span class="string">&#x27;吕布&#x27;</span>); <span class="comment">-- 失败</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">commit</span> ;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># session A</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、插入数据</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> customer <span class="keyword">values</span> (<span class="number">10</span>, <span class="string">&#x27;小吕布&#x27;</span>); <span class="comment">-- 成功</span></span><br></pre></td></tr></table></figure>

<p>我们可以看到，SessionB在一个事务中，想要插入一条ID为10的用户。<br>重要的是，要第一步查询，已经确定了ID为10的用户并不存在。</p>
<p>但是在事务的过程中，Session A 插入了一条ID为10的客户，并成功提交事务。</p>
<p>等再回到Session B， 再想插入一条ID为10的客户，就报错了<code>Duplicate entry &#39;10&#39; for key &#39;customer.PRIMARY&#39;</code>。</p>
<p>其实，在Session B的操作中，逻辑都是没问题的。但是还是发生了幻读，导致了系统异常。</p>
<p>解决办法是，在Session B中，我们这样写select语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">10</span> <span class="keyword">for</span> <span class="keyword">update</span> ;</span><br></pre></td></tr></table></figure>

<p>在 select 语句后面， 添加一个<code>for update</code>，可以把<code>ID=10</code>给加上一个锁，<br>SessionA， 再想干扰，添加数据的时候，就会拿不到锁，而只能等待SessionB的事务完成，并释放锁。</p>
<p>所以保证了SessionB的原子性，杜绝的幻读。</p>
<h3 id="串行化（SERIALIZABLE）"><a href="#串行化（SERIALIZABLE）" class="headerlink" title="串行化（SERIALIZABLE）"></a>串行化（SERIALIZABLE）</h3><p>串行化，这种隔离级别，可以杜绝所有的干扰，包括（脏读、不可重复读、幻读）。</p>
<p>在此级别下，我们便不需要对 SELECT 操作显式加锁，InnoDB会自动加锁，事务安全，但性能很低。</p>
<p>非常不推荐使用。</p>
<h2 id="InnoDB的事务实现（MVCC）"><a href="#InnoDB的事务实现（MVCC）" class="headerlink" title="InnoDB的事务实现（MVCC）"></a>InnoDB的事务实现（MVCC）</h2><p>MVCC，多版本并发控制。<br>顾名思义，他会记录数据变更的版本（像git一样），形成一个版本链。</p>
<p>在通过对这个版本链中不同版本的处理，来实现事务，和事务隔离级别。</p>
<h3 id="版本链"><a href="#版本链" class="headerlink" title="版本链"></a>版本链</h3><p>在数据库行数据的结构中，除了我们存储的字段外，还有两个必不可少的隐藏字段：</p>
<p>当前事务ID(<code>trx_id)</code> 和 上个版本数据的引用(<code>roll_pointer</code>)。</p>
<p>直接上代码，我们用Java来模拟MVCC。</p>
<p>完整代码，请查看<a href="https://github.com/CPyeah/java-projets/tree/master/java-mvcc/src/main/java">这里</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Row</span>&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 当前操作的事务id</span></span><br><span class="line">	<span class="keyword">private</span> Integer trx_id;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 历史记录的地址</span></span><br><span class="line">	<span class="keyword">private</span> Row&lt;T&gt; roll_pointer;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 主键ID</span></span><br><span class="line">	<span class="keyword">private</span> Integer primaryId;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 其他数据</span></span><br><span class="line">	<span class="keyword">private</span> T otherData;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 行锁</span></span><br><span class="line">	<span class="keyword">private</span> ReentrantLock rowLock;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>我们可以通过roll_pointer来找到所有的历史版本，可以实现回滚操作，也可以选择指定的版本来展示。</p>
<p>我们再看一下事务操作的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.LinkedList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事务控制</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransactionController</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 当前活跃的事务列表</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> List&lt;Integer&gt; m_ids = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 全局事务ID</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">AtomicInteger</span> <span class="variable">globeTransactionID</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(<span class="number">100</span>);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 获取事务ID</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> Integer <span class="title function_">getNextTransactionId</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> globeTransactionID.getAndAdd(<span class="number">100</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新数据，加行锁</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; T <span class="title function_">update</span><span class="params">(Row&lt;T&gt; newRow, Transaction transaction,</span></span><br><span class="line"><span class="params">			HashMap&lt;Integer, Row&lt;T&gt;&gt; tableData)</span> &#123;</span><br><span class="line">		<span class="type">Integer</span> <span class="variable">primaryId</span> <span class="operator">=</span> newRow.getPrimaryId();</span><br><span class="line">		Row&lt;T&gt; oldRow = tableData.get(primaryId);</span><br><span class="line">		<span class="keyword">if</span> (oldRow == <span class="literal">null</span>) &#123;</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;Data does not exist&quot;</span>);</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			newRow.setTrx_id(transaction.getTransactionId());</span><br><span class="line">			newRow.setRoll_pointer(oldRow); <span class="comment">// 更新版本链</span></span><br><span class="line">			tableData.put(primaryId, newRow);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> newRow.getOtherData();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 开启一个事务</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> Transaction <span class="title function_">start</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">Integer</span> <span class="variable">transactionId</span> <span class="operator">=</span> getNextTransactionId();</span><br><span class="line"></span><br><span class="line">		<span class="type">Transaction</span> <span class="variable">transaction</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Transaction</span>();</span><br><span class="line">		transaction.setTransactionId(transactionId);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 把当前的事务ID，存放到活跃事务列表中</span></span><br><span class="line">		m_ids.add(transactionId);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> transaction;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 事务提交</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">commit</span><span class="params">(Transaction transaction)</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (transaction.getLock() != <span class="literal">null</span>) &#123;</span><br><span class="line">			transaction.getLock().unlock();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 在活跃事务列表中，移除事务ID</span></span><br><span class="line">		m_ids.remove(transaction.getTransactionId());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中几个关键点：</p>
<ul>
<li>全局事务ID ： 全局唯一，递增</li>
<li>当前活跃的事务列表： 这里维护所有的未提交的事务的ID，</li>
<li>开启一个事务： 生成一个事务ID，并把这个事务，维护到活跃事务列表中</li>
<li>更新数据： 新数据赋予事务ID，新数据可以引用到上个版本的老数据，加行锁</li>
<li>提交事务： 解锁，把活跃事务列表中的删除当前事务</li>
</ul>
<p>我们接下来看下事务是怎么运转的：</p>
<p>我们设计一个这样的测试：</p>
<p>完整代码请看<a href="https://github.com/CPyeah/java-projets/tree/master/java-mvcc/src/test/java">这里</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.BeforeAll;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransactionControllerTest</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@BeforeAll</span></span><br><span class="line">	<span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">		Row&lt;Customer&gt; row = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;刘备&quot;</span>);</span><br><span class="line"></span><br><span class="line">		Customer.tableData.put(row.getPrimaryId(), row);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test1</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 开启事务A</span></span><br><span class="line">		<span class="type">Transaction</span> <span class="variable">transaction_A</span> <span class="operator">=</span> TransactionController.start();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 开启事务B</span></span><br><span class="line">		<span class="type">Transaction</span> <span class="variable">transaction_B</span> <span class="operator">=</span> TransactionController.start();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">		Row&lt;Customer&gt; 关羽 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;关羽&quot;</span>);</span><br><span class="line">		TransactionController.update(关羽, transaction_A, Customer.tableData);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">		Row&lt;Customer&gt; 张飞 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;张飞&quot;</span>);</span><br><span class="line">		TransactionController.update(张飞, transaction_A, Customer.tableData);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 事务A提交，并释放锁</span></span><br><span class="line">		TransactionController.commit(transaction_A);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">		Row&lt;Customer&gt; 赵云 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;赵云&quot;</span>);</span><br><span class="line">		TransactionController.update(赵云, transaction_B, Customer.tableData);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">		Row&lt;Customer&gt; 诸葛亮 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;诸葛亮&quot;</span>);</span><br><span class="line">		TransactionController.update(诸葛亮, transaction_B, Customer.tableData);</span><br><span class="line"></span><br><span class="line">		<span class="comment">//commit</span></span><br><span class="line">		TransactionController.commit(transaction_B);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 打印undo日志链表</span></span><br><span class="line">		printData(Customer.tableData.get(<span class="number">1</span>));</span><br><span class="line">		<span class="comment">// 1-诸葛亮(200) -&gt; 1-赵云(200) -&gt; 1-张飞(100) -&gt; 1-关羽(100) -&gt; 1-刘备(null)</span></span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printData</span><span class="params">(Row&lt;Customer&gt; customerRow)</span> &#123;</span><br><span class="line">		<span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>(toString(customerRow));</span><br><span class="line"></span><br><span class="line">		Row&lt;Customer&gt; currentPointer = customerRow;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">while</span> (currentPointer.getRoll_pointer() != <span class="literal">null</span>) &#123;</span><br><span class="line">			currentPointer = currentPointer.getRoll_pointer();</span><br><span class="line">			sb.append(<span class="string">&quot; -&gt; &quot;</span>)</span><br><span class="line">					.append(toString(currentPointer));</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(sb);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> String <span class="title function_">toString</span><span class="params">(Row&lt;Customer&gt; customerRow)</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> customerRow.getPrimaryId() + <span class="string">&quot;-&quot;</span> + customerRow.getOtherData().getName()</span><br><span class="line">				+ <span class="string">&quot;(&quot;</span></span><br><span class="line">				+ customerRow.getTrx_id()</span><br><span class="line">				+ <span class="string">&quot;)&quot;</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Row&lt;Customer&gt; <span class="title function_">getCustomerRow</span><span class="params">(Integer id, String name)</span> &#123;</span><br><span class="line">		<span class="type">Customer</span> <span class="variable">customer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Customer</span>();</span><br><span class="line">		customer.setId(id);</span><br><span class="line">		customer.setName(name);</span><br><span class="line"></span><br><span class="line">		Row&lt;Customer&gt; row = <span class="keyword">new</span> <span class="title class_">Row</span>&lt;&gt;();</span><br><span class="line">		row.setPrimaryId(customer.getId());</span><br><span class="line">		row.setOtherData(customer);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> row;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中使用<code>Customer.tableData</code>来模拟存储数据。</p>
<p>在<code>test1</code>中，我们开启了两个事务，并执行了<code>update</code>操作，最总形成了一个版本链：</p>
<p>效果如图所示：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/O2WJFy.png"></p>
<blockquote>
<p>两个事务不能交叉修改同一个数据，因为在<code>Transaction_A</code>第一次执行<code>update</code>操作的时候，<br>就给这个数据加上了行锁，<code>Transaction_B</code>必须等到<code>Transaction_A</code>提交，释放了锁，<br>才可以进行<code>Transaction_B</code>的<code>update</code>操作。</p>
</blockquote>
<p>得到的数据<code>版本链</code>效果如下：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/cfz3Lp.png"></p>
<h3 id="隔离级别的实现"><a href="#隔离级别的实现" class="headerlink" title="隔离级别的实现"></a>隔离级别的实现</h3><p>我们知道有四大隔离级别，我们来看下它们是怎样实现的。</p>
<h4 id="SERIALIZABLE"><a href="#SERIALIZABLE" class="headerlink" title="SERIALIZABLE"></a>SERIALIZABLE</h4><p>串行化，这种级别下，不管是更新，还是查询，它都会加锁，<br>所以每次查询的数据，肯定是事务已经提交后的数据，<br>而每次更新数据的过程中，数据不会再发生变化。<br>不管是查询，还是更新数据的过程中，版本链都不会更新。</p>
<h4 id="READ-UNCOMMITTED"><a href="#READ-UNCOMMITTED" class="headerlink" title="READ UNCOMMITTED"></a>READ UNCOMMITTED</h4><p>读未提交，它的实现也很简单，每次查看数据的时候，都读取版本链中最新的数据，不管操作这个数据的事务有没有提交。</p>
<h4 id="READ-COMMITTED"><a href="#READ-COMMITTED" class="headerlink" title="READ COMMITTED"></a>READ COMMITTED</h4><p>读已提交，<br>他会在每次查询的时候，都会生成一个<code>ReadView</code>，<br>它会拿到版本链，会从版本链从上往下搜索，<br>找到已经提交了的，最新的一个版本的数据。</p>
<h4 id="REPEATABLE-READ"><a href="#REPEATABLE-READ" class="headerlink" title="REPEATABLE READ"></a>REPEATABLE READ</h4><p>可重复读<br>它会在当前的事务中，第一次查询的时候，生成一个<code>ReadView</code>，<br>也是从版本链中搜索，找到最新一个已经提交了的事务，<br>但是不同于读已提交的是，这个ReadView只生成一次，<br>以后的每次查询，都会查看这同一个ReadView。<br>从而保证<code>可重复读</code>。</p>
<h3 id="ReadView获取"><a href="#ReadView获取" class="headerlink" title="ReadView获取"></a>ReadView获取</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取到ReadView</span></span><br><span class="line"><span class="keyword">public</span> &lt;T&gt; Row&lt;T&gt; <span class="title function_">readView</span><span class="params">(Row&lt;T&gt; chain)</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> (chain == <span class="literal">null</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (m_ids.isEmpty()) &#123;</span><br><span class="line">		<span class="keyword">return</span> chain;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 该值代表生成readView时m_ids中的最小值</span></span><br><span class="line">	<span class="type">Integer</span> <span class="variable">min_trx_id</span> <span class="operator">=</span> m_ids.get(<span class="number">0</span>);</span><br><span class="line">	<span class="keyword">for</span> (Integer id : m_ids) &#123;</span><br><span class="line">		min_trx_id = Math.min(min_trx_id, id);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 该值代表生成readView时系统中应该分配给下一个事务的id值</span></span><br><span class="line">	<span class="type">Integer</span> <span class="variable">max_trx_id</span> <span class="operator">=</span> getNextTransactionId();</span><br><span class="line"></span><br><span class="line">	Row&lt;T&gt; pointer = chain;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">		<span class="keyword">if</span> (isThisReadView(pointer, min_trx_id, max_trx_id)) &#123;</span><br><span class="line">			<span class="keyword">return</span> pointer;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (pointer.getRoll_pointer() != <span class="literal">null</span>) &#123;</span><br><span class="line">			pointer = pointer.getRoll_pointer();</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断是否此版本为ReadView</span></span><br><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="type">boolean</span> <span class="title function_">isThisReadView</span><span class="params">(Row&lt;T&gt; pointer,</span></span><br><span class="line"><span class="params">		Integer min,</span></span><br><span class="line"><span class="params">		Integer max)</span> &#123;</span><br><span class="line">	<span class="comment">// 如果被访问版本的trx_id属性值小于m_ids列表中最小的事务id，</span></span><br><span class="line">	<span class="comment">// 表明生成该版本的事务在生成ReadView前已经提交，</span></span><br><span class="line">	<span class="comment">// 所以该版本可以被当前事务访问。</span></span><br><span class="line">	<span class="keyword">if</span> (pointer.getTrx_id() &lt; min) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 如果被访问版本的trx_id属性值大于m_ids列表中最大的事务id，</span></span><br><span class="line">	<span class="comment">// 表明生成该版本的事务在生成ReadView后才生成，</span></span><br><span class="line">	<span class="comment">// 所以该版本不可以被当前事务访问。</span></span><br><span class="line">	<span class="keyword">if</span> (pointer.getTrx_id() &gt; max) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 如果被访问版本的trx_id属性值在m_ids列表中最大的事务id和最小事务id之间，</span></span><br><span class="line">	<span class="comment">// 那就需要判断一下trx_id属性值是不是在m_ids列表中，</span></span><br><span class="line">	<span class="comment">// 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；</span></span><br><span class="line">	<span class="comment">// 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。</span></span><br><span class="line">	<span class="keyword">if</span> (m_ids.contains(pointer.getTrx_id())) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>我们在test1中，加上查看readView的效果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test1</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 开启事务A</span></span><br><span class="line">	<span class="type">Transaction</span> <span class="variable">transaction_A</span> <span class="operator">=</span> TransactionController.start();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 开启事务B</span></span><br><span class="line">	<span class="type">Transaction</span> <span class="variable">transaction_B</span> <span class="operator">=</span> TransactionController.start();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">	Row&lt;Customer&gt; 关羽 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;关羽&quot;</span>);</span><br><span class="line">	TransactionController.update(关羽, transaction_A, Customer.tableData);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 查看readView</span></span><br><span class="line">	Row&lt;Customer&gt; readView = TransactionController.readView(Customer.tableData.get(<span class="number">1</span>));</span><br><span class="line">	System.out.println(toString(readView));<span class="comment">// 1-刘备(0)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">	Row&lt;Customer&gt; 张飞 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;张飞&quot;</span>);</span><br><span class="line">	TransactionController.update(张飞, transaction_A, Customer.tableData);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 事务A提交，并释放锁</span></span><br><span class="line">	TransactionController.commit(transaction_A);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 查看readView</span></span><br><span class="line">	readView = TransactionController.readView(Customer.tableData.get(<span class="number">1</span>));</span><br><span class="line">	System.out.println(toString(readView));<span class="comment">// 1-张飞(100)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">	Row&lt;Customer&gt; 赵云 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;赵云&quot;</span>);</span><br><span class="line">	TransactionController.update(赵云, transaction_B, Customer.tableData);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 查看readView</span></span><br><span class="line">	readView = TransactionController.readView(Customer.tableData.get(<span class="number">1</span>));</span><br><span class="line">	System.out.println(toString(readView)); <span class="comment">//1-张飞(100)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新数据，同时会加上行锁</span></span><br><span class="line">	Row&lt;Customer&gt; 诸葛亮 = getCustomerRow(<span class="number">1</span>, <span class="string">&quot;诸葛亮&quot;</span>);</span><br><span class="line">	TransactionController.update(诸葛亮, transaction_B, Customer.tableData);</span><br><span class="line"></span><br><span class="line">	<span class="comment">//commit</span></span><br><span class="line">	TransactionController.commit(transaction_B);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 查看readView</span></span><br><span class="line">	readView = TransactionController.readView(Customer.tableData.get(<span class="number">1</span>));</span><br><span class="line">	System.out.println(toString(readView)); <span class="comment">// 1-诸葛亮(200)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 打印undo日志链表</span></span><br><span class="line">	printData(Customer.tableData.get(<span class="number">1</span>));</span><br><span class="line">	<span class="comment">// 1-诸葛亮(200) -&gt; 1-赵云(200) -&gt; 1-张飞(100) -&gt; 1-关羽(100) -&gt; 1-刘备(null)</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>完整代码请查看<a href="https://github.com/CPyeah/java-projets/blob/master/java-mvcc/src/test/java/TransactionControllerTest.java">这里</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，我们已经学习了MySQL事务到相关知识。</p>
<ul>
<li>我们了解到了事务到概念</li>
<li>学习了事务的常见用法</li>
<li>了解了事务的四大特性 ACID</li>
<li>并重点说了事务的隔离特定</li>
<li>实践了不同事务隔离级别下的效果</li>
<li>使用Java代码模拟了MVCC的实现</li>
<li>并通过MVCC，掌握事务隔离级别的实现原理</li>
</ul>
<p>本篇文章，希望大家好好掌握。😊</p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL学习及原理浅析</title>
    <url>/2021/08/13/database/MySQL%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%8E%9F%E7%90%86%E6%B5%85%E6%9E%90/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>从今天开始，我们将学习目前最流行的一个数据库MySQL。</p>
<p>这篇文章，带大家走进Mysql的世界。</p>
<ul>
<li>MySQL的底层结构</li>
<li>MySQL的查询过程</li>
<li>索引结构</li>
<li>MySQL的三种Log</li>
<li>MySQL的存储引擎</li>
</ul>
<span id="more"></span>

<h2 id="MySQL的底层结构"><a href="#MySQL的底层结构" class="headerlink" title="MySQL的底层结构"></a>MySQL的底层结构</h2><p>MySQL我们可以主要分成三层：</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/v3Tr6K.png"></p>
<ol>
<li>客户端连接层。主要负责处理客户端的连接，用户的账号密码校验，权限等功能。</li>
<li>核心服务层。主要功能有缓存，对SQL语句的解析和优化，对底层API的调用。</li>
<li>存储引擎。 对数据对管理，存储，查询，事务，索引等等功能。</li>
</ol>
<h2 id="MySQL的查询过程"><a href="#MySQL的查询过程" class="headerlink" title="MySQL的查询过程"></a>MySQL的查询过程</h2><p>一个SQL的查询过程可以分成六步。 如图：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/mkccLn.png"></p>
<ol>
<li>客户端和MySQL建立连接。</li>
<li>查询缓存，如果缓存命中，直接返回。但是不建议使用缓存，命中率低，弊大于利。</li>
<li>解析SQL，生成语法解析树。如果SQL写的有问题，这一步会报错。</li>
<li>查询优化，通过语法树，生成执行计划，计划可能不止一个，优化器会找到成本最小的一个执行计划。</li>
<li>执行计划，查询执行引擎拿到了执行计划，调用对应的存储引擎的接口，来执行查询，得到结果。</li>
<li>返回结果，缓存结果。如果结果集很大（1W条），不会等到全部结果出来再返回，会在第一条结果出来的时候，就开始返回结果。</li>
</ol>
<h2 id="MySQL的三种Log"><a href="#MySQL的三种Log" class="headerlink" title="MySQL的三种Log"></a>MySQL的三种Log</h2><p>MySQL有三种Log，各司其职。分别是binlog、redo log、undo log。</p>
<h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>binlog的主要作用是记录数据库的每一步变化。由MySQL核心服务层控制。</p>
<p>可以让别的服务来监听，实现数据同步。</p>
<p>或者再数据库损坏之后，恢复数据。</p>
<p>数据库的每一次变化，比如某一个表新增了一条数据，就会生成一个对应的binlog。<br>另外的服务监听到了之后，可以做出对应的操作，把数据同步一份。</p>
<p>可以做主备，可以做读写分离。</p>
<h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>首先我们先要了解到一点，磁盘的IO昂贵，数据库再做数据变更的时候，都不会一有变更，就立即更新磁盘数据。</p>
<p>做法都是先在内存中进行操作，等到合适的时候（配置决定），再一次性的刷到磁盘当中。</p>
<p>但是如果数据在内存当中变更了之后，数据库崩溃了，这个时候内存中的数据就会丢失。</p>
<p>MySQL就会有一个redo log来保证上述情况的数据不丢失。</p>
<p>redo log由存储引擎控制。</p>
<p>当MySQL修改数据的做法如下：</p>
<ol>
<li>把对应数据的页，查询出来，并保存到内存中</li>
<li>修改内存中的数据，同时生成redo log（哪一页，修改了那些内容）。原子操作</li>
<li>如果这时MySQL崩溃，可以根据redo log恢复内存中的数据。</li>
<li>如果没有崩溃，会在合适的时候，把内存中的数据落到磁盘上，同时删除对应的redo log。</li>
</ol>
<h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3><p>undo log和事务有关。InnoDB存储引擎特有。</p>
<p>在一个事务中，每一次操作，都会生成一个log，所有的log会组成一个数据链。</p>
<p>可以用来控制回滚，和在不同的事务级别下，所展示的数据的版本。</p>
<p>这就是MVCC，多版本并发控制。我们在事务那一章的时候，还会详细说明。</p>
<h2 id="MySQL的存储引擎"><a href="#MySQL的存储引擎" class="headerlink" title="MySQL的存储引擎"></a>MySQL的存储引擎</h2><p>MySQL的存储引擎的设计是MySQL的一大特点。<br>它可以让我们灵活的使用不同的存储引擎来应对不同的需求。</p>
<p>我们可以使用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ENGINE, SUPPORT <span class="keyword">FROM</span> INFORMATION_SCHEMA.ENGINES;</span><br><span class="line"><span class="comment">-- 或者</span></span><br><span class="line"><span class="keyword">SHOW</span> ENGINES;</span><br></pre></td></tr></table></figure>

<p>来查询存储引擎列表，和当前MySQL是否支持。</p>
<p>我们可以查看<a href="https://dev.mysql.com/doc/refman/8.0/en/storage-engines.html">官方文档</a><br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/8hRNsc.png"></p>
<p>我们在这里也做一下简单的介绍：</p>
<h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>我们最常用的存储引擎当属InnoDB。</p>
<p>它支持事务，符合ACID，支持行级锁，<br>支持B树索引，新版版还支持全文索引，<br>使用MVCC多版本并发控制，支持崩溃恢复，<br>还支持外键。</p>
<p>它是我们一般情况下的首选。</p>
<p>在需要事务的场景中，我们更是无脑选择InnoDB。</p>
<h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>MyISAM它的特点是不支持事务。当时它的优势是结构简单，比InnoDB稍快。</p>
<p>读效率比写更快。适合需要大量读的场景中。</p>
<p>支持B树索引和全文索引。如果小项目不想使用ES的话，可以考虑使用MyISAM做视图。</p>
<h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>看名字就知道，它的特点是把数据存储在内存中的，<br>所以没有持久化，断电崩溃数据会丢失。</p>
<p>但是就是因为使用的内存，它的速度非常快。可以部分替代Redis的功能。</p>
<h3 id="Archive"><a href="#Archive" class="headerlink" title="Archive"></a>Archive</h3><p>如果你需要保存日志信息，存档信息等一些需要快速查询的场景。<br>你可以使用Archive。</p>
<p>它支持数据压缩，不支持事务、索引。</p>
<p>可以部分替代MongoDB的功能。</p>
<h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><p>CSV的结构很简单，它会生成一个<code>.cvs</code>的文件来存储数据。</p>
<p>我们可以使用Excel来打开它。一般很少使用。</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>除了上述的存储引擎，剩下还有一些存储引擎。<br>比如说：Merge、Federated、Blackhole、NDB、Example<br>具体参考<a href="https://dev.mysql.com/doc/refman/8.0/en/storage-engines.html">官方文档</a></p>
<h2 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h2><p>索引是为了提高查询效率的一种手段。</p>
<p>如果我们的数据一本新华字典的话，索引就是字典的目录。可以大大提高我们查询的效率。</p>
<p>但是索引是有代价的，它会提高修改数据的成本，也需要单独的空间来存放索引数据。</p>
<p>常见的索引结构有以下几种；</p>
<ul>
<li>Hash</li>
<li>B tree</li>
<li>全文索引</li>
</ul>
<p>本文，我们会重点说说B树这种结构。</p>
<h3 id="什么是B树"><a href="#什么是B树" class="headerlink" title="什么是B树"></a>什么是B树</h3><p>B树是一种多叉树，一个根节点下面一般有很多叶子节点，所以B树的高度一般不高。</p>
<p>使用B树存储的数据都是有序的。</p>
<p>如下图：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/mwUrxI.png"></p>
<h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>B+树是B树的一种升级版。</p>
<p>它的特点是，只有叶子节点存储数据。非叶子节点只存储索引。</p>
<p>叶子节点（数据节点）同样也是有序的，并且相邻的两个叶子节点使用双向链表连接起来，这样范围查询的效率非常高。</p>
<p>可参考下图：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/tu3yvP.png"></p>
<p>MySQL的InnoDB存储引擎使用的就是B+树作为索引结构。</p>
<p>每一个节点的大小固定，迎合一次磁盘IO，大小应该是16KB。</p>
<p>而非叶子上存储的都是索引，所以一个节点上可以存储非常多的索引数据。<br>再通过二分查找，来找到对应的数据地址。</p>
<h3 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h3><p>在InnoDB存储引擎中，表中的数据都是通过一个B+树来维护的，<br>同时表中所有的数据，都存放在B+树的叶子节点上。</p>
<p>而非聚簇索引，B+树的叶子节点上，存储的都是主键ID。<br>如果需要找到详情的数据信息，需要回表查询，即拿到主键ID，到主B+树（聚簇索引）上再查询。</p>
<h3 id="如何通过索引实现范围查询"><a href="#如何通过索引实现范围查询" class="headerlink" title="如何通过索引实现范围查询"></a>如何通过索引实现范围查询</h3><p>如果我们有一个这样的查询语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 查询今年以来的订单</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">where</span> create_time <span class="operator">&gt;</span> <span class="string">&#x27;2021-01-01 00:00:00&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>为了加快查询效率，我们会在<code>create_time</code>字段上添加索引。<br>这样就有了一个按照时间排序好的索引B+树了。</p>
<p>我们的查询会从全表扫面，变成通过索引查询。</p>
<p>我们会先通过索引找到第一create_time为’2021-01-01 00:00:00’的订单索引，</p>
<p>再通过B+树叶子节点间的链表指针，往后扫描，找到满足条件的所有的订单索引。</p>
<p>再拿到满足条件的订单主键ID，去订单主聚簇索引中回表查询详细信息，返回结果。</p>
<h3 id="联合索引、索引下推、覆盖索引"><a href="#联合索引、索引下推、覆盖索引" class="headerlink" title="联合索引、索引下推、覆盖索引"></a>联合索引、索引下推、覆盖索引</h3><h4 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h4><p>我们可以给一个字段添加索引，如上述的订单创建时间。</p>
<p>但是很多情况下的业务复杂，筛选条件众多，我们会为几个字段一起添加一个联合索引。</p>
<p>比如<code>订单的买家</code>、<code>订单创建时间</code>和<code>订单状态</code>可以作为一个联合索引。</p>
<p>这样在应用程序的客户端当中，买家查询自己的订单列表，并按照订单创建时间倒排，并可以通过订单状态做筛选条件。<br>这种情况下的查询效率会很高效。</p>
<h4 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h4><p>索引下推只会作用在联合索引上。并且会发生在范围查询上。</p>
<p>一句话说明：索引下推会尽量使用索引来判断where条件，而减少回表次数。</p>
<p>还是以订单表为列子，联合索引：客户姓名、订单时间</p>
<p>如果我们要查询：今年以来，姓王的客户的订单</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">where</span> create_time <span class="operator">&gt;</span> <span class="string">&#x27;2021-01-01 00:00:00&#x27;</span> <span class="keyword">and</span> customer_name <span class="keyword">like</span> <span class="string">&#x27;王%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>而我们都知道，范围查询会中断索引。</p>
<p>如果我们不使用索引下推的话：</p>
<p>我们会在<code>客户姓名、订单时间索引</code>B+树中找出满足客户姓名姓氏的所有订单ID</p>
<p>拿到所有订单ID去主键聚簇索引中回表查询数据，再判断今年以来的订单数据。</p>
<p>这种情况下，回表查询的订单ID会非常多。</p>
<p>而如果我们使用索引下推：</p>
<p>我们会在索引的B+树中，提前查询、筛选中满足姓氏和时间的订单ID。</p>
<p>再回表查询。</p>
<p>这种情况下，回表查询的订单ID是提前筛选好的，会少很多。</p>
<h4 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h4><p>还是上述情况，订单表的联合索引<code>客户姓名、订单时间</code>。有这样的查询语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">where</span> create_time <span class="operator">&gt;</span> <span class="string">&#x27;2021-01-01 00:00:00&#x27;</span> <span class="keyword">and</span> customer_name <span class="keyword">like</span> <span class="string">&#x27;王%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>SQL语句中的所有的查询条件和返回数据，在联合索引的B+树中都有，</p>
<p>我们只需要通过索引查询出来主键ID，就可以直接返回结果了，不需要再回表查询。</p>
<p>这就是覆盖索引。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本次我们探讨了一种目前最流行的关系型数据库MySQL。</p>
<p>带大家了解了下MySQL的基本结构，它的查询过程。</p>
<p>通过三种Log来了解了一些MySQL的内部原理。</p>
<p>还有索引相关的一些内容。</p>
<p>希望大家都有所收获。</p>
<p>我们下次还会讲到MySQL的事务和MySQL调优相关的内容。</p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL调优</title>
    <url>/2021/09/11/database/MySQL%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这篇文章，我们将谈到SQL优化的相关知识。</p>
<ul>
<li>我们会讲到如何合理定义数据结构</li>
<li>如何设计高效的索引</li>
<li>如果写出高效的SQL语句</li>
<li>如果发生了慢查询，我们如何分析</li>
<li>如何选择其他的组件来替换MySQL</li>
</ul>
<p>现在，我们开始吧！！</p>
<span id="more"></span>

<h2 id="数据结构的优化"><a href="#数据结构的优化" class="headerlink" title="数据结构的优化"></a>数据结构的优化</h2><h3 id="数据类型的选择"><a href="#数据类型的选择" class="headerlink" title="数据类型的选择"></a>数据类型的选择</h3><h4 id="使用最佳的数据类型"><a href="#使用最佳的数据类型" class="headerlink" title="使用最佳的数据类型"></a>使用最佳的数据类型</h4><p>数据类型越短越好，<br>越小的数据类型，往往意味着更好的效率。</p>
<p>整型的效率会比字符串的性能高<br>使用Date类型来存储时间，比字符串类型的效率来的高。</p>
<h4 id="尽量使用非空"><a href="#尽量使用非空" class="headerlink" title="尽量使用非空"></a>尽量使用非空</h4><p>null会影响到索引效率，查询的返回结果。<br>可会可能引发业务层的空指针。</p>
<p>我们可以给字段设为not null，且设定一个默认值。</p>
<h4 id="可以使用UNSIGNED来修饰数字类型"><a href="#可以使用UNSIGNED来修饰数字类型" class="headerlink" title="可以使用UNSIGNED来修饰数字类型"></a>可以使用UNSIGNED来修饰数字类型</h4><p>无符号数字的存储效率是有符号数组的将近一倍。</p>
<p>比如ID，金额等一些确定是正数的数字类型，<br>我们可以使用UNSIGNED来修饰。</p>
<h3 id="表的设计"><a href="#表的设计" class="headerlink" title="表的设计"></a>表的设计</h3><h4 id="避免宽表"><a href="#避免宽表" class="headerlink" title="避免宽表"></a>避免宽表</h4><p>宽表意味着一条记录有很多字段。<br>我们尽量避免一张表有多于100个字段。</p>
<p>他会在查询的时候，增加性能的负担。<br>尤其是使用alter操作来改变表结构的时候，<br>会非常消耗性能。</p>
<p>我们可以给一张宽表拆分成不同的小表。<br>比如：一张订单表，我们可以拆分成<br>订单主表；订单金额表；订单商品表；订单物流表 等等。</p>
<h4 id="范式-and-反范式"><a href="#范式-and-反范式" class="headerlink" title="范式 and 反范式"></a>范式 and 反范式</h4><p>满足范式的设计，往往会更加精简，<br>但是如果需要查询更多的信息，需要连表查询。</p>
<p>比如说，订单表里面只有买家ID这个字段，<br>在页面上展示的时候，往往是需要展示买家名称，<br>这个时候，就需要连表查询，关联订单表，和客户表，<br>而在我们分布式系统中，更需要单独调用别的中台的接口，来填充信息。</p>
<p>而反范式，就是把一些数据给冗余下来，以提高查询效率。</p>
<p>在高并发，高性能，高数据量的时候，<br>往往都是单表查询，<br>反范式，冗余会使用的更多。<br>冗余可以大大简化我们的SQL，提高我们索引的命中率。</p>
<h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><blockquote>
<p>好的索引，是查询效率提升的关键</p>
</blockquote>
<h3 id="什么时候添加索引"><a href="#什么时候添加索引" class="headerlink" title="什么时候添加索引"></a>什么时候添加索引</h3><p>如果我们表的数据只有十几行甚至几行的时候，<br>我们不要添加索引。<br>因为这个时候，全表扫描的效率往往更好，<br>而索引的维护，还会影响到数据的修改效率。</p>
<p>如果我们的表数据量很多，<br>我们推荐设计合适的索引来提高查询效率。</p>
<p>如果我们的表数据非常非常多，<br>我们考虑使用分区，分表</p>
<h3 id="添加合适的索引"><a href="#添加合适的索引" class="headerlink" title="添加合适的索引"></a>添加合适的索引</h3><p>在查询条件上，<br>在关联字段上，<br>在排序字段上，<br>在分组字段上，<br>可以添加索引。</p>
<p>添加索引的字段值区分度越高越好，比如ID<br>像枚举类型的值不适合设置成索引。</p>
<p>索引不是越多越好，索引会占用空间，索引会影响修改数据的效率。</p>
<h3 id="组合索引"><a href="#组合索引" class="headerlink" title="组合索引"></a>组合索引</h3><p>根据业务中的查询条件，添加合适的组合索引<br>遵循最左匹配原则</p>
<h3 id="使用覆盖索引"><a href="#使用覆盖索引" class="headerlink" title="使用覆盖索引"></a>使用覆盖索引</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">where</span> buyer_id <span class="operator">=</span> <span class="string">&#x27;&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">where</span> buyer_id <span class="operator">=</span> <span class="string">&#x27;&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>如果我们在订单表（order）中的买家ID（buyer_id）上建立索引，</p>
<p>上面第一条的SQL会比第二条的执行速度快很多。</p>
<p>因为第一条索引直接走了覆盖索引，而不用回表查询，大大提高效率。</p>
<h3 id="精简索引字段"><a href="#精简索引字段" class="headerlink" title="精简索引字段"></a>精简索引字段</h3><p>如果索引字段太长，且有很多重复的字符，我们可以截取一部分来设成索引。</p>
<p>可以减少索引体积。</p>
<p>比如说email，或者网站地址，或者非常长的ID</p>
<p>把区分度高的部分，截取出来，设成索引。</p>
<h2 id="SQL语句编写的优化"><a href="#SQL语句编写的优化" class="headerlink" title="SQL语句编写的优化"></a>SQL语句编写的优化</h2><h3 id="基础SQL原则"><a href="#基础SQL原则" class="headerlink" title="基础SQL原则"></a>基础SQL原则</h3><ul>
<li>只返回必要的行，避免<code>select *</code>这样的语句。</li>
<li>where条件里面控制范围</li>
<li>limit 控制返回条数</li>
<li>缓存热点数据，使用服务端缓存（redis），避免使用MySQL缓存</li>
<li>查询条件 和 索引相匹配</li>
</ul>
<h3 id="count函数优化"><a href="#count函数优化" class="headerlink" title="count函数优化"></a>count函数优化</h3><p>一般来说，我们尽量使用<code>count(*)</code>，来统计行数，<br>但是还有一种用法，我们可以使用<code>count(column_1)</code>来统计，column_1不为空的记录数。</p>
<p>在column_1不为空的情况下：<br>count(*) &#x3D;&#x3D; count(column_1)</p>
<p>在column_1有null值的情况下：<br>count(*) &gt; column_1</p>
<p>这点需要大家注意区别。</p>
<p>在不需要准确数据的情况下，<br>我们可以使用 explain 来替代 count。</p>
<p>explain会给出一个总数目的估计值，<br>explain只会给出一个查询计划，并不会真正去存储引擎上执行，<br>它的执行效率是高的。</p>
<h3 id="避免深分页"><a href="#避免深分页" class="headerlink" title="避免深分页"></a>避免深分页</h3><p>我们要避免这样的SQL。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> limit <span class="number">1000</span>, <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<p>这样会先把前面的1010条数据都查询出来，在截取后10条记录返回。<br>很营销效率。</p>
<p>在这种情况下，我会推荐使用游标的来查询。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> id <span class="operator">&gt;</span> <span class="string">&#x27;&#x27;</span> limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<h3 id="分解大批量"><a href="#分解大批量" class="headerlink" title="分解大批量"></a>分解大批量</h3><p>如果我们需要清楚历史日志数据，我们可能会这样：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> log <span class="keyword">where</span> create_time <span class="operator">&lt;</span> <span class="string">&#x27;&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>如果历史数据非常大，这样会非常影响数据库的性能，<br>并会锁住很多记录，占用系统资源。</p>
<p>可能会让很多小而重要的查询发生中断。</p>
<p>我们需要这样做：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> log <span class="keyword">where</span> create_time <span class="operator">&lt;</span> <span class="string">&#x27;&#x27;</span> limit <span class="number">1000</span>;</span><br></pre></td></tr></table></figure>

<p>并在业务代码中，循环删除。</p>
<h2 id="慢查询及其分析"><a href="#慢查询及其分析" class="headerlink" title="慢查询及其分析"></a>慢查询及其分析</h2><h3 id="开启慢查询监控"><a href="#开启慢查询监控" class="headerlink" title="开启慢查询监控"></a>开启慢查询监控</h3><p>我们可以先查看一下配置，直接执行下面的SQL：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;slow%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>得到效果如下：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/O1oh8f.png"><br>很明显，我还没有开启慢查询监控。</p>
<p>我们继续再修改配置，开启监控：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> slow_query_log<span class="operator">=</span><span class="keyword">ON</span>;</span><br></pre></td></tr></table></figure>

<p>在设置一下触发时间：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;long%&#x27;</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> long_query_time <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>默认的慢查询的触发时间是10秒，太长了<br>我们配置成合适的触发时间， 我这里配置的是1秒。</p>
<p>Tip：配置好之后，需要重新打开新的session查看配置。</p>
<p>一切完成之后，如果我们再发生了慢查询，就会在对应的位置生成log啦。<br>我们再可以使用explain分析SQL</p>
<h3 id="使用EXPLAIN来分析SQL执行计划"><a href="#使用EXPLAIN来分析SQL执行计划" class="headerlink" title="使用EXPLAIN来分析SQL执行计划"></a>使用EXPLAIN来分析SQL执行计划</h3><p>首先上<a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html">官方文档</a><br>最权威</p>
<p>explain SQL 是一个非常复杂的过程，里面的细节很多，<br>在这里只做一个简单的介绍，和常用的排查慢查询的方法。</p>
<h4 id="执行和字段解释"><a href="#执行和字段解释" class="headerlink" title="执行和字段解释"></a>执行和字段解释</h4><p>我们拿到了慢查询的SQL，直接再语句的前面加上一个<code>explain</code> 就行。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> customer <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>我们可以看到一下结果：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/FZy098.png"></p>
<p>一共返回了12个字段，我来看一下每一个字段代表什么意思。</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>JSON Name</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_id"><code>id</code></a></td>
<td><code>select_id</code></td>
<td>表示查询中执行select子句或者操作表的顺序，id的值越大，代表优先级越高，越先执行</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_select_type"><code>select_type</code></a></td>
<td>None</td>
<td>表示 select 查询的类型，主要是用于区分各种复杂的查询，例如：普通查询、联合查询、子查询等</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_table"><code>table</code></a></td>
<td><code>table_name</code></td>
<td>查询的表名，并不一定是真实存在的表，有别名显示别名，也可能为临时表</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_partitions"><code>partitions</code></a></td>
<td><code>partitions</code></td>
<td>查询时匹配到的分区信息，对于非分区表值为NULL，当查询的是分区表时，partitions显示分区表命中的分区情况</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_type"><code>type</code></a></td>
<td><code>access_type</code></td>
<td>查询使用了何种类型，它在 SQL优化中是一个非常重要的指标</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_possible_keys"><code>possible_keys</code></a></td>
<td><code>possible_keys</code></td>
<td>表示在MySQL中通过哪些索引，能让我们在表中找到想要的记录，一旦查询涉及到的某个字段上存在索引，则索引将被列出，但这个索引并不定一会是最终查询数据时所被用到的索引</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_key"><code>key</code></a></td>
<td><code>key</code></td>
<td>区别于possible_keys，key是查询中实际使用到的索引，若没有使用索引，显示为NULL</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_key_len"><code>key_len</code></a></td>
<td><code>key_length</code></td>
<td>表示查询用到的索引长度（字节数），原则上长度越短越好</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_ref"><code>ref</code></a></td>
<td><code>ref</code></td>
<td>搜索关联字段，有可能是常数、多表关联字段、函数等</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_rows"><code>rows</code></a></td>
<td><code>rows</code></td>
<td>以表的统计信息和索引使用情况，估算要找到我们所需的记录，需要读取的行数。</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_filtered"><code>filtered</code></a></td>
<td><code>filtered</code></td>
<td>这个是一个百分比的值，表里符合条件的记录数的百分比。简单点说，这个字段表示存储引擎返回的数据在经过过滤后，剩下满足条件的记录数量的比例</td>
</tr>
<tr>
<td><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_extra"><code>Extra</code></a></td>
<td>None</td>
<td>不适合在其他列中显示的信息，Explain 中的很多额外的信息会在 Extra 字段显示</td>
</tr>
</tbody></table>
<h4 id="重点排查顺序"><a href="#重点排查顺序" class="headerlink" title="重点排查顺序"></a>重点排查顺序</h4><p>explain了一条SQL之后，我们的排查流程如下：</p>
<ul>
<li><p>type</p>
<ul>
<li>system &gt; const &gt; eq_ref &gt; ref &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL</li>
<li>一般最少要达到range等级，最好达到ref等级</li>
</ul>
</li>
<li><p>key</p>
<ul>
<li>实际上用到的索引</li>
</ul>
</li>
<li><p>key_len</p>
<ul>
<li>使用到的索引长度，可以算出联合索引中走了几个索引</li>
<li>utf8中一个字符占3个字节， 允许null +1， not null +2</li>
</ul>
</li>
<li><p>Extra</p>
<ul>
<li>一些额外信息，表示使用了哪些操作</li>
<li>像使用了覆盖索引，索引下推，这都是比较好的</li>
<li>像使用了文件排序，需要优化下，尽量使用索引排序</li>
</ul>
</li>
</ul>
<h2 id="使用其他的组件来替代MySQL"><a href="#使用其他的组件来替代MySQL" class="headerlink" title="使用其他的组件来替代MySQL"></a>使用其他的组件来替代MySQL</h2><ul>
<li>一些经常查询，或者修改频次高的数据，我们尽量放到Redis里面</li>
<li>如果需要使用到全文索引，首推Elastic Search</li>
<li>如果是类似日志的数据，数据量大，不需要连表，不需要复杂的索引，可以使用MongoDB</li>
</ul>
<p>但是MySQL是一款非常成熟，非常稳定的数据库，在一般的条件下，我们还是会首选MySQL。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，我们学到了MySQL优化的一些相关知识。<br>我们从建表开始，选择合适的数据结构，索引的建立，<br>到生产中，遇到的慢查询的处理。</p>
<p>希望对大家有所帮助！！Peace～</p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Redis 集群进行扩展</title>
    <url>/2022/05/01/database/Redis%20%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<p>使用 Redis 集群进行横向扩展</p>
<p>Redis 使用称为 Redis 集群的部署拓扑进行水平扩展。本主题将教您如何在生产环境中设置、测试和操作 Redis 集群。您将从最终用户的角度了解 Redis 集群的可用性和一致性特征。</p>
<p>如果您计划运行生产 Redis 集群部署或想要更好地了解 Redis 集群的内部工作原理，请参阅<a href="https://redis.io/topics/cluster-spec">Redis 集群规范</a> 。要了解 Redis Enterprise 如何处理缩放，请参阅<a href="https://redis.com/redis-enterprise/technology/linear-scaling-redis-enterprise/">使用 Redis Enterprise 进行线性缩放</a> 。</p>
<span id="more"></span>

<h2 id="Redis集群101"><a href="#Redis集群101" class="headerlink" title="Redis集群101"></a>Redis集群101</h2><p>Redis Cluster 提供了一种运行 Redis 安装的方法，其中数据会自动跨多个 Redis 节点进行分片。Redis 集群还在分区期间提供一定程度的可用性——实际上，是在某些节点发生故障或无法通信时继续运行的能力。但是，如果发生较大的故障（例如，当大多数主节点不可用时），集群将变得不可用。</p>
<p>因此，借助 Redis 集群，您可以：</p>
<ul>
<li>在多个节点之间自动拆分数据集。</li>
<li>当节点的子集出现故障或无法与集群的其余部分通信时继续操作。</li>
</ul>
<h4 id="Redis-集群-TCP-端口"><a href="#Redis-集群-TCP-端口" class="headerlink" title="Redis 集群 TCP 端口"></a>Redis 集群 TCP 端口</h4><p>每个 Redis 集群节点都需要两个打开的 TCP 连接：一个用于为客户端提供服务的 Redis TCP 端口，例如 6379，以及第二个称为 <em>集群总线端口的端口</em> 。默认情况下，集群总线端口设置为数据端口加10000（如16379）；但是，您可以在<code>cluster-port</code>配置中覆盖它。</p>
<p>集群总线是一种使用二进制协议的节点到节点的通信通道，由于带宽和处理时间小，更适合节点之间交换信息。节点使用集群总线进行故障检测、配置更新、故障转移授权等。客户端不应该尝试与集群总线端口通信，而是使用 Redis 命令端口。但是，请确保在防火墙中打开这两个端口，否则 Redis 集群节点将不会无法通信。</p>
<p>为了让 Redis 集群正常工作，您需要为每个节点：</p>
<ol>
<li>客户端通信端口（通常为 6379）用于与客户端通信，并向所有需要访问集群的客户端以及使用该客户端端口进行密钥迁移的所有其他集群节点开放。</li>
<li>集群总线端口必须可以从所有其他集群节点访问。</li>
</ol>
<p>如果您不打开两个 TCP 端口，您的集群将不会按预期工作。</p>
<h4 id="Redis-集群和-Docker"><a href="#Redis-集群和-Docker" class="headerlink" title="Redis 集群和 Docker"></a>Redis 集群和 Docker</h4><p>目前，Redis Cluster 不支持 NATted 环境和 IP 地址或 TCP 端口重新映射的一般环境。</p>
<p>Docker 使用一种称为<em>端口映射</em>的技术：与程序认为使用的端口相比，在 Docker 容器内运行的程序可能会暴露出不同的端口。这对于在同一服务器上同时使用相同端口运行多个容器很有用。</p>
<p>要使 Docker 兼容 Redis Cluster，需要使用 Docker 的 <em>主机网络模式</em> 。有关详细信息，请参阅Docker 文档<code>--net=host</code>中的选项。<a href="https://docs.docker.com/engine/userguide/networking/dockernetworks/"></a> </p>
<h4 id="Redis集群数据分片"><a href="#Redis集群数据分片" class="headerlink" title="Redis集群数据分片"></a>Redis集群数据分片</h4><p>Redis 集群不使用一致性哈希，而是使用一种不同形式的分片，其中每个键在概念上都是我们所说的<strong>哈希槽</strong>的一部分。</p>
<p>Redis 集群中有 16384 个哈希槽，要计算给定键的哈希槽，我们只需对键的 CRC16 取模 16384。</p>
<p>Redis 集群中的每个节点都负责哈希槽的一个子集，因此，例如，您可能有一个包含 3 个节点的集群，其中：</p>
<ul>
<li>节点 A 包含从 0 到 5500 的哈希槽。</li>
<li>节点 B 包含从 5501 到 11000 的哈希槽。</li>
<li>节点 C 包含从 11001 到 16383 的哈希槽。</li>
</ul>
<p>这使得添加和删除集群节点变得容易。例如，如果我想添加一个新的节点D，我需要将节点A、B、C的一些哈希槽移动到D。同样，如果我想从集群中删除节点A，我可以移动哈希槽由 A 提供给 B 和 C。一旦节点 A 为空，我就可以将其从集群中完全移除。</p>
<p>将哈希槽从一个节点移动到另一个节点不需要停止任何操作；因此，添加和删除节点，或更改节点持有的哈希槽的百分比，不需要停机。</p>
<p>Redis Cluster 支持多键操作，只要单个命令执行（或整个事务，或 Lua 脚本执行）涉及的所有键都属于同一个哈希槽。<em>用户可以使用称为散列标签</em>的功能强制多个键成为同一散列槽的一部分。</p>
<p>散列标签记录在 Redis 集群规范中，但要点是如果键中 {} 括号之间有子字符串，则仅对字符串内部的内容进行散列。例如，键<code>user:&#123;123&#125;:profile</code>和<code>user:&#123;123&#125;:account</code>保证在同一个散列槽中，因为它们共享相同的散列标签。因此，您可以在同一个多键操作中对这两个键进行操作。</p>
<h4 id="Redis集群主从模型"><a href="#Redis集群主从模型" class="headerlink" title="Redis集群主从模型"></a>Redis集群主从模型</h4><p>为了在主节点的子集出现故障或无法与大多数节点通信时保持可用，Redis 集群使用主副本模型，其中每个哈希槽都有 1 个（主节点本身）到 N 个副本（N-1额外的副本节点）。</p>
<p>在我们包含节点 A、B、C 的示例集群中，如果节点 B 发生故障，集群将无法继续，因为我们无法再提供 5501-11000 范围内的哈希槽。</p>
<p>但是，在创建集群的时候（或者以后），我们给每个master添加一个replica节点，这样最终的集群就是由A、B、C为主节点，A1、B1、C1为master节点组成的。副本节点。这样，如果节点 B 发生故障，系统可以继续运行。</p>
<p>节点 B1 复制 B，B 发生故障，集群将节点 B1 提升为新的主节点，并继续正常运行。</p>
<p>但是需要注意的是，如果节点 B 和 B1 同时发生故障，Redis Cluster 将无法继续运行。</p>
<h4 id="Redis集群一致性保证"><a href="#Redis集群一致性保证" class="headerlink" title="Redis集群一致性保证"></a>Redis集群一致性保证</h4><p>Redis Cluster 不保证 <strong>强一致性</strong> 。实际上，这意味着在某些情况下，Redis 集群可能会丢失系统向客户端确认的写入。</p>
<p>Redis Cluster 会丢失写入的第一个原因是因为它使用异步复制。这意味着在写入期间会发生以下情况：</p>
<ul>
<li>你的客户写信给主人 B。</li>
<li>主 B 回复 OK 给你的客户。</li>
<li>主节点 B 将写入传播到其副本 B1、B2 和 B3。</li>
</ul>
<p>如您所见，B 在回复客户端之前不会等待 B1、B2、B3 的确认，因为这对 Redis 来说是一个令人望而却步的延迟惩罚，所以如果您的客户端写了一些东西，B 会确认写入，但在此之前崩溃能够将写入发送到它的副本，其中一个副本（没有收到写入）可以提升为主，永远失去写入。</p>
<p>这与大多数配置为每秒将数据刷新到磁盘的数据库所发生的情况非常相似，因此根据过去不涉及分布式系统的传统数据库系统的经验，您已经能够推断出这种情况。同样，您可以通过强制数据库在回复客户端之前将数据刷新到磁盘来提高一致性，但这通常会导致性能极低。这相当于 Redis 集群中的同步复制。</p>
<p>基本上，需要在性能和一致性之间进行权衡。</p>
<p>Redis Cluster 在绝对需要时支持同步写入，通过<a href="https://redis.io/commands/wait"><code>WAIT</code></a> 命令实现。这使得丢失写入的可能性大大降低。但是，请注意，即使使用同步复制，Redis Cluster 也没有实现强一致性：在更复杂的故障场景下，总是有可能无法接收到写入的副本将被选为 master。</p>
<p>还有另一个值得注意的场景，Redis 集群将丢失写入，这发生在网络分区期间，其中客户端与少数实例隔离，至少包括一个主实例。</p>
<p>以我们的 6 节点集群为例，由 A、B、C、A1、B1、C1 组成，有 3 个主节点和 3 个副本节点。还有一个客户端，我们称之为 Z1。</p>
<p>发生分区后，有可能分区的一侧有A、C、A1、B1、C1，另一侧有B、Z1。</p>
<p>Z1 仍然能够写入 B，B 将接受其写入。如果分区在很短的时间内恢复正常，集群将继续正常运行。但是，如果分区持续足够长的时间让 B1 在分区的多数端被提升为主节点，则 Z1 在此期间发送给 B 的写入将丢失。</p>
<p>笔记</p>
<p>Z1 可以发送到 B 的写入量有一个 <strong>最大窗口</strong> ：如果经过足够的时间分区的多数方选择一个副本作为主节点，则少数方的每个主节点都将停止接受写入.</p>
<p>这个时间量是Redis Cluster的一个非常重要的配置指令，称为 <strong>节点超时时间</strong> 。</p>
<p>节点超时结束后，主节点被认为发生故障，可以由其副本之一替换。类似地，在节点超时过去但主节点无法感知大多数其他主节点的情况下，它会进入错误状态并停止接受写入。</p>
<h2 id="Redis集群配置参数"><a href="#Redis集群配置参数" class="headerlink" title="Redis集群配置参数"></a>Redis集群配置参数</h2><p>我们即将创建一个示例集群部署。在继续之前，我们先介绍一下Redis Cluster在<code>redis.conf</code>文件中引入的配置参数。</p>
<ul>
<li><strong>cluster-enabled<code>&lt;yes/no&gt;</code></strong> ：如果是，则在特定的 Redis 实例中启用 Redis 集群支持。否则实例将像往常一样作为独立实例启动。</li>
<li><strong>cluster-config-file<code>&lt;filename&gt;</code></strong> ：请注意，尽管有此选项的名称，但这不是用户可编辑的配置文件，而是 Redis 集群节点在每次发生更改时自动保存集群配置（基本上是状态）的文件，为了能够在启动时重新读取它。该文件列出了集群中的其他节点、它们的状态、持久变量等内容。由于接收到某些消息，此文件通常会被重写并刷新到磁盘上。</li>
<li><strong>cluster-node-timeout<code>&lt;milliseconds&gt;</code></strong> ：Redis 集群节点可以不可用的最长时间，不会被视为失败。如果主节点在超过指定时间段内无法访问，它将由其副本进行故障转移。此参数控制 Redis 集群中的其他重要内容。值得注意的是，在指定时间内无法到达大多数主节点的每个节点都将停止接受查询。</li>
<li><strong>cluster-slave-validity-factor<code>&lt;factor&gt;</code></strong> ：如果设置为零，副本将始终认为自己有效，因此将始终尝试对主服务器进行故障转移，而不管主服务器和副本之间的链接保持断开状态的时间长短。如果该值为正数，则计算最大断开连接时间作为<em>节点超时</em>值乘以此选项提供的因子，如果节点是副本，则如果主链接断开连接的时间超过指定的时间，它将不会尝试启动故障转移。例如，如果节点超时设置为 5 秒且有效性因子设置为 10，则与主服务器断开连接超过 50 秒的副本将不会尝试对其主服务器进行故障转移。请注意，如果没有能够对其进行故障转移的副本，则任何非零值都可能导致 Redis 集群在主服务器发生故障后不可用。在这种情况下，只有当原来的主节点重新加入集群时，集群才会恢复可用。</li>
<li><strong>cluster-migration-barrier<code>&lt;count&gt;</code></strong> ：一个主节点将保持连接的最小副本数，以便另一个副本迁移到不再被任何副本覆盖的主节点。有关详细信息，请参阅本教程中有关副本迁移的相应部分。</li>
<li><strong>cluster-require-full-coverage<code>&lt;yes/no&gt;</code></strong> ：如果将其设置为 yes，默认情况下，如果任何节点未覆盖一定百分比的键空间，则集群将停止接受写入。如果该选项设置为 no，即使只能处理有关键子集的请求，集群仍会为查询提供服务。</li>
<li><strong>cluster-allow-reads-when-down<code>&lt;yes/no&gt;</code></strong> ：如果设置为 no，默认情况下，Redis 集群中的节点将在集群标记为失败时停止为所有流量提供服务，或者当节点无法访问时master 的法定人数或未满足全覆盖时。这可以防止从不知道集群更改的节点读取可能不一致的数据。此选项可以设置为 yes 以允许在故障状态期间从节点读取，这对于想要优先读取可用性但仍希望防止不一致写入的应用程序很有用。它也可以用于只有一个或两个分片的 Redis 集群，因为它允许节点在主节点发生故障但无法进行自动故障转移时继续提供写入服务。</li>
</ul>
<h2 id="创建和使用-Redis-集群"><a href="#创建和使用-Redis-集群" class="headerlink" title="创建和使用 Redis 集群"></a>创建和使用 Redis 集群</h2><p>要创建和使用 Redis 集群，请按照以下步骤操作：</p>
<ul>
<li><a href="https://redis.io/docs/management/scaling/#create-a-redis-cluster">创建 Redis 集群</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#interact-with-the-cluster">与集群交互</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#write-an-example-app-with-redis-rb-cluster">使用 redis-rb-cluster 编写示例应用程序</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#reshard-the-cluster">重新分片集群</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#a-more-interesting-example-application">一个更有趣的示例应用程序</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#test-the-failover">测试故障转移</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#manual-failover">手动故障转移</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#add-a-new-node">添加新节点</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#remove-a-node">删除节点</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#replica-migration">副本迁移</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#upgrade-nodes-in-a-redis-cluster">升级 Redis 集群中的节点</a> </li>
<li><a href="https://redis.io/docs/management/scaling/#migrate-to-redis-cluster">迁移到 Redis 集群</a></li>
</ul>
<p>但是，首先，请熟悉创建集群的要求。</p>
<h4 id="创建-Redis-集群的要求"><a href="#创建-Redis-集群的要求" class="headerlink" title="创建 Redis 集群的要求"></a>创建 Redis 集群的要求</h4><p>要创建集群，首先需要有几个空的 Redis 实例以<em>集群模式</em>运行。</p>
<p>至少，在<code>redis.conf</code>文件中设置以下指令：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">port</span> <span class="number">7000</span></span><br><span class="line"><span class="string">cluster-enabled</span> <span class="literal">yes</span></span><br><span class="line"><span class="string">cluster-config-file</span> <span class="string">nodes.conf</span></span><br><span class="line"><span class="string">cluster-node-timeout</span> <span class="number">5000</span></span><br><span class="line"><span class="string">appendonly</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure>

<p>要启用集群模式，请将<code>cluster-enabled</code>指令设置为<code>yes</code>. 每个实例还包含存储此节点配置的文件路径，默认情况下为<code>nodes.conf</code>. 该文件从未被人类触及；它只是在 Redis 集群实例启动时生成，并在每次需要时更新。</p>
<p>请注意，按预期工作的<strong>最小集群</strong>必须至少包含三个主节点。对于部署，我们强烈建议使用具有三个主节点和三个副本的六节点集群。</p>
<p>您可以通过创建以下以您将在任何给定目录中运行的实例的端口号命名的目录来在本地进行测试。</p>
<p>例如：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mkdir</span> <span class="string">cluster-test</span></span><br><span class="line"><span class="string">cd</span> <span class="string">cluster-test</span></span><br><span class="line"><span class="string">mkdir</span> <span class="number">7000 </span><span class="number">7001 </span><span class="number">7002 </span><span class="number">7003 </span><span class="number">7004 </span><span class="number">7005</span></span><br></pre></td></tr></table></figure>

<p>在每个目录中创建一个<code>redis.conf</code>文件，从 7000 到 7005。作为配置文件的模板，只需使用上面的小示例，但请确保<code>7000</code>根据目录名称将端口号替换为正确的端口号。</p>
<p>您可以按如下方式启动每个实例，每个实例都在单独的终端选项卡中运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> 7000</span><br><span class="line">redis-server ./redis.conf</span><br></pre></td></tr></table></figure>

<p>您将从日志中看到每个节点都为自己分配了一个新 ID：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line">[<span class="number">82462</span>] <span class="number">26</span> Nov <span class="number">11</span>:<span class="number">56</span>:<span class="number">55.329</span> * No cluster configuration found, I<span class="symbol">&#x27;m</span> <span class="number">97</span>a3a64667477371c4479320d683e4c8db5858b1</span><br></pre></td></tr></table></figure>

<p>此 ID 将永远被此特定实例使用，以便该实例在集群上下文中具有唯一名称。每个节点都会记住使用此 ID 的每个其他节点，而不是通过 IP 或端口。IP地址和端口可能会改变，但唯一的节点标识符在节点的整个生命周期内永远不会改变。我们将此标识符简称为 <strong>Node ID</strong> 。</p>
<h4 id="创建-Redis-集群"><a href="#创建-Redis-集群" class="headerlink" title="创建 Redis 集群"></a>创建 Redis 集群</h4><p>现在我们有许多实例在运行，您需要通过向节点写入一些有意义的配置来创建集群。</p>
<p>您可以手动配置和执行单个实例或使用 create-cluster 脚本。让我们来看看你是如何手动完成的。</p>
<p>要创建集群，请运行：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">redis-cli <span class="comment">--cluster create 127.0.0.1:7000 127.0.0.1:7001 \</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7002</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7003</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7004</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7005</span> \</span><br><span class="line"><span class="comment">--cluster-replicas 1</span></span><br></pre></td></tr></table></figure>

<p>这里使用的命令是 <strong>create</strong> ，因为我们要创建一个新集群。该选项<code>--cluster-replicas 1</code>意味着我们希望为每个创建的母版创建一个副本。</p>
<p>其他参数是我想用来创建新集群的实例的地址列表。</p>
<p><code>redis-cli</code>将提出一个配置。通过键入<strong>yes</strong>接受建议的配置。集群将被配置和 <em>加入</em> ，这意味着实例将被引导到彼此交谈。最后，如果一切顺利，您将看到如下消息：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-attr">[OK]</span> <span class="attribute">All</span> <span class="number">16384</span> slots covered</span><br></pre></td></tr></table></figure>

<p>这意味着至少有一个主实例服务于 16384 个可用插槽中的每一个。</p>
<p>如果您不想像上面解释的那样通过手动配置和执行单个实例来创建 Redis 集群，则有一个更简单的系统（但您不会学到相同数量的操作细节）。</p>
<p><code>utils/create-cluster</code>在 Redis 发行版中找到该目录。里面有一个脚本<code>create-cluster</code>（与它所在的目录同名），它是一个简单的 bash 脚本。为了启动具有 3 个主节点和 3 个副本的 6 节点集群，只需键入以下命令：</p>
<ol>
<li><code>create-cluster start</code></li>
<li><code>create-cluster create</code></li>
</ol>
<p>当实用程序希望您接受集群布局时，<code>yes</code>在第 2 步中回复。<code>redis-cli</code></p>
<p>您现在可以与集群交互，默认情况下第一个节点将从端口 30001 启动。完成后，停止集群：</p>
<ol start="3">
<li><code>create-cluster stop</code></li>
</ol>
<p>请阅读<code>README</code>此目录的内部以获取有关如何运行脚本的更多信息。</p>
<h4 id="与集群交互"><a href="#与集群交互" class="headerlink" title="与集群交互"></a>与集群交互</h4><p>要连接到 Redis 集群，您需要一个支持集群的 Redis 客户端。请参阅您选择的客户端的<a href="https://redis.io/docs/clients">文档</a> 以确定其集群支持。</p>
<p>您还可以使用<code>redis-cli</code>命令行实用程序测试您的 Redis 集群：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">$ redis-cli -c -p <span class="number">7000</span></span><br><span class="line">redis <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span>&gt; <span class="keyword">set</span> foo bar</span><br><span class="line">-&gt; Redirected to slot [<span class="number">12182</span>] located at <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7002</span></span><br><span class="line">OK</span><br><span class="line">redis <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7002</span>&gt; <span class="keyword">set</span> hello world</span><br><span class="line">-&gt; Redirected to slot [<span class="number">866</span>] located at <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span></span><br><span class="line">OK</span><br><span class="line">redis <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span>&gt; <span class="keyword">get</span> foo</span><br><span class="line">-&gt; Redirected to slot [<span class="number">12182</span>] located at <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7002</span></span><br><span class="line"><span class="string">&quot;bar&quot;</span></span><br><span class="line">redis <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7002</span>&gt; <span class="keyword">get</span> hello</span><br><span class="line">-&gt; Redirected to slot [<span class="number">866</span>] located at <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span></span><br><span class="line"><span class="string">&quot;world&quot;</span></span><br></pre></td></tr></table></figure>

<p>笔记</p>
<p>如果您使用脚本创建集群，您的节点可能会侦听不同的端口，默认情况下从 30001 开始。</p>
<p><code>redis-cli</code>集群支持非常基础，因此它始终使用 Redis 集群节点能够将客户端重定向到正确节点的事实。一个认真的客户端能够做得更好，缓存哈希槽和节点地址之间的映射，直接使用正确的连接到正确的节点。地图仅在集群配置发生变化时刷新，例如在故障转移后或系统管理员通过添加或删除节点更改集群布局后。</p>
<h4 id="使用-redis-rb-cluster-编写示例应用程序"><a href="#使用-redis-rb-cluster-编写示例应用程序" class="headerlink" title="使用 redis-rb-cluster 编写示例应用程序"></a>使用 redis-rb-cluster 编写示例应用程序</h4><p>在继续展示如何操作 Redis 集群、执行故障转移或重新分片等操作之前，我们需要创建一些示例应用程序，或者至少能够理解简单的 Redis 集群客户端交互的语义。</p>
<p>通过这种方式，我们可以运行一个示例，同时尝试使节点出现故障，或者开始重新分片，以了解 Redis 集群在真实世界条件下的行为。当没有人写入集群时，查看发生了什么没有多大帮助。</p>
<p>本节通过两个示例说明<a href="https://github.com/antirez/redis-rb-cluster">redis-rb-cluster</a> 的一些基本用法 。第一个是以下内容，是 <a href="https://github.com/antirez/redis-rb-cluster/blob/master/example.rb"><code>example.rb</code></a>  redis-rb-cluster 分发版中的文件：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"> <span class="number">1</span>  <span class="keyword">require</span> <span class="string">&#x27;./cluster&#x27;</span></span><br><span class="line"> <span class="number">2</span></span><br><span class="line"> <span class="number">3</span>  <span class="keyword">if</span> <span class="variable constant_">ARGV</span>.length != <span class="number">2</span></span><br><span class="line"> <span class="number">4</span>      startup_nodes = [</span><br><span class="line"> <span class="number">5</span>          &#123;<span class="symbol">:host</span> =&gt; <span class="string">&quot;127.0.0.1&quot;</span>, <span class="symbol">:port</span> =&gt; <span class="number">7000</span>&#125;,</span><br><span class="line"> <span class="number">6</span>          &#123;<span class="symbol">:host</span> =&gt; <span class="string">&quot;127.0.0.1&quot;</span>, <span class="symbol">:port</span> =&gt; <span class="number">7001</span>&#125;</span><br><span class="line"> <span class="number">7</span>      ]</span><br><span class="line"> <span class="number">8</span>  <span class="keyword">else</span></span><br><span class="line"> <span class="number">9</span>      startup_nodes = [</span><br><span class="line"><span class="number">10</span>          &#123;<span class="symbol">:host</span> =&gt; <span class="variable constant_">ARGV</span>[<span class="number">0</span>], <span class="symbol">:port</span> =&gt; <span class="variable constant_">ARGV</span>[<span class="number">1</span>].to_i&#125;</span><br><span class="line"><span class="number">11</span>      ]</span><br><span class="line"><span class="number">12</span>  <span class="keyword">end</span></span><br><span class="line"><span class="number">13</span></span><br><span class="line"><span class="number">14</span>  rc = <span class="title class_">RedisCluster</span>.new(startup_nodes,<span class="number">32</span>,<span class="symbol">:timeout</span> =&gt; <span class="number">0.1</span>) </span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="number">16</span>  last = <span class="literal">false</span></span><br><span class="line"><span class="number">17</span></span><br><span class="line"><span class="number">18</span>  <span class="keyword">while</span> <span class="keyword">not</span> last</span><br><span class="line"><span class="number">19</span>      <span class="keyword">begin</span></span><br><span class="line"><span class="number">20</span>          last = rc.get(<span class="string">&quot;__last__&quot;</span>) </span><br><span class="line"><span class="number">21</span>          last = <span class="number">0</span> <span class="keyword">if</span> !last</span><br><span class="line"><span class="number">22</span>      <span class="keyword">rescue</span> =&gt; e</span><br><span class="line"><span class="number">23</span>          puts <span class="string">&quot;error <span class="subst">#&#123;e.to_s&#125;</span>&quot;</span></span><br><span class="line"><span class="number">24</span>          sleep <span class="number">1</span></span><br><span class="line"><span class="number">25</span>      <span class="keyword">end</span></span><br><span class="line"><span class="number">26</span>  <span class="keyword">end</span></span><br><span class="line"><span class="number">27</span></span><br><span class="line"><span class="number">28</span>  ((last.to_i+<span class="number">1</span>) ..<span class="number">1000000000</span>) .each&#123;|<span class="params">x</span>|</span><br><span class="line"><span class="number">29</span>      <span class="keyword">begin</span></span><br><span class="line"><span class="number">30</span>          rc.set(<span class="string">&quot;foo<span class="subst">#&#123;x&#125;</span>&quot;</span>,x) </span><br><span class="line"><span class="number">31</span>          puts rc.get(<span class="string">&quot;foo<span class="subst">#&#123;x&#125;</span>&quot;</span>) </span><br><span class="line"><span class="number">32</span>          rc.set(<span class="string">&quot;__last__&quot;</span>,x) </span><br><span class="line"><span class="number">33</span>      <span class="keyword">rescue</span> =&gt; e</span><br><span class="line"><span class="number">34</span>          puts <span class="string">&quot;error <span class="subst">#&#123;e.to_s&#125;</span>&quot;</span></span><br><span class="line"><span class="number">35</span>      <span class="keyword">end</span></span><br><span class="line"><span class="number">36</span>      sleep <span class="number">0.1</span></span><br><span class="line"><span class="number">37</span>  &#125;</span><br></pre></td></tr></table></figure>

<p>该应用程序做了一件非常简单的事情，它将表单中的键设置<code>foo&lt;number&gt;</code>为<code>number</code>，一个接一个。因此，如果您运行该程序，结果将是以下命令流：</p>
<ul>
<li>设置 foo0 0</li>
<li>设置 foo1 1</li>
<li>设置 foo2 2</li>
<li>等等…</li>
</ul>
<p>该程序看起来比通常情况下更复杂，因为它被设计为在屏幕上显示错误而不是异常退出，因此对集群执行的每个操作都由<code>begin</code> <code>rescue</code>块包装。</p>
<p>第<strong>14</strong>行是程序中第一个有趣的行。<em>它创建 Redis Cluster 对象，使用启动节点</em>列表作为参数，该对象允许对不同节点进行的最大连接数，最后是给定操作被认为失败后的超时。</p>
<p>启动节点不需要是集群的所有节点。重要的是至少有一个节点是可达的。另请注意，一旦 redis-rb-cluster 能够连接到第一个节点，它就会更新此启动节点列表。您应该预料到任何其他认真的客户都会有这样的行为。</p>
<p>现在我们已经将 Redis Cluster 对象实例存储在<strong>rc</strong>变量中，我们可以像使用普通 Redis 对象实例一样使用该对象。</p>
<p>这正是<strong>第 18 到 26 行</strong>发生的事情：当我们重新启动示例时，我们不想再次开始<code>foo0</code>，所以我们将计数器存储在 Redis 本身中。上面的代码旨在读取此计数器，或者如果计数器不存在，则将其赋值为零。</p>
<p>但是请注意它是一个 while 循环，因为我们想要一次又一次地尝试，即使集群已关闭并返回错误。正常的应用不需要这么小心。</p>
<p><strong>28 和 37 之间的行</strong>启动主循环，在该循环中设置键或显示错误。</p>
<p>注意<code>sleep</code>循环结束时的调用。在你的测试中，如果你想尽可能快地写入集群，你可以删除睡眠（相对于这是一个繁忙的循环，当然没有真正的并行性，所以你通常会得到 10k ops&#x2F;second最好的条件）。</p>
<p>通常写入速度会减慢，以便示例应用程序更容易被人类理解。</p>
<p>启动应用程序会产生以下输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ruby ./example.rb</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">^C (I stopped the program here) </span><br></pre></td></tr></table></figure>

<p>这不是一个非常有趣的程序，我们稍后会使用一个更好的程序，但我们已经可以看到程序运行时重新分片期间会发生什么。</p>
<h4 id="重新分片集群"><a href="#重新分片集群" class="headerlink" title="重新分片集群"></a>重新分片集群</h4><p>现在我们准备尝试集群重新分片。为此，请保持 example.rb 程序运行，以便您查看是否对程序运行有影响。此外，您可能希望对<code>sleep</code> 调用进行注释，以便在重新分片期间有一些更严重的写入负载。</p>
<p>重新分片基本上意味着将哈希槽从一组节点移动到另一组节点。与集群创建一样，它是使用 redis-cli 实用程序完成的。</p>
<p>要开始重新分片，只需键入：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">redis-cli <span class="attr">--cluster</span> reshard <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">7000</span></span><br></pre></td></tr></table></figure>

<p>你只需要指定一个节点，redis-cli 会自动找到其他节点。</p>
<p>目前 redis-cli 只能在管理员支持下重新分片，你不能说将 5% 的槽从这个节点移动到另一个节点（但这实现起来非常简单）。所以它从问题开始。第一个是你想做多少重新分片：</p>
<figure class="highlight vbnet"><table><tr><td class="code"><pre><span class="line">How many slots <span class="keyword">do</span> you want <span class="keyword">to</span> move (<span class="keyword">from</span> <span class="number">1</span> <span class="keyword">to</span> <span class="number">16384</span>) ?</span><br></pre></td></tr></table></figure>

<p>我们可以尝试重新分片 1000 个哈希槽，如果示例仍在运行而没有 sleep 调用，那么它应该已经包含大量的键。</p>
<p>然后 redis-cli 需要知道重新分片的目标是什么，即接收哈希槽的节点。我将使用第一个主节点，即 127.0.0.1:7000，但我需要指定实例的节点 ID。这已经由 redis-cli 打印在列表中，但如果需要，我总能使用以下命令找到节点的 ID：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">$ redis-cli -p <span class="number">7000</span> cluster nodes | <span class="keyword">grep</span> myself</span><br><span class="line"><span class="number">97</span>a3a64667477371c4479320d683e4c8db5858b1 :<span class="number">0</span> myself,master - <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> connected <span class="number">0</span>-<span class="number">5460</span></span><br></pre></td></tr></table></figure>

<p>好的，所以我的目标节点是 97a3a64667477371c4479320d683e4c8db5858b1。</p>
<p>现在系统会询问您要从哪些节点获取这些密钥。我将只键入<code>all</code>以便从所有其他主节点获取一些哈希槽。</p>
<p>在最终确认之后，您会看到一条消息，显示每个插槽都会显示 redis-cli 将从一个节点移动到另一个节点，并且会为从一侧移动到另一侧的每个实际键打印一个点。</p>
<p>当重新分片正在进行时，您应该能够看到您的示例程序不受影响地运行。如果需要，您可以在重新分片期间多次停止并重新启动它。</p>
<p>在重新分片结束时，您可以使用以下命令测试集群的健康状况：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">redis-cli <span class="attr">--cluster</span> check <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">7000</span></span><br></pre></td></tr></table></figure>

<p>所有的槽都会像往常一样被覆盖，但是这次 127.0.0.1:7000 的 master 会有更多的哈希槽，大约有 6461 个。</p>
<p>重新分片可以自动执行，无需以交互方式手动输入参数。这可以使用如下命令行：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">redis-cli --cluster reshard <span class="tag">&lt;<span class="name">host</span>&gt;</span>:<span class="tag">&lt;<span class="name">port</span>&gt;</span> --cluster-from <span class="tag">&lt;<span class="name">node-id</span>&gt;</span> --cluster-to <span class="tag">&lt;<span class="name">node-id</span>&gt;</span> --cluster-slots <span class="tag">&lt;<span class="name">number</span> <span class="attr">of</span> <span class="attr">slots</span>&gt;</span> --cluster-yes</span><br></pre></td></tr></table></figure>

<p>如果您可能经常重新分片，这允许建立一些自动化，但是目前没有办法<code>redis-cli</code>自动重新平衡集群检查密钥在集群节点之间的分布并根据需要智能地移动插槽。将来会添加此功能。</p>
<p>该<code>--cluster-yes</code>选项指示集群管理器自动对命令的提示回答“是”，允许它以非交互模式运行。请注意，也可以通过设置 <code>REDISCLI_CLUSTER_YES</code>环境变量来激活此选项。</p>
<h4 id="一个更有趣的示例应用程序"><a href="#一个更有趣的示例应用程序" class="headerlink" title="一个更有趣的示例应用程序"></a>一个更有趣的示例应用程序</h4><p>我们早期编写的示例应用程序不是很好。它以一种简单的方式写入集群，甚至不检查写入的内容是否正确。</p>
<p>从我们的角度来看，接收写入的集群可以始终将密钥写入<code>foo</code>每个<code>42</code>操作，而我们根本不会注意到。</p>
<p>所以在<code>redis-rb-cluster</code>存储库中，有一个更有趣的应用程序，叫做<code>consistency-test.rb</code>. 它使用一组计数器，默认为 1000，并发送<a href="https://redis.io/commands/incr"><code>INCR</code></a> 命令以增加计数器。</p>
<p>然而，应用程序不只是编写，还做了两件额外的事情：</p>
<ul>
<li>当使用 更新计数器时<a href="https://redis.io/commands/incr"><code>INCR</code></a> ，应用程序会记住写入。</li>
<li>它还会在每次写入之前读取一个随机计数器，并检查该值是否符合我们的预期，并将其与内存中的值进行比较。</li>
</ul>
<p>这意味着这个应用程序是一个简单的 <strong>一致性检查器</strong> ，并且能够告诉您集群是否丢失了一些写入，或者它是否接受了我们没有收到确认的写入。在第一种情况下，我们会看到一个计数器的值小于我们记忆中的值，而在第二种情况下，该值会更大。</p>
<p>运行一致性测试应用程序每秒产生一行输出：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">ruby</span> <span class="string">consistency-test.rb</span></span><br><span class="line"><span class="number">925</span> <span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">925</span> <span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br><span class="line"><span class="number">5030 </span><span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">5030 </span><span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br><span class="line"><span class="number">9261 </span><span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">9261 </span><span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br><span class="line"><span class="number">13517</span> <span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">13517</span> <span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br><span class="line"><span class="number">17780</span> <span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">17780</span> <span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br><span class="line"><span class="number">22025</span> <span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">22025</span> <span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br><span class="line"><span class="number">25818</span> <span class="string">R</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span> <span class="number">25818</span> <span class="string">W</span> <span class="string">(0</span> <span class="string">err)</span>  <span class="string">|</span></span><br></pre></td></tr></table></figure>

<p>该行显示执行的读取和写入<strong>次数</strong> <strong>，</strong> 以及错误次数（由于系统不可用导致错误，查询未被接受）。</p>
<p>如果发现某些不一致，则会将新行添加到输出中。例如，如果我在程序运行时手动重置计数器，就会发生这种情况：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">redis-cli -h 127.0.0.1 -p 7000 <span class="built_in">set</span> key_217 0</span></span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">(in the other tab I see...) </span><br><span class="line"></span><br><span class="line">94774 R (0 err)  | 94774 W (0 err)  |</span><br><span class="line">98821 R (0 err)  | 98821 W (0 err)  |</span><br><span class="line">102886 R (0 err)  | 102886 W (0 err)  | 114 lost |</span><br><span class="line">107046 R (0 err)  | 107046 W (0 err)  | 114 lost |</span><br></pre></td></tr></table></figure>

<p>当我将计数器设置为 0 时，实际值为 114，因此程序报告 114 次丢失写入（<a href="https://redis.io/commands/incr"><code>INCR</code></a> 集群未记住的命令）。</p>
<p>这个程序作为测试用例更有趣，所以我们将用它来测试 Redis 集群故障转移。</p>
<h4 id="测试故障转移"><a href="#测试故障转移" class="headerlink" title="测试故障转移"></a>测试故障转移</h4><p>要触发故障转移，我们可以做的最简单的事情（这也是分布式系统中可能发生的语义上最简单的故障）是使单个进程崩溃，在我们的例子中是单个主进程。</p>
<p>笔记</p>
<p>在此测试期间，您应该在运行一致性测试应用程序的情况下打开一个选项卡。</p>
<p>我们可以识别一个 master 并使用以下命令使它崩溃：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">redis-cli</span> <span class="string">-p</span> <span class="number">7000 </span><span class="string">cluster</span> <span class="string">nodes</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">master</span></span><br><span class="line"><span class="string">3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7001</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385482984082</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">5960</span><span class="number">-10921</span></span><br><span class="line"><span class="string">2938205e12de373867bf38f1ca29d31d0ddb3e46</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7002</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385482983582</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">11423</span><span class="number">-16383</span></span><br><span class="line"><span class="string">97a3a64667477371c4479320d683e4c8db5858b1</span> <span class="string">:0</span> <span class="string">myself,master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">0</span><span class="number">-5959</span> <span class="number">10922</span><span class="number">-11422</span></span><br></pre></td></tr></table></figure>

<p>好的，所以 7000、7001 和 7002 是主人。<strong>让我们使用DEBUG SEGFAULT</strong>命令使节点 7002 崩溃 ：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">redis-cli</span> <span class="string">-p</span> <span class="number">7002 </span><span class="string">debug</span> <span class="string">segfault</span></span><br><span class="line"><span class="attr">Error:</span> <span class="string">Server</span> <span class="string">closed</span> <span class="string">the</span> <span class="string">connection</span></span><br></pre></td></tr></table></figure>

<p>现在我们可以查看一致性测试的输出，看看它报告了什么。</p>
<figure class="highlight python-repl"><table><tr><td class="code"><pre><span class="line">18849 R (0 err)  | 18849 W (0 err)  |</span><br><span class="line">23151 R (0 err)  | 23151 W (0 err)  |</span><br><span class="line">27302 R (0 err)  | 27302 W (0 err)  |</span><br><span class="line"></span><br><span class="line"><span class="meta prompt_">...</span> <span class="language-python">many error warnings here ...</span></span><br><span class="line"></span><br><span class="line">29659 R (578 err)  | 29660 W (577 err)  |</span><br><span class="line">33749 R (578 err)  | 33750 W (577 err)  |</span><br><span class="line">37918 R (578 err)  | 37919 W (577 err)  |</span><br><span class="line">42077 R (578 err)  | 42078 W (577 err)  |</span><br></pre></td></tr></table></figure>

<p>正如您在故障转移期间看到的那样，系统无法接受 578 次读取和 577 次写入，但是数据库中没有产生不一致。这听起来可能出乎意料，因为在本教程的第一部分中我们指出 Redis 集群在故障转移期间可能会丢失写入，因为它使用异步复制。我们没有说的是，这不太可能发生，因为 Redis 将回复发送到客户端，并将复制命令发送到副本，大约同时进行，因此丢失数据的窗口非常小。但是很难触发并不代表不可能，所以这并没有改变Redis集群提供的一致性保证。</p>
<p>我们现在可以检查故障转移后的集群设置是什么（请注意，与此同时我重新启动了崩溃的实例，以便它作为副本重新加入集群）：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">redis-cli</span> <span class="string">-p</span> <span class="number">7000 </span><span class="string">cluster</span> <span class="string">nodes</span></span><br><span class="line"><span class="string">3fc783611028b1707fd65345e763befb36454d73</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7004</span> <span class="string">slave</span> <span class="string">3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0</span> <span class="number">0</span> <span class="number">1385503418521</span> <span class="number">0</span> <span class="string">connected</span></span><br><span class="line"><span class="string">a211e242fc6b22a9427fed61285e85892fa04e08</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7003</span> <span class="string">slave</span> <span class="string">97a3a64667477371c4479320d683e4c8db5858b1</span> <span class="number">0</span> <span class="number">1385503419023</span> <span class="number">0</span> <span class="string">connected</span></span><br><span class="line"><span class="string">97a3a64667477371c4479320d683e4c8db5858b1</span> <span class="string">:0</span> <span class="string">myself,master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">0</span><span class="number">-5959</span> <span class="number">10922</span><span class="number">-11422</span></span><br><span class="line"><span class="string">3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7005</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385503419023</span> <span class="number">3</span> <span class="string">connected</span> <span class="number">11423</span><span class="number">-16383</span></span><br><span class="line"><span class="string">3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7001</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385503417005</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">5960</span><span class="number">-10921</span></span><br><span class="line"><span class="string">2938205e12de373867bf38f1ca29d31d0ddb3e46</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7002</span> <span class="string">slave</span> <span class="string">3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span> <span class="number">0</span> <span class="number">1385503418016</span> <span class="number">3</span> <span class="string">connected</span></span><br></pre></td></tr></table></figure>

<p>现在主服务器运行在端口 7000、7001 和 7005 上。以前的主服务器，即运行在端口 7002 上的 Redis 实例，现在是 7005 的副本。</p>
<p>该<a href="https://redis.io/commands/cluster-nodes"><code>CLUSTER NODES</code></a> 命令的输出可能看起来很吓人，但实际上非常简单，由以下标记组成：</p>
<ul>
<li>节点编号</li>
<li>ip:端口</li>
<li>标志：主人，副本，我自己，失败，……</li>
<li>如果是副本，则为主节点的节点 ID</li>
<li>上次挂起的 PING 仍在等待回复的时间。</li>
<li>最后一次收到 PONG 的时间。</li>
<li>此节点的配置纪元（请参阅集群规范）。</li>
<li>此节点的链接状态。</li>
<li>插槽服务…</li>
</ul>
<h4 id="手动故障转移"><a href="#手动故障转移" class="headerlink" title="手动故障转移"></a>手动故障转移</h4><p>有时，在不实际导致主服务器出现任何问题的情况下强制进行故障转移很有用。例如，要升级其中一个主节点的 Redis 进程，最好对其进行故障转移以将其转变为对可用性影响最小的副本。</p>
<p>Redis 集群使用<a href="https://redis.io/commands/cluster-failover"><code>CLUSTER FAILOVER</code></a>  命令支持手动故障转移，该命令必须在要进行故障转移的主服务器的副本之一中执行。</p>
<p>与实际主节点故障导致的故障转移相比，手动故障转移是特殊的并且更安全。它们以一种避免过程中数据丢失的方式发生，只有当系统确定新主服务器处理了旧主服务器的所有复制流时，才将客户端从原始主服务器切换到新主服务器。</p>
<p>这是您在执行手动故障转移时在副本日志中看到的内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Manual failover user request accepted.</span></span><br><span class="line"><span class="comment"># Received replication offset for paused master manual failover: 347540</span></span><br><span class="line"><span class="comment"># All master replication stream processed, manual failover can start.</span></span><br><span class="line"><span class="comment"># Start of election delayed for 0 milliseconds (rank #0, offset 347540) .</span></span><br><span class="line"><span class="comment"># Starting a failover election for epoch 7545.</span></span><br><span class="line"><span class="comment"># Failover election won: I&#x27;m the new master.</span></span><br></pre></td></tr></table></figure>

<p>基本上，连接到我们正在故障转移的主服务器的客户端已停止。同时，master 将其复制偏移量发送到副本，副本等待达到其一侧的偏移量。当达到复制偏移量时，故障转移开始，旧的主服务器被告知配置切换。当客户端在旧 master 上解除阻塞时，它们将被重定向到新 master。</p>
<p>笔记</p>
<p>要将副本提升为主副本，它必须首先被集群中的大多数主副本知道为副本。否则，它无法赢得故障转移选举。如果副本刚刚添加到集群（请参阅<a href="https://redis.io/docs/management/scaling/#add-a-new-node-as-a-replica">将新节点添加为副本</a> ），您可能需要等待一段时间才能发送<a href="https://redis.io/commands/cluster-failover"><code>CLUSTER FAILOVER</code></a> 命令，以确保集群中的主节点知道新副本。</p>
<h4 id="添加新节点"><a href="#添加新节点" class="headerlink" title="添加新节点"></a>添加新节点</h4><p>添加一个新节点基本上是添加一个空节点然后将一些数据移动到其中的过程，以防它是一个新的主节点，或者告诉它设置为一个已知节点的副本，以防它是一个副本。</p>
<p>我们将展示两者，从添加一个新的主实例开始。</p>
<p>在这两种情况下，执行的第一步都是 <strong>添加一个空节点</strong> 。</p>
<p>这就像在端口 7006 中启动一个新节点一样简单（我们已经为现有的 6 个节点使用了 7000 到 7005），除了端口号外，其他节点的配置相同，所以你应该按顺序做什么以符合我们用于先前节点的设置：</p>
<ul>
<li>在您的终端应用程序中创建一个新选项卡。</li>
<li>进入<code>cluster-test</code>目录。</li>
<li>创建一个名为<code>7006</code>.</li>
<li>在里面创建一个 redis.conf 文件，类似于用于其他节点的文件，但使用 7006 作为端口号。</li>
<li>最后启动服务器<code>../redis-server ./redis.conf</code></li>
</ul>
<p>此时服务器应该正在运行。</p>
<p>现在我们可以像往常一样使用<strong>redis-cli</strong>将节点添加到现有集群。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">redis-cli --cluster <span class="keyword">add</span>-node <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7006</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span></span><br></pre></td></tr></table></figure>

<p>如您所见，我使用了<strong>add-node</strong>命令，将新节点的地址指定为第一个参数，并将集群中随机现有节点的地址指定为第二个参数。</p>
<p>实际上，这里的 redis-cli 对我们帮助不大，它只是向<a href="https://redis.io/commands/cluster-meet"><code>CLUSTER MEET</code></a> 节点发送一条消息，这也可以手动完成。然而，redis-cli 也会在操作之前检查集群的状态，因此即使您知道内部工作原理，也始终通过 redis-cli 执行集群操作是个好主意。</p>
<p>现在我们可以连接到新节点，看看它是否真的加入了集群：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">redis</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7006&gt;</span> <span class="string">cluster</span> <span class="string">nodes</span></span><br><span class="line"><span class="string">3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7001</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385543178575</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">5960</span><span class="number">-10921</span></span><br><span class="line"><span class="string">3fc783611028b1707fd65345e763befb36454d73</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7004</span> <span class="string">slave</span> <span class="string">3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0</span> <span class="number">0</span> <span class="number">1385543179583</span> <span class="number">0</span> <span class="string">connected</span></span><br><span class="line"><span class="string">f093c80dde814da99c5cf72a7dd01590792b783b</span> <span class="string">:0</span> <span class="string">myself,master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="string">connected</span></span><br><span class="line"><span class="string">2938205e12de373867bf38f1ca29d31d0ddb3e46</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7002</span> <span class="string">slave</span> <span class="string">3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span> <span class="number">0</span> <span class="number">1385543178072</span> <span class="number">3</span> <span class="string">connected</span></span><br><span class="line"><span class="string">a211e242fc6b22a9427fed61285e85892fa04e08</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7003</span> <span class="string">slave</span> <span class="string">97a3a64667477371c4479320d683e4c8db5858b1</span> <span class="number">0</span> <span class="number">1385543178575</span> <span class="number">0</span> <span class="string">connected</span></span><br><span class="line"><span class="string">97a3a64667477371c4479320d683e4c8db5858b1</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7000</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385543179080</span> <span class="number">0</span> <span class="string">connected</span> <span class="number">0</span><span class="number">-5959</span> <span class="number">10922</span><span class="number">-11422</span></span><br><span class="line"><span class="string">3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7005</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1385543177568</span> <span class="number">3</span> <span class="string">connected</span> <span class="number">11423</span><span class="number">-16383</span></span><br></pre></td></tr></table></figure>

<p>请注意，由于此节点已经连接到集群，因此它已经能够正确重定向客户端查询，并且通常来说是集群的一部分。然而，与其他大师相比，它有两个特点：</p>
<ul>
<li>它没有数据，因为它没有分配的哈希槽。</li>
<li>因为它是没有分配slots的master，当replica要成为master时，它不参与选举过程。</li>
</ul>
<p>现在可以使用 的重新分片功能将哈希槽分配给该节点<code>redis-cli</code>。正如我们在上一节中所做的那样，显示它基本上是无用的，没有区别，它只是一个以空节点为目标的重新分片。</p>
<h5 id="添加一个新节点作为副本"><a href="#添加一个新节点作为副本" class="headerlink" title="添加一个新节点作为副本"></a>添加一个新节点作为副本</h5><p>可以通过两种方式添加新副本。显而易见的是再次使用 redis-cli，但使用 –cluster-slave 选项，如下所示：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">redis-cli --cluster <span class="keyword">add</span>-node <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7006</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span> --cluster-slave</span><br></pre></td></tr></table></figure>

<p>请注意，此处的命令行与我们用于添加新主控的命令行完全相同，因此我们没有指定要将副本添加到哪个主控。在这种情况下，redis-cli 会将新节点添加为副本较少的主节点中随机主节点的副本。</p>
<p>但是，您可以使用以下命令行准确指定新副本的目标主机：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">redis-cli --cluster <span class="keyword">add</span>-node <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7006</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">7000</span> --cluster-slave --cluster-master-id <span class="number">3</span>c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span><br></pre></td></tr></table></figure>

<p>这样我们就可以将新副本分配给特定的主服务器。</p>
<p>将副本添加到特定 master 的更手动的方法是将新节点添加为空 master，然后使用 <a href="https://redis.io/commands/cluster-replicate"><code>CLUSTER REPLICATE</code></a> 命令将其变成副本。如果节点被添加为副本但您希望将其移动为不同主节点的副本，这也适用。</p>
<p>例如，为了添加节点 127.0.0.1:7005 的副本，该节点当前服务于 11423-16383 范围内的哈希槽，其节点 ID 为 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e，我需要做的就是连接新节点（已经添加为空主）并发送命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis 127.0.0.1:7006&gt; cluster replicate 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span><br></pre></td></tr></table></figure>

<p>而已。现在我们有了这组哈希槽的新副本，集群中的所有其他节点都已经知道了（几秒钟后需要更新它们的配置）。我们可以通过以下命令来验证：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">$ redis-cli -p <span class="number">7000</span> cluster nodes | <span class="keyword">grep</span> slave | <span class="keyword">grep</span> <span class="number">3</span>c3a0c74aae0b56170ccb03a76b60cfe7dc1912e</span><br><span class="line">f093c80dde814da99c5cf72a7dd01590792b783b <span class="number">127.0</span>.<span class="number">0</span>.<span class="number">1</span>:<span class="number">7006</span> slave <span class="number">3</span>c3a0c74aae0b56170ccb03a76b60cfe7dc1912e <span class="number">0</span> <span class="number">1385543617702</span> <span class="number">3</span> connected</span><br><span class="line"><span class="number">2938205</span>e12de373867bf38f1ca29d31d0ddb3e46 <span class="number">127.0</span>.<span class="number">0</span>.<span class="number">1</span>:<span class="number">7002</span> slave <span class="number">3</span>c3a0c74aae0b56170ccb03a76b60cfe7dc1912e <span class="number">0</span> <span class="number">1385543617198</span> <span class="number">3</span> connected</span><br></pre></td></tr></table></figure>

<p>节点 3c3a0c… 现在有两个副本，分别运行在端口 7002（现有的）和 7006（新的）上。</p>
<h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><p>要删除副本节点，只需使用<code>del-node</code>redis-cli 命令：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">redis-cli <span class="attr">--cluster</span> <span class="selector-tag">del</span>-node <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">7000</span> `&lt;node-id&gt;`</span><br></pre></td></tr></table></figure>

<p>第一个参数只是集群中的随机节点，第二个参数是要删除的节点的 ID。</p>
<p>您也可以以相同的方式删除主节点， <strong>但是要删除主节点，它必须为空</strong> 。如果主节点不为空，则需要将数据从它重新分片到之前的所有其他主节点。</p>
<p>删除主节点的另一种方法是在其副本之一上对其执行手动故障转移，并在该节点变成新主节点的副本后删除该节点。显然，当您想减少集群中的实际主节点数量时，这无济于事，在这种情况下，需要重新分片。</p>
<h4 id="副本迁移"><a href="#副本迁移" class="headerlink" title="副本迁移"></a>副本迁移</h4><p>在 Redis 集群中，您可以随时使用以下命令重新配置副本以与不同的主服务器进行复制：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">CLUSTER REPLICATE <span class="tag">&lt;<span class="name">master-node-id</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>但是，有一种特殊情况，您希望副本自动从一个主服务器移动到另一个主服务器，而无需系统管理员的帮助。副本的自动重新配置称为 <em>副本迁移</em> ，能够提高 Redis 集群的可靠性。</p>
<p>笔记</p>
<p><a href="https://redis.io/topics/cluster-spec">您可以在Redis Cluster Specification</a> 中阅读副本迁移的详细信息，这里我们将仅提供一些有关一般概念的信息以及您应该如何做才能从中受益。</p>
<p>您可能希望让您的集群副本在特定条件下从一个主服务器移动到另一个主服务器的原因是，通常 Redis 集群对故障的抵抗力与附加到给定主服务器的副本数量一样多。</p>
<p>例如，如果主节点及其副本同时发生故障，那么每个主节点都有一个副本的集群将无法继续运行，这仅仅是因为没有其他实例可以拥有主节点所服务的哈希槽的副本。然而，虽然网络分裂可能同时隔离多个节点，但许多其他类型的故障，如单个节点本地的硬件或软件故障，是一类非常值得注意的故障，不太可能同时发生时间，因此在您的集群中，每个主节点都有一个副本，副本可能在凌晨 4 点被杀死，而主节点在早上 6 点被杀死。这仍然会导致集群无法再运行。</p>
<p>为了提高系统的可靠性，我们可以选择向每个 master 添加额外的副本，但这是昂贵的。副本迁移允许将更多的副本添加到几个主服务器。所以你有 10 个主节点，每个主节点有 1 个副本，总共有 20 个实例。但是，例如，您添加了 3 个以上的实例作为某些主实例的副本，因此某些主实例将拥有多个副本。</p>
<p>对于副本迁移，如果主服务器没有副本，则来自具有多个副本的主服务器的副本将迁移到<em>孤立</em>的主服务器。所以当你的副本像我们上面的例子那样在凌晨 4 点宕机后，另一个副本将取代它，当主服务器在凌晨 5 点也发生故障时，仍然有一个副本可以被选举出来，这样集群就可以继续运行操作。</p>
<p>那么简而言之，关于副本迁移，您应该知道些什么？</p>
<ul>
<li>集群将尝试从给定时刻拥有最多副本的主服务器迁移副本。</li>
<li>要从副本迁移中获益，您只需向集群中的单个主服务器添加更多副本，与哪个主服务器无关。</li>
<li>有一个配置参数控制副本迁移功能，称为<code>cluster-migration-barrier</code>：您可以在<code>redis.conf</code>Redis 集群提供的示例文件中阅读更多相关信息。</li>
</ul>
<h4 id="升级-Redis-集群中的节点"><a href="#升级-Redis-集群中的节点" class="headerlink" title="升级 Redis 集群中的节点"></a>升级 Redis 集群中的节点</h4><p>升级副本节点很容易，因为您只需要停止节点并使用更新版本的 Redis 重新启动它。如果有客户端使用副本节点缩放读取，则在给定副本不可用时，它们应该能够重新连接到不同的副本。</p>
<p>升级 masters 有点复杂，建议的过程是：</p>
<ol>
<li>用于<a href="https://redis.io/commands/cluster-failover"><code>CLUSTER FAILOVER</code></a> 触发主服务器到其副本之一的手动故障转移。（请参阅本主题中的<a href="https://redis.io/docs/management/scaling/#manual-failover">手动故障转移</a> 。）</li>
<li>等待主人变成副本。</li>
<li>最后像升级副本一样升级节点。</li>
<li>如果您希望主节点成为您刚刚升级的节点，请触发新的手动故障转移，以便将升级后的节点变回主节点。</li>
</ol>
<p>按照此过程，您应该一个接一个地升级节点，直到升级所有节点。</p>
<h4 id="迁移到-Redis-集群"><a href="#迁移到-Redis-集群" class="headerlink" title="迁移到 Redis 集群"></a>迁移到 Redis 集群</h4><p>愿意迁移到 Redis 集群的用户可能只有一个主节点，或者可能已经使用了预先存在的分片设置，其中密钥在 N 个节点之间拆分，使用一些内部算法或由他们的客户端库或 Redis 代理实现的分片算法。</p>
<p>在这两种情况下，都可以轻松迁移到 Redis 集群，但最重要的细节是应用程序是否使用多键操作，以及如何使用。存在三种不同的情况：</p>
<ol>
<li>不使用多键操作，或事务，或涉及多个键的 Lua 脚本。键是独立访问的（即使通过事务或 Lua 脚本将多个命令分组访问，关于同一个键，也是如此）。</li>
<li>多键操作，或事务，或涉及多个键的 Lua 脚本被使用，但仅与具有相同<strong>哈希标签</strong>的键一起使用，这意味着一起使用的键都有一个<code>&#123;...&#125;</code>恰好相同的子字符串。例如，在同一哈希标签的上下文中定义了以下多键操作：<code>SUNION &#123;user:1000&#125;.foo &#123;user:1000&#125;.bar</code>。</li>
<li>涉及多个键的多个键操作、事务或 Lua 脚本与没有显式或相同散列标签的键名一起使用。</li>
</ol>
<p>第三种情况 Redis Cluster 不处理：应用程序需要修改以便不使用多键操作或仅在同一哈希标签的上下文中使用它们。</p>
<p>案例 1 和案例 2 已涵盖，因此我们将重点关注以相同方式处理的这两种情况，因此文档中不会进行区分。</p>
<p>假设您将现有的数据集拆分为 N 个主节点，如果您没有预先存在的分片，则 N&#x3D;1，需要执行以下步骤才能将数据集迁移到 Redis 集群：</p>
<ol>
<li>阻止你的客户。目前无法自动实时迁移到 Redis 集群。您可以在您的应用程序&#x2F;环境的上下文中编排实时迁移。</li>
<li>使用命令为你所有的 N 个 master 生成一个 append only 文件<a href="https://redis.io/commands/bgrewriteaof"><code>BGREWRITEAOF</code></a> ，并等待 AOF 文件完全生成。</li>
<li>将你的 AOF 文件从 aof-1 保存到 aof-N 的某个地方。此时您可以根据需要停止旧实例（这很有用，因为在非虚拟化部署中您经常需要重用相同的计算机）。</li>
<li>创建一个由 N 个主节点和零个副本组成的 Redis 集群。您稍后将添加副本。确保您的所有节点都使用仅附加文件来实现持久性。</li>
<li>停止所有集群节点，将它们的仅附加文件替换为您预先存在的仅附加文件，第一个节点为 aof-1，第二个节点为 aof-2，直到 aof-N。</li>
<li>使用新的 AOF 文件重新启动 Redis 集群节点。他们会抱怨有些键根据他们的配置不应该存在。</li>
<li>使用<code>redis-cli --cluster fix</code>命令来修复集群，以便根据每个节点是否具有权威的哈希槽来迁移密钥。</li>
<li>在最后使用<code>redis-cli --cluster check</code>以确保您的集群正常。</li>
<li>重新启动修改为使用 Redis 集群感知客户端库的客户端。</li>
</ol>
<p>还有一种方法可以将数据从外部实例导入到 Redis 集群，那就是使用<code>redis-cli --cluster import</code>命令。</p>
<p>该命令将正在运行的实例的所有键（从源实例中删除键）移动到指定的预先存在的 Redis 集群。但是请注意，如果您使用 Redis 2.8 实例作为源实例，操作可能会很慢，因为 2.8 没有实现迁移连接缓存，因此您可能需要在执行此类操作之前使用 Redis 3.x 版本重新启动源实例。</p>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis高级数据结构</title>
    <url>/2021/04/26/database/Redis%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这篇文章介绍一下高级Redis数据结构，及其用法。</p>
<p>在工作的使用频率很高。</p>
<ul>
<li>分布式锁</li>
<li>队列</li>
<li>位图</li>
<li>布隆过滤器</li>
<li>HyperLogLog</li>
<li>限流器</li>
<li>GeoHash</li>
</ul>
<span id="more"></span>

<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>大家都知道，线程安全在我们的系统当中，非常重要。<br>如果多个线程同时操作一笔订单，很可能造成数据不一致。</p>
<p>而在分布式系统中，<code>synchronized</code>就排不上用场了，需要使用分布式锁来解决线程安全的问题。</p>
<p>而使用redis就是一个很好的选择。</p>
<p>使用<code>Redisson</code>封装的分布式锁，非常简单，功能也相当强大。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">lockTest</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> redisson.getLock(<span class="string">&quot;my-lock&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="comment">// do somethings</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>除了基础的分布式锁，Redisson还提供了：</p>
<ul>
<li>可重入锁</li>
<li>公平锁</li>
<li>自旋锁</li>
<li>读写锁</li>
<li>锁超时时间</li>
<li>获取锁的时间限制</li>
</ul>
<p>功能强大且使用方便，具体参考<a href="https://github.com/redisson/redisson/wiki/8.-distributed-locks-and-synchronizers">官方文档</a>。</p>
<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><p>队列是我们一种常用的数据结构。也有很多专业的中间件来实现。比如：Kafka，RabbitMQ，RocketMQ。。。<br>而redis也支持消息队列，而且功能还不少。有：</p>
<ul>
<li>简单的消息队列</li>
<li>延迟队列</li>
<li>阻塞队列</li>
<li>消息的多播</li>
</ul>
<p>Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用<code>rpush/lpush</code>操作入队列，使用 <code>lpop/rpop</code> 来出队列。</p>
<p>延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score。</p>
<p>Redisson对此都有很好的支持：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简单队列</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">simple</span><span class="params">()</span> &#123;</span><br><span class="line">    RQueue&lt;Object&gt; queue = redissonClient.getQueue(<span class="string">&quot;simple&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">            queue.add(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).start();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">poll</span> <span class="operator">=</span> queue.poll();</span><br><span class="line">        <span class="keyword">if</span> (poll == <span class="literal">null</span>) &#123;</span><br><span class="line">            i--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(poll);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 阻塞队列</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">blockQueue</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    RBlockingQueue&lt;Object&gt; queue = redissonClient.getBlockingQueue(<span class="string">&quot;block&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                queue.put(i);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).start();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">        <span class="comment">// 阻塞take</span></span><br><span class="line">        <span class="type">Object</span> <span class="variable">poll</span> <span class="operator">=</span> queue.take();</span><br><span class="line">        System.out.println(poll);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 延迟队列</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">delayQueue</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    RBlockingQueue&lt;Object&gt; blockingQueue = redissonClient.getBlockingQueue(<span class="string">&quot;delayQueue1&quot;</span>);</span><br><span class="line">    RDelayedQueue&lt;Object&gt; delayQueue = redissonClient</span><br><span class="line">            .getDelayedQueue(blockingQueue);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">        delayQueue.offerAsync(i, (<span class="number">500</span> - i * <span class="number">10</span>), TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    blockingQueue = redissonClient.getBlockingQueue(<span class="string">&quot;delayQueue&quot;</span>);</span><br><span class="line">    System.out.println(blockingQueue.size());</span><br><span class="line">    redissonClient.getDelayedQueue(blockingQueue);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; blockingQueue.size(); i++) &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">poll</span> <span class="operator">=</span> blockingQueue.take();</span><br><span class="line">        System.out.println(poll);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>以上都是消息队列的<code>生产者-消费者模式</code>，而消息队列的另外一种模式<code>订阅模式</code>，redis也能实现。</p>
<p>有两种数据结构支持。</p>
<ul>
<li>PubSub</li>
<li>Stream</li>
</ul>
<h2 id="位图"><a href="#位图" class="headerlink" title="位图"></a>位图</h2><p>位图完全是为了节约空间而设计的，我们可以把它想象成一个巨大的List，而里面只存放<code>1/0</code>。</p>
<p>比如记录一个用户一年的签到记录，我们可以用位图来记录，签到的就是<code>1</code>，未签到的是<code>0</code>。</p>
<p>使用方法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">RBitSet</span> <span class="variable">bitset</span> <span class="operator">=</span> redissonClient.getBitSet(<span class="string">&quot;bitset&quot;</span>);</span><br><span class="line">    bitset.set(<span class="number">0</span>, <span class="literal">true</span>);</span><br><span class="line">    System.out.println(bitset.get(<span class="number">0</span>));</span><br><span class="line">    System.out.println(bitset.get(<span class="number">1</span>));</span><br><span class="line">    System.out.println(bitset.incrementAndGetInteger(<span class="number">0</span>, <span class="number">1</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h2><p>我们如何判断一个ID是否在我们的系统里。我们有两种基本的方法来判断：</p>
<ul>
<li>我们把这个ID拿到数据查询一下就知道来</li>
<li>我们把所有的ID保存的一个Set里面，判断这个新的ID在不在这个Set里面</li>
</ul>
<p>但是上面两种方法有一个致命的缺陷：<br>就是在数据量特别大的时候，非常消耗性能，不管是对数据库的IO，还是保存所有的ID。</p>
<p>这个是有个非常精妙的算法 - <code>布隆过滤器</code>。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/HeAOem.png"></p>
<p>它的原理非常简单：<br>底层是一个位图，并且有若干种Hash算法。<br>在新增ID的时候，对每一个ID做多种Hash运算，并在位图中得到若干位置，把对应的位置变成<code>1</code>。<br>而判断一个ID是否在系统中，也对这个ID做同样的Hash运算，得到若干位置，判断位图中的对应位置是否都是<code>1</code>。<br>如果都是<code>1</code>的话，表示大概率可能存在于系统中，如果有一个<code>0</code>，表示肯定不在系统中。</p>
<p>Redisson也做了封装，使用非常方便。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> &#123;</span><br><span class="line">    RBloomFilter&lt;String&gt; bloom = redissonClient.getBloomFilter(<span class="string">&quot;bloom&quot;</span>);</span><br><span class="line">    bloom.tryInit(<span class="number">1000</span>, <span class="number">0.1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        bloom.add(<span class="string">&quot;user_id_&quot;</span> + i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">80</span>; i &lt; <span class="number">120</span>; i++) &#123;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">contains</span> <span class="operator">=</span> bloom.contains(<span class="string">&quot;user_id_&quot;</span> + i);</span><br><span class="line">        System.out.println(<span class="string">&quot;user_id_&quot;</span> + i + <span class="string">&quot;  -&gt;  &quot;</span> + contains);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog是一个很神奇的数据结构。</p>
<p>我们先来说两个概念： PV 和 UV。<br>PV：简单来说就是流量。只要有一次访问，不管是不是同一个人，就记一个流量。<br>UV：独立访客，单位时间内，一个新的访客，就算一个UV。</p>
<p>在我们的统计中，PV很好统计，来一次访问，PV值就往上加1，顶多需要保持一下自增的原子性。<br>而计算UV，在互联网领域中一个是一个难题。</p>
<p>通常来说我们计算一个网站一天的UV，我们需要把每一个访客的ID给记录下来，计算时去重。<br>这样就导致一个问题，如果访问量非常大，就非常的消耗存储空间。</p>
<p>这个时候，HyperLogLog就能派上用场了。</p>
<p>我们先看下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">compareTest</span><span class="params">()</span> &#123;</span><br><span class="line">    RHyperLogLog&lt;String&gt; today = redisson.getHyperLogLog(<span class="string">&quot;UV_&quot;</span> + LocalDate.now());</span><br><span class="line">    HashSet&lt;String&gt; set = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">    <span class="type">Random</span> <span class="variable">random</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">userId</span> <span class="operator">=</span> <span class="string">&quot;id_&quot;</span> + random.nextInt(<span class="number">500</span>);</span><br><span class="line">        today.add(userId);</span><br><span class="line">        set.add(userId);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">&quot;RHyperLogLog: &quot;</span> + today.count());</span><br><span class="line">    System.out.println(<span class="string">&quot;set count: &quot;</span> + set.size());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里使用的Set方法，和HyperLogLog，两个做一个比较。<br>从结果可以看出，两者的差距非常小，但是HyperLogLog并没有把每一个ID都记录下来，节约了大量存储空间。</p>
<p>HyperLogLog的原理相对复杂，具体可以参考这篇<a href="http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf">论文</a>。</p>
<p>这里我来介绍一下它的思想：<br>假设我们有两个网站，需要比较一下他们的UV，看哪个网站的访问率高。<br>假设访问用户的ID使用手机号码表示，如：1xxxxxxxxxx<br>我们不想把每个访客的手机号码都记录下来，因为太浪费存储空间了。<br>我们可以定一个规则，我们只记录当天客户中，手机尾号为<code>0</code>位数最高的手机号码。<br>比如说，第一个网站记录下来的手机号码是：18322333000，末尾有3个0，<br>而第二的网站记录下来的手机号码是：18623000000，末尾有6个0。<br>我们就可以判断出，第二的网站的访问的人数更多。<br>大家体会一下。</p>
<p>HyperLogLog还有一个重要的概念，就是合并。<br>我们可以把连续7天的UV，合并成这一周的UV，并保证准确性。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mergeTest</span><span class="params">()</span> &#123;</span><br><span class="line">    RHyperLogLog&lt;String&gt; today = redisson.getHyperLogLog(<span class="string">&quot;UV_&quot;</span> + LocalDate.now());</span><br><span class="line">    RHyperLogLog&lt;String&gt; nextDay = redisson.getHyperLogLog(<span class="string">&quot;UV_&quot;</span> + LocalDate.now().plusDays(<span class="number">1</span>));</span><br><span class="line">    HashSet&lt;String&gt; set = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">    <span class="type">Random</span> <span class="variable">random</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">userId</span> <span class="operator">=</span> <span class="string">&quot;id_&quot;</span> + random.nextInt(<span class="number">1000</span>);</span><br><span class="line">        today.add(userId);</span><br><span class="line">        set.add(userId);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">userId</span> <span class="operator">=</span> <span class="string">&quot;id_&quot;</span> + random.nextInt(<span class="number">2000</span>);</span><br><span class="line">        nextDay.add(userId);</span><br><span class="line">        set.add(userId);</span><br><span class="line">    &#125;</span><br><span class="line">    today.mergeWith(nextDay.getName());</span><br><span class="line">    System.out.println(<span class="string">&quot;RHyperLogLog: &quot;</span> + today.count());</span><br><span class="line">    System.out.println(<span class="string">&quot;set count: &quot;</span> + set.size());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="限流器"><a href="#限流器" class="headerlink" title="限流器"></a>限流器</h2><p>限流器在我们的生产中非常重要，也很常用。Redis也有封装好的限流器。<br>实现了分布式限流器的功能。<br>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="comment">// redisson用了zset来记录请求的信息，这样可以非常巧妙的通过比较score，也就是请求的时间戳，来判断当前请求距离上一个请求有没有超过一个令牌生产周期。</span></span><br><span class="line">    <span class="comment">// 如果超过了，则说明令牌桶中的令牌需要生产，之前用掉了多少个就生产多少个，而之前用掉了多少个令牌的信息也在zset中保存了。</span></span><br><span class="line">    <span class="type">RRateLimiter</span> <span class="variable">limiter</span> <span class="operator">=</span> redissonClient.getRateLimiter(<span class="string">&quot;limiter_1&quot;</span>);</span><br><span class="line">    <span class="comment">// 1号限流器， 每一秒 允许一个请求</span></span><br><span class="line">    limiter.trySetRate(RateType.PER_CLIENT, <span class="number">1</span>, <span class="number">1</span>, RateIntervalUnit.SECONDS);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">            <span class="comment">// 阻塞</span></span><br><span class="line"><span class="comment">//			limiter.acquire(1);</span></span><br><span class="line">            <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> limiter.tryAcquire(<span class="number">1</span>, <span class="number">100</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">            <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">                <span class="comment">// 快速失败</span></span><br><span class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">&quot; failed !&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + <span class="string">&quot; -&gt; &quot;</span> + LocalDateTime.now());</span><br><span class="line">            <span class="comment">// do something</span></span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">    Thread.sleep(<span class="number">12000</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Redisson真好用！</p>
</blockquote>
<h2 id="Geo"><a href="#Geo" class="headerlink" title="Geo"></a>Geo</h2><p>Redis也提供了Geo功能，可以很方便实现附近的人，两坐标之间的距离等功能。<br>它的原理是把经纬度坐标，做Hash，得到一个分数，用zset做存储。<br>Hash算法的原理，是把整个地球当作一个平面，并把这个平面切割成很多很多的小块，并对每个方块做编码。<br>如果两个点所在的方块越接近，表示这两个点越接近。 当然，有一点点误差。<br>使用方法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">    RGeo&lt;Object&gt; geo = redissonClient.getGeo(<span class="string">&quot;geo&quot;</span>);</span><br><span class="line">    <span class="type">GeoEntry</span> <span class="variable">juejin</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GeoEntry</span>(<span class="number">116.48105</span>, <span class="number">39.996794</span>, <span class="string">&quot;juejin&quot;</span>);</span><br><span class="line">    geo.add(juejin);</span><br><span class="line">    geo.add(<span class="number">116.514203</span>, <span class="number">39.905409</span>, <span class="string">&quot;ireader&quot;</span>);</span><br><span class="line">    geo.add(<span class="number">116.489033</span>, <span class="number">40.007669</span>, <span class="string">&quot;meituan&quot;</span>);</span><br><span class="line">    geo.add(<span class="number">116.562108</span>, <span class="number">39.787602</span>, <span class="string">&quot;jd&quot;</span>);</span><br><span class="line">    geo.add(<span class="number">116.334255</span>, <span class="number">40.027400</span>, <span class="string">&quot;xiaomi&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 两点距离</span></span><br><span class="line">    System.out.println(geo.dist(<span class="string">&quot;meituan&quot;</span>, <span class="string">&quot;jd&quot;</span>, GeoUnit.METERS));</span><br><span class="line">    <span class="comment">// 坐标</span></span><br><span class="line">    System.out.println(geo.pos(<span class="string">&quot;xiaomi&quot;</span>));</span><br><span class="line">    <span class="comment">// hash</span></span><br><span class="line">    System.out.println(geo.hash(<span class="string">&quot;ireader&quot;</span>));</span><br><span class="line">    <span class="comment">// 附近</span></span><br><span class="line">    System.out.println(geo.radiusWithPositionAsync(<span class="string">&quot;jd&quot;</span>, <span class="number">20</span>, GeoUnit.KILOMETERS).get());</span><br><span class="line">    <span class="comment">// 附近</span></span><br><span class="line">    System.out.println(</span><br><span class="line">            geo.radiusWithPositionAsync(<span class="number">116.334255</span>, <span class="number">40.027400</span>, <span class="number">20</span>, GeoUnit.KILOMETERS).get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意： 在一个地图应用中，车的数据、餐馆的数据、人的数据可能会有百万千万条，<br>如果使用Redis 的 Geo 数据结构，它们将全部放在一个 zset 集合中。<br>在 Redis 的集群环境中，集合可能会从一个节点迁移到另一个节点，如果单个 key 的数据过大，会对集群的迁移工作造成较大的影响，<br>在集群环境中单个 key 对应的数据量不宜超过 1M，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。<br>所以，这里建议 Geo 的数据使用单独的 Redis 实例部署，不使用集群环境。<br>如果数据量过亿甚至更大，就需要对 Geo 数据进行拆分，按国家拆分、按省拆分，按市拆分，在人口特大城市甚至可以按区拆分。<br>这样就可以显著降低单个 zset 集合的大小。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今天我们一起学习了7种高级结构</p>
<ul>
<li>分布式锁</li>
<li>队列</li>
<li>位图</li>
<li>布隆过滤器</li>
<li>HyperLogLog</li>
<li>限流器</li>
<li>GeoHash<br>希望以后大家能在工作中用到。</li>
</ul>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>redis</tag>
        <tag>redisson</tag>
      </tags>
  </entry>
  <entry>
    <title>DynamoDB</title>
    <url>/2022/06/07/database/Dynamo%20paper/</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Amazon 是世界上最大的电商之一。</p>
<p>在这里我们所遇到的最大挑战之一就是 <strong>超大规模下的稳定性问题</strong> （reliability at massive scale）。即使是最微小的故障（the slightest outage），也会造成巨大的经济 损失，而且会降低客户对我们的信任。Amazon.com 作为一个为全球提供 web 服务的平台， 其底层的基础设施是由分布在全球的数据中心中成千上万的服务器和网络设备组成的。在如 此庞大的规模下，大大小小的组件故障是不断在发生的，而我们应对这些故障时所采取 的 <strong>管理持久状态的方式</strong> （the way persistent state is managed）， <strong>驱动着软件系 统的可靠性（reliability）和可扩展性（scalability）的发展</strong> 。</p>
<p>本文介绍 Dynamo —— 一个<strong>高可用键值存储系统</strong> —— 的设计和实现。Amazon 的一些核心 服务就是基于 Dynamo 提供不间断服务的（always-on experience）。为了达到这种等级的 可用性（level of availability），Dynamo  <strong>牺牲了几种特定故障场景下的一致性</strong> 。另 外，Dynamo 大量使用了 <strong>对象版本化</strong> （object versioning）和<strong>应用协助的冲突解决</strong> （application-assisted conflict resolution）机制，给开发者提供了一种新颖的接口。</p>
<span id="more"></span> 

<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>Amazon 是一个全球电商平台，峰值用户达到几千万。支撑 Amazon 的是分布在全球的数据 中心中成千上万的服务器。Amazon 平台对<strong>性能、可靠性和效率</strong>等指标有着很高的要求 。而且，为了支撑持续增长（continous growth），平台需要有 <strong>高度的可扩展性</strong> 。 <strong>可 靠性是我们最重要的需求之一</strong> ，因为即使是最微小的故障也会造成巨大的经济损失，而且 会降低客户对我们的信任。</p>
<p>我们从打造 Amazon 平台的切身实践中总结出的一条经验是： <strong>一个系统的可靠性和可扩展 性取决于如何管理它的应用状态</strong> 。</p>
<blockquote>
<p>The reliability and scalability of a system is dependent on how its application state is managed.</p>
</blockquote>
<p>Amazon 使用的是高度去中心化的、松耦合的、面向服务的架构，由几百个服务组成。这样 的环境对 <strong>永远可用</strong> （always available）的存储技术有着强烈的需求。例如， <strong>即使磁 盘挂掉、路由抖动、甚至数据中心被飓风摧毁，用户应该仍然能向他们的购物车添加和查看 商品</strong> 。要实现这样的目标，管理购物车的系统就必须永远能读写它的 数据仓库，而且 数据仓库还要跨多个数据中心可用。</p>
<p>对于我们这种由几百万台设备组成的基础设施，故障是家常便饭；在任何时刻都会有 <strong>比例小 但数量不少</strong> （small but significant number）的服务器和网络设备发生故障。因此， Amazon 的软件系统要 <strong>将故障视为正常的、可预期的行为（treat failure handling as the normal case），不应因设备故障而影响可用性和性能</strong> 。</p>
<p>为了满足可靠性和可扩展性的需求，Amazon 开发了一些存储技术，S3 （Simple Storage Service）可能是最广为人知的一种。本文介绍 Amazon 的另一个存储产品 Dynamo —— 一个 高可用键值存储数据仓库（data store）—— 的设计和实现。</p>
<p>Dynamo 用于管理<strong>对可靠性要求非常高的服务</strong>的状态，这些服务还要求对可靠性、一致 性、成本-效率（cost-effectiveness）和性能有很强的控制能力。</p>
<blockquote>
<p>Dynamo is used to manage the state of services that have very high reliability requirements and need tight control over the tradeoffs between availability, consistency, cost-effectiveness and performance.</p>
</blockquote>
<p>Amazon 平台有很多类型的应用，不同的类型对存储的需求差异很大。例如，其中一类应用 希望能  <strong>数据仓库的配置足够灵活，以便在成本最经济的方式下，由开发者来决定如何 在可用性和性能之间取得折中</strong> 。</p>
<p>Amazon 的一些服务 <strong>只需以主键（primary key）的方式访问数据仓库</strong> 。对于很多服 务，例如畅销排行榜、购物车、客户喜好偏向、session 管理、销售排名、商品目录等等， 常见的关系型数据库会非常低效，而且限制了规模的扩展性和可用性。Dynamo 提供了只使 用主键（primary key only）的访问接口来满足这类应用的需求。</p>
<p><strong>Dynamo 基于一些业内熟知的技术实现了可扩展性和高可用性</strong> ：</p>
<ul>
<li>数据通过<strong>一致性哈希</strong>分散和复制（partitioned and replicated）[10]</li>
<li>通过 <strong>对象版本化</strong> （object versioning）实现一致性 [12]</li>
<li>副本之间的一致性由一种 <strong>类似仲裁的技术</strong> （quorum-like technique）和一个去中 心化的 <strong>副本同步协议</strong> （replica synchroni protocol）保证</li>
<li>gossip-based 分布式故障检测和成员检测（membership）协议</li>
</ul>
<p>Dynamo 是一个只需最少人工管理的、完全去中心化的系统。</p>
<blockquote>
<p>Dynamo is a completely decentralized system with minimal need for manual administration.</p>
</blockquote>
<p>向 Dynamo 添加或移除存储节点不需要人工 partition（调整哈希节点）或 redistribution（在节点之间重新平衡数据分布）。</p>
<p>Dynamo 在过去的几年已经成为 Amazon 很多核心服务的底层存储技术。在节假日购物高峰 ，它能实现不停服（平滑）扩容以支持极高的峰值负载。例如购物车服务的几千万请求会 产生单日 300 万次的付款动作，管理 session 状态的服务能处理几千万的并发活跃用户等 等。</p>
<p><strong>本文对该领域的主要贡献</strong> ：</p>
<ul>
<li>评估了如何通过组合不同技术实现一个高度可用的（highly-available）系统</li>
<li>证明了最终一致性存储系统可以用于生产环境，满足应用的高要求</li>
<li>展示了若干优化技术，以满足生产环境的非常严格的性能要求</li>
</ul>
<p>本文章节结构介绍（略，见下面全文）。</p>
<h2 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h2><p>Amazon 的电商平台由几百个服务组成，它们协同工作，提供的服务包罗万象，从推荐系统 到订单处理到欺诈检测等等。每个服务对外提供定义良好的 API，被其他服务通过网络的方 式访问。这些服务运行在分布在全球的数据中心中，成千上万的服务器组成的基础设施之上 。有些服务是无状态的（例如，聚合其他服务的响应的服务），有些是有状态的（例如，基 于存储在数据仓库里的状态，执行业务逻辑并产生响应的服务）。</p>
<p>传统上，生产系统使用关系型数据库来存储状态。但对很多<strong>持久状态的存储</strong>需求来说， 关系型数据库并不是一种理想的方式。</p>
<ul>
<li>这类服务大多数 <strong>&#x3D;只用主键去检索&#x3D;</strong> ，并不需要RDBMS 提供的复杂查询和管理功能。 这些额外的功能需要昂贵的硬件和专门的技能，而实际上服务根本用不到，最终的结果就是 使用关系型数据库非常不经济；</li>
<li>另外，关系型数据库的复制功能很受限，而且通常是靠 <strong>牺牲可用性来换一致性</strong> 。虽然 近些年有了一些改进，但总体来说水平扩展（scale-out）以及使用智能（smart） partitioning 来做负载均衡还是很不方便。</li>
</ul>
<p>本文介绍 Dynamo 是如何解决以上需求的。Dynamo 有易用的 key&#x2F;value 接口，高度可用 ，有定义清晰的一致性窗口（clearly defined consistency window），资源使用效率很高 ，并且有易用的水平扩展方案以解决请求量或数据增长带来的挑战。 <strong>每个使用 Dynamo 的 服务，使用的都是它们独立的一套 Dynamo 系统</strong> 。</p>
<blockquote>
<p>Each service that uses Dynamo runs its own Dynamo instances.</p>
</blockquote>
<h3 id="2-1-系统假设与需求"><a href="#2-1-系统假设与需求" class="headerlink" title="2.1 系统假设与需求"></a>2.1 系统假设与需求</h3><p>Dynamo 对使用它的服务有如下几点假设。</p>
<h4 id="查询模型（Query-Model）"><a href="#查询模型（Query-Model）" class="headerlink" title="查询模型（Query Model）"></a>查询模型（Query Model）</h4><p><strong>通过唯一的 key 对数据进行读写</strong> 。状态以 <strong>二进制对象</strong> （binary objects，e.g. blobs）形式存储，以唯一的 key 索引。</p>
<p><strong>任何操作都不会跨多个 data items</strong> （数据单元），没有关系型 schema 需求。</p>
<p>Dynamo 面向的应用 <strong>存储的都是相对较小的文件（一般小于 1 MB）</strong> 。</p>
<h4 id="ACID-特性"><a href="#ACID-特性" class="headerlink" title="ACID 特性"></a>ACID 特性</h4><p>ACID（Atomicity, Consistency, Isolation, Durability）是一组保证数据库事务可 靠执行的特性。在数据库领域，对数据的单次逻辑操作（single logical operation） 称为一次事务（transaction）。 我们在 Amazon 的实践表明，让数据仓库支持 ACID 会使得它的可用性（availability） 非常差，工业界和学术界也已经就这一点达成了广泛共识 [5]。</p>
<p><strong>Dynamo 的目标应用具有这样的特点：如果能给可用性（CAP 里面的 A）带来很大提升 ，那牺牲一些一致性（C）也是允许的</strong> 。</p>
<p>Dynamo 不提供任何隔离保证，并且只允许带单个 key 的更新操作（permit only single key updates）。</p>
<h4 id="效率（Efficiency）"><a href="#效率（Efficiency）" class="headerlink" title="效率（Efficiency）"></a>效率（Efficiency）</h4><p>系统需要运行在通用硬件（commodity hardware）之上。Amazon 的服务对延迟有着严格的 要求，通常用百分位值（percentile）<code>P99.9</code> 衡量。</p>
<p>考虑到对状态数据的访问是服务的核心操作之一，我们的存储系统必须满足那些严格的 SLA （见 Section 2.2）。另外，服务要有配置 Dynamo 的能力，以便能满足服务的延迟和吞吐 需求。最终，就是在性能、成本效率、可用性和持久性之间取得折中。</p>
<h4 id="其他方面"><a href="#其他方面" class="headerlink" title="其他方面"></a>其他方面</h4><p>Dynamo 定位是 Amazon 内部使用，因此我们假设环境是安全的，不需要考虑认证和鉴权 等安全方面的问题。</p>
<p>另外， <strong>由于设计中每个服务都使用各自的一套 Dynamo，因此 Dynamo 的初始设计规模是 几百个存储节点</strong> 。后面会讨论可扩展性限制的问题，以及可能的解决方式。</p>
<h3 id="2-2-SLA-Service-Level-Agreements"><a href="#2-2-SLA-Service-Level-Agreements" class="headerlink" title="2.2 SLA (Service Level Agreements)"></a>2.2 SLA (Service Level Agreements)</h3><p>要 <strong>保证一个应用完成请求所花的时间有一个上限</strong> （bounded time），它所依赖的那些服 务就要有一个更低的上限。 <strong>对于给定的系统特性</strong> ，其中最主要的是客户端期望的 <strong>请求 率分布</strong> （request rate distribution）， <strong>客户端和服务端会定义一个 SLA（服务级别 协议）</strong> 来作为契约。</p>
<p>举个简单例子：某个服务向客户端保证，在 500 QPS 的负载下，它处理 <code>99.9%</code> 的请求 所花的时间都在能 <code>300ms</code> 以内。</p>
<p>在 Amazon 的去中心化的、面向服务的基础设施中，SLA 扮演着重要角色。例如，对购物 页面的一次请求，在典型情况下会使渲染引擎向多达 150 个服务发送子请求，而这些子服 务又都有自己的依赖，最终形成一张多层的（more than one level）调用图（call graph ）。为了保证渲染引擎能在一个上限时间内返回一个页面，调用链中的所有服务就都必须遵 循各自的性能契约（contract）。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/5JEehw.png"></p>
<p>图 1 是一张简化之后的 Amazon 平台架构图。可以看到，动态 web 内容由页面渲染组件 提供，而它是通过调用其他的一些服务来完成这项工作的。</p>
<p><strong>每个服务可以选择不同类型的数据仓库（data store）来管理（存储）它们的状态数据， 这些数据仓库只能在各自的服务边界（service boundaries）内访问</strong> 。一些服务会通过聚 合其他服务的数据来组合产生一个响应（composite response）。典型情况下，聚合服务（ aggregator service）是无状态的，虽然它们大量使用缓存技术。</p>
<p>对于面向性能的 SLA（performance oriented SLA），业内一般习惯使用<strong>平均值、中位数 和方差</strong>来描述。但在 Amazon 我们发现，要打造一个让所有用户——而不是大部分用户——都 有良好体验的系统，以上 SLA 并不合适。例如， <strong>如果使用了个性化推荐技术，那用户的 访问历史越多，他的请求被处理的时间就越长，最终落到了性能分布的长尾区</strong> 。基于平均 值或中位数的 SLA 并不能反映这种情况。为了解决这个问题， <strong>我们使用了 <code>P99.9</code> 分布。<code>99.9%</code> 这个精度是经过大量实验分析，权衡了成本和性能之后得到的</strong> 。 我们在生产环境的实验显示，这比基于均值或中位数的 SLA 有更好的用户体验。</p>
<p>本文多处都将引用 P99.9 分布，这也显示了 Amazon 的工程师对提高用户体验所做的持续 不断的努力。一些基于均值的论文，我们会在它真正有意义的场景才拿出来作为比较，但我 们自己的工程和优化都不是以<strong>均值 SLA</strong> 为核心的。某些技术，例如 write coordinator（写操作协调者），是完全面向 P99.9 来控制性能的。</p>
<p><strong>存储系统在构建一个服务的 SLA 中经常扮演着重要角色，尤其是业务逻辑相对轻量的 场景</strong> ，Amazon 的服务即属于这一类。因此，<strong>状态管理</strong> 就成了服务的  <strong>SLA 的主要 部分</strong> 。</p>
<p><strong>Dynamo 的设计目标之一就是：允许服务自己控制自己的系统特性</strong> ——例如持久性和一 致性—— <strong>让服务自己决定如何在功能、性能和成本效率之间取得折中</strong> 。</p>
<blockquote>
<p>One of the main design considerations for Dynamo is to give services control over their system properties, such as durability and consistency, and to let services make their own tradeoffs between functionality, performance and cost-effectiveness.</p>
</blockquote>
<h3 id="2-3-设计考虑"><a href="#2-3-设计考虑" class="headerlink" title="2.3 设计考虑"></a>2.3 设计考虑</h3><p><strong>商业系统中数据复制算法一般都是同步的，以提供一个强一致性的数据访问接口。 为了达到这种级别的一致性，这些算法被迫牺牲了某些故障场景下的数据可用性</strong> 。例如， 如果数据有冲突，它们会禁止访问这个数据，直到数据的不一致完全得到了解决。在早期，这 种 <strong>复制式数据库</strong> （replicated database）是可以工作的。</p>
<p>但众所周知，分布式系统是无法同时满足 <strong>强一致性、高可用性和正确处理网络故障（CAP ）</strong> 这几个条件的 [2, 11]。 <strong>因此，系统和应用都需要知道，在什么场景下选择满足什么 特性</strong> 。</p>
<p>对于 <strong>服务器和网络故障较高的场景</strong> ，可以通过 <strong>乐观复制</strong> （optimistic replication ）技术增强 <strong>可用性</strong> ，在后台将数据变动同步到其他节点，并发更新和失联也是可以容忍 的。这种方式的问题是会 <strong>导致数据冲突，需要检测并解决冲突</strong> 。而解决数据冲突又会带 来两个额外问题：</p>
<ul>
<li>何时解决？</li>
<li>谁来解决？</li>
</ul>
<p><strong>Dynamo 设计为最终一致数据仓库</strong> （eventually consistent data store），即，最终 所有的更新会应用到所有的副本。</p>
<h4 id="何时解决冲突？"><a href="#何时解决冲突？" class="headerlink" title="何时解决冲突？"></a>何时解决冲突？</h4><p>设计时的一个重要考虑是： <strong>何时解决更新冲突</strong> ，例如，是读的时候还是写的时候。</p>
<blockquote>
<p>An important design consideration is to decide when to perform the process of resolving update conflicts, i.e., whether conflicts should be resolved during reads or writes.</p>
</blockquote>
<p>一些传统的数据仓库是在 <strong>写的时候解决冲突</strong> ，这样可以<strong>保证读的复杂度很低</strong> [7]。 在这种系统中，任何时候 <strong>如果数据仓库不能访问所有（或者大多数）副本，写就会被拒绝</strong> 。</p>
<p>Dynamo 的设计与此相反，它的目标是提供一个 <strong>“永远可写”（always writable）</strong> 的数据 仓库（例如，一个对写操作高度可用的数据仓库）。对很多 Amazon 服务来说，拒绝写 入会造成很差的用户体验。比如即使发生服务器或网络故障，也应该允许用户往购物车添 加或删除商品。 <strong>这个需求使我们将解决冲突的复杂度放到了读操作，以保证写永远不会 被拒绝</strong> 。</p>
<h4 id="谁来解决冲突？"><a href="#谁来解决冲突？" class="headerlink" title="谁来解决冲突？"></a>谁来解决冲突？</h4><p>下一个需要考虑的问题是： <strong>谁来解决冲突</strong> 。<strong>数据仓库</strong>和<strong>应用</strong>都可以做这件事情。</p>
<ul>
<li><strong>如果由数据仓库来做，那选择会相当受限</strong> 。在这种情况下，数据仓库只能使用一些 非常简单的策略，例如 <strong>“最后一次写有效”</strong> （last write wins） [22]，来解决更新冲突。</li>
<li>另一方面，由于 <strong>应用理解数据描述的是什么</strong> （application is aware of the data schema）， <strong>它可以自主选择对用户体验最好的冲突解决算法</strong> 。例如，购物车应用可 以选择“合并”冲突的版本，返回一个合并后的（unified）购物车。尽管这样可以带来很 大的灵活性，但一些应用开发者并不想自己实现一套冲突解决机制，因此在这种情况下 ，解决冲突的问题就下放给了数据仓库，由后者来选择一些简单的策略，例如 “last write wins”。</li>
</ul>
<h4 id="其他设计原则"><a href="#其他设计原则" class="headerlink" title="其他设计原则"></a>其他设计原则</h4><ul>
<li><strong>增量扩展性</strong> （Incremental scalability）：应当支持 <strong>逐机器（节点）扩容</strong> ，而 且对系统及运维人员带来的影响尽量小</li>
<li><strong>对称性</strong> （Symmetry）： <strong>每个节点的职责应该是相同的</strong> ，不应当出现某些节点承担 特殊职责或特殊角色的情况。以我们的实践经验，<strong>对称性简化了系统的交付和运维</strong></li>
<li><strong>去中心化</strong> （Decentralization）： <strong>“去中心化”是“对称性”的进一步扩展</strong> ，系统应 该是去中心化的、点对点的，而不应该是集中式控制的。在过去，集中式控制导致了很多 服务故障（outage），我们应当极力避免它。去中心化会使得系统更简单、更具扩展性和 可用性</li>
<li><strong>异构性</strong> （Heterogeneity）：系统要能够利用到基础设施的异构性。例如， <strong>负载的 分布要和存储节点的能力成比例</strong> 。对于逐步加入能力更强的新节点，而不是一次升级所 有节点来说，这种异构支持能力是不可或缺的</li>
</ul>
<h2 id="3-相关工作"><a href="#3-相关工作" class="headerlink" title="3. 相关工作"></a>3. 相关工作</h2><h3 id="3-1-点对点系统（Peer-to-Peer-Systems）"><a href="#3-1-点对点系统（Peer-to-Peer-Systems）" class="headerlink" title="3.1 点对点系统（Peer to Peer Systems）"></a>3.1 点对点系统（Peer to Peer Systems）</h3><p>一些点对点（peer-to-peer, P2P）系统关注了 <strong>数据存储和分散</strong> （data storage and distribution）的问题。</p>
<h4 id="P2P-系统"><a href="#P2P-系统" class="headerlink" title="P2P 系统"></a>P2P 系统</h4><p>第一代 P2P 系统，例如 Freenet 和 Gnutella，在文件共享系统（file sharing system） 领域使用广泛。它们都是<strong>非受信（untrusted）P2P 网络</strong>的代表，节点之间的 overlay （网络术语，和 underlay 对应，请参考 Wikipedia 或其他资料，译者注）链路都是随机 （随意）建立的（established arbitrarily）。在这种网络中，一次查询请求通常是 <strong>泛 洪（flood）到整张网络，找到尽量多的共享这个数据的节点</strong> 。</p>
<h4 id="结构化-P2P-系统"><a href="#结构化-P2P-系统" class="headerlink" title="结构化 P2P 系统"></a>结构化 P2P 系统</h4><p>P2P 网络到下一代，就是有名的 <strong>结构化 P2P 网络</strong> （structured P2P network）。这种 网络使用了全局一致性协议（globally consistent protocol），保证 <strong>任何一个节点可以 高效地将查询请求路由到存储这个数据的节点</strong> 。</p>
<p>Pastry [16] 和 Chord [20] 这样的系统 <strong>利用路由机制可以保证查询在若干（有上限） 跳</strong> （a bounded number of hops）之内收到应答。</p>
<p>为了减少多跳（multi-hop）路由带来的额外延迟，一些 P2P 系统（例如 [14]）使用了  <strong><code>O(1)</code>路由机制</strong> ，在这种机制中， <strong>每个节点维护了足够多的路由信息</strong> ，因此它可以 将（访问数据的）请求在常量跳数（constant number of hops）内路由到合适的对端节点 。</p>
<p>包括 Oceanstore [9] 和 PAST [17] 在内的很多存储系统都是构建在这种路由（routing） overlay 之上的。Oceanstore 提供全球分布的、事务型的、持久的存储服务，支持分布在 很大地理范围内的副本的串行化更新（serialized updates on widely replicated data） 。 <strong>为了支持并发更新，同时避免广域锁</strong> （wide-are locking）内在的一些问题，它使用了一 种基于冲突解决（conflict resolution）的更新模型。conflict resolution 在 [21] 中 提出，用于减少事务异常中止（transaction abort）的数量。 <strong>Oceanstore 处理冲突的方式是 ：对并发更新进行排序（order），将排好序的若干个更新作为原子操作应用到所有副本</strong> 。 Oceanstore 是为在<strong>不受信的基础设施上做数据复制的场景</strong>设计的。</p>
<p>作为对比，PAST 是在 Pastry 之上提供了一个简单的抽象层，以此来提供持久和 <strong>不可变对 象</strong> （persistent and immutable objects）。它假设 <strong>应用可以在它之上构建自己需要的 存储语义</strong> （storage semantics）（例如可变文件）。</p>
<h3 id="3-2-分布式文件系统与数据库"><a href="#3-2-分布式文件系统与数据库" class="headerlink" title="3.2 分布式文件系统与数据库"></a>3.2 分布式文件系统与数据库</h3><p>文件系统和数据库系统领域已经对<strong>通过分散数据（distributing data）来提高性能、可 用性和持久性</strong>进行了广泛研究。和  <strong>P2P 存储系统只支持扁平命名空间</strong> （flat namespace）相比， <strong>典型的分布式文件系统都支持层级化的命名空间</strong> （hierarchical namespace）。</p>
<ul>
<li>Ficus [5] 和 Coda [19] 这样的系统通过文件复制来提高可用性，代价是牺牲一致性。 解决更新冲突一般都有各自特殊的解决方式</li>
<li>Farsite [1] 是一不使用中心式服务器（例如 NFS）的分布式文件系统，它通过复制实现 高可用和高扩展</li>
<li><strong>Google File System</strong> [6] 是另一个分布式文件系统，用于存储 Google 内部应用的 状态数据。GFS 的设计很简单，一个主节点（master）管理所有元数据，数据进行分片（ chunk），存储到不同数据节点（chunkservers）。</li>
<li>Bayou 是一个分布式关系型数据库系统，允许在失联情况下进行操作（disconnected operation），提供最终一致性</li>
</ul>
<p>在这些系统中，Bayou、Coda 和 Ficus 都支持失联情况下进行操作，因此对网络分裂和宕 机都有很强的弹性，它们的不同之处在于如何解决冲突。例如，Coda 和 Ficus 在系统层面 解决（system level conflict resolution），而 Bayou 是在应用层面（application level）。相同的是，它们都提供最终一致性。与这些系统类似， <strong>Dynamo 允许在网络发生 分裂的情况下继续执行读写操作，然后通过不同的冲突解决机制来处理更新冲突</strong> 。</p>
<p>分布式块存储系统（distributed block storage system），例如 FAB [18]，将一个大块 分割成很多小块并以很高的可用性的方式存储。和这类系统相比， <strong>我们的场景更适合使用键 值存储</strong> ，原因包括：</p>
<ul>
<li>系统定位是 <strong>存储相对较小的文件</strong> （ <code>size &lt; 1 MB</code>）</li>
<li><strong>键值存储</strong> （key-value store）更容易在应用级别 <strong>针对单个应用</strong> （per-application）进行配置</li>
</ul>
<p>Antiquity 是一个广域分布式文件系统，设计用于处理多个服务器挂掉的情况 [23]。它使 用 <strong>安全日志</strong> （secure log）保证数据完整性，在不同服务器之间复制 secure log 来保 证持久性（durability），使用 <strong>拜占庭容错协议</strong> （Byzantine fault tolerance protocols）保证数据一致性。与此不同， <strong>Dynamo 并不将数据完整性和安全性作为主要关 注点，因为我们面向的是受信环境</strong> 。</p>
<p><strong>Bigtable 是一个管理结构化数据</strong> （structured data）的分布式文件系统，它维护了一 张稀疏的多维有序映射表（sparse, multi-dimensional sorted map），允许应用通过多重 属性访问它们的数据（access their data using multiple attributes） [2]。与此不同 ，<strong>Dynamo 面向的应用都是以 key&#x2F;value 方式访问数据的，我们的主要关注点是高可用</strong> ，即使在发生网络分裂或服务器宕机的情况下，写请求也是不会被拒绝的。</p>
<p>传统的复制型关系数据库系统（replicated relational database systems）都将关注点放 在 <strong>保证副本的强一致性</strong> 。虽然强一致性可以 <strong>给应用的写操作提供方便的编程模型</strong> ， 但导致系统的扩展性和可用性非常受限 [7]，无法处理网络分裂的情况。</p>
<h3 id="3-3-讨论"><a href="#3-3-讨论" class="headerlink" title="3.3 讨论"></a>3.3 讨论</h3><p>Dynamo 面临的需求使得它与前面提到的集中式存储系统都不相同。</p>
<p>首先，Dynamo 针对的主要是 <strong>需要“永远可写的”（always writable）数据仓库的应用</strong> ， 即使发生故障或并发更新，写也不应该被拒绝。对于 Amazon 的很多应用来说，这一点是非 常关键的。</p>
<p>第二，Dynamo 构建在<strong>受信的、单一管理域的基础设施</strong>之上。</p>
<p>第三，使用 Dynamo 的应用 <strong>没有层级命名空间（hierarchical namespace）的需求</strong> （这是很 多文件系统的标配），也没有复杂的关系型 schema 的需求（很多传统数据库都支持）。</p>
<p>第四，Dynamo 是为 <strong>延迟敏感型应用</strong> （latency sensitive application）设计的，至少 <code>99.9%</code> 的读写操作都要在几百毫秒内完成。为了到达如此严格的响应要求，在多节点 之间对请求进行路由的方式（被很多分布式哈希表系统使用，例如 Chord 和 Pastry ）就无法使用了。因为多跳路由会增加响应时间的抖动性，因此会增加长尾部分的延迟。 Dynamo 可以被描述为：一个 <strong>零跳（zero hop）分布式哈希表（DHT）</strong> ，每个节点在本地 维护了足够多的路由信息，能够将请求直接路由到合适节点。</p>
<h2 id="4-系统架构"><a href="#4-系统架构" class="headerlink" title="4. 系统架构"></a>4. 系统架构</h2><p>生产级别的存储系统的架构是很复杂的。除了最终存储数据的组件之外，系统还要针对下列 方面制定可扩展和健壮的解决方案：负载均衡、成员管理（membership）、故障检测、故障 恢复、副本同步、过载处理（overload handling）、状态转移、并发和任务调度、请求 marshalling、请求路由（routing）、系统监控和告警，以及配置管理。</p>
<p>详细描述以上提到的每一方面显然是不可能的，因此本文将关注下面几项 Dynamo 用到的分 布式系统核心技术：</p>
<ul>
<li>partitioning（分区，经哈希决定将数据存储到哪个&#x2F;些节点）</li>
<li>复制（replication）</li>
<li>版本化（versioning）</li>
<li>成员管理（membership）</li>
<li>故障处理（failure handling）</li>
<li>规模扩展（scaling）</li>
</ul>
<p>表 1 总结了 Dynamo 使用的这些技术及每项技术的好处。</p>
<p>表 1 Dynamo 用到的技术及其好处</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/W1XVlo.png"></p>
<h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><ul>
<li>技术：<strong>一致性哈希</strong></li>
<li>好处：增量可扩展性</li>
</ul>
<h4 id="写高可用"><a href="#写高可用" class="headerlink" title="写高可用"></a>写高可用</h4><ul>
<li>技术：读时协调（解决冲突）的 <strong>向量时钟</strong> （vector clocks with reconciliation during reads）</li>
<li>好处：version size（？）和更新频率（update rates）解耦</li>
</ul>
<h4 id="短时故障处理"><a href="#短时故障处理" class="headerlink" title="短时故障处理"></a>短时故障处理</h4><ul>
<li>技术： <strong>宽松的选举和 hinted handoff</strong> （移交给其他节点处理，附带提示信息）</li>
<li>好处：部分副本不可用时，仍然可以提供高可用性和持久性</li>
</ul>
<h4 id="持久（permanent）故障恢复"><a href="#持久（permanent）故障恢复" class="headerlink" title="持久（permanent）故障恢复"></a>持久（permanent）故障恢复</h4><ul>
<li>技术： <strong>基于 Merkle tree 的逆熵</strong> （anti-entropy）</li>
<li>好处：后台同步版本不一致的副本</li>
</ul>
<h4 id="成员管理和故障检测"><a href="#成员管理和故障检测" class="headerlink" title="成员管理和故障检测"></a>成员管理和故障检测</h4><ul>
<li>技术：<strong>基于 Gossip 的成员管理协议和故障检测</strong></li>
<li>好处：保持了 <strong>架构的对称性</strong> ，无需一个中心组件（centralized registry）来存储成员和节点状态等信息</li>
</ul>
<h3 id="4-1-系统接口"><a href="#4-1-系统接口" class="headerlink" title="4.1 系统接口"></a>4.1 系统接口</h3><p>Dynamo 存储键值对象的接口非常简单，它提供两个操作：</p>
<ul>
<li><code>get()</code></li>
<li><code>put()</code></li>
</ul>
<p><code>get(key)</code> 会定位到存储系统中 <code>key</code> 对应的所有对象副本，<strong>返回对象</strong> ——可能是单个对 象，也可能是一个对象列表（有冲突情况下，包括了所有版本）——  <strong>以及一个 <code>context</code>（ 上下文）</strong> 。</p>
<p><code>put(key)</code> 确定对象应该存放的位置，然后写到相应的磁盘。</p>
<p><code>context</code> 包含了系统中对象的元数据，例如对象的版本， <strong>对调用方是不透明的</strong> （ opaque）。 <strong>上下文信息是和对象存储在一起的</strong> ，这样系统很 <strong>容易验证 <code>put</code> 请求的 <code>context</code> 是否合法</strong> 。</p>
<p>Dynamo  <strong>将调用方提供的 key 和对象都视为不透明的字节序列</strong> （opaque array of bytes） 。它 <strong>对 key 应用 MD5 哈希得到一个 128bit 的 ID，并根据这个 ID 计算应该存储 到哪些节点</strong> 。</p>
<blockquote>
<p>Dynamo treats both the key and the object supplied by the caller as an opaque array of bytes. It applies a MD5 hash on the key to generate a 128-bit identifier, which is used to determine the storage nodes that are responsible for serving the key.</p>
</blockquote>
<h3 id="4-2-数据分散（Partitioning）算法"><a href="#4-2-数据分散（Partitioning）算法" class="headerlink" title="4.2 数据分散（Partitioning）算法"></a>4.2 数据分散（Partitioning）算法</h3><p>Dynamo 的核心需求之一是：系统必须支持 <strong>增量扩展</strong> （scale incrementally）。 这就要求有一种机制能够将数据分散到系统中的不同的节点（例如，以一台机器作为一个 节点的维度）上。</p>
<p>Dynamo 的<strong>分散方案基于一致性哈希</strong> [10]。在一致性哈希中，哈希函数的 <strong>输出是一个 固定的范围，通常作为一个循环空间，或称环（ring）</strong> 。 <strong>每个节点都会随 机分配一个在这个循环空间内的值</strong> ，这个值代表了节点在这个环上的位置。</p>
<p>用如下方式找到一个数据项（data item）对应的存储节点：</p>
<ol>
<li>首先对它的 key 做哈希得到一个哈希值</li>
<li>然后，在环上沿着顺时针方向找到第一个 <strong>所带的值比这个哈希值更大的节点</strong> （前面 提到每个节点都会被分配一个值）</li>
</ol>
<p>即，每个节点要负责环上从它自己到它的下一个节点之间的区域。<strong>一致性哈希的主要好处是 ：添加或删除节点只会影响相邻的节点，其他节点不受影响。</strong></p>
<blockquote>
<p>The principle advantage of consistent hashing is that departure or arrival of a node only affects its immediate neighbors and other nodes remain unaffected.</p>
</blockquote>
<p>但是， <strong>初级的一致性哈希算法在这里是有一些问题的</strong> 。 首先，给每个节点随机分配一个位置会导致数据和负载的非均匀分布。 其次，初级的一致性哈希算法没有考虑到节点的异构因素，导致性能不理想。</p>
<p>为了解决这些问题，Dynamo 使用了一致性哈希的一个变种（和 [10, 20] 的类似）： <strong>每个 节点并不是映射到环上的一个点，而是多个点</strong> 。</p>
<blockquote>
<p>Intead of mapping a node to a single point in the circle, each node gets assigned to multiple points in the ring.</p>
</blockquote>
<p>为了实现这种设计，Dynamo 使用了 <strong>虚拟节点</strong> （virtual node）的概念。一个虚拟节点 看上去和一个普通节点一样，但 <strong>实际上可能管理不止一台虚拟节点</strong> 。具体来说，  <strong>当一个新节点添加到系统后，它会在环上被分配多个位置（对应多个 token）</strong> 。 我们会在 Section 6 介绍 Dynamo 分散策略（算法）的深入调优 。</p>
<p><strong>虚拟节点可以代来如下好处</strong> ：</p>
<ol>
<li>当一个节点不可用时（故障或例行维护），这个节点的负载会均匀分散到其他可用节点上</li>
<li>当一个节点重新可用时，或新加入一个节点时，这个节点会获得与其他节点大致相同的 负载</li>
<li>一个节点负责的虚拟节点的数量可用根据节点容量来决定，这样可用充分利用物理基础 设施中的异构性信息</li>
</ol>
<h3 id="4-3-数据复制（Replication）"><a href="#4-3-数据复制（Replication）" class="headerlink" title="4.3 数据复制（Replication）"></a>4.3 数据复制（Replication）</h3><p>为了实现高可用性和持久性，Dynamo 将数据复制到多台机器上。每个数据会被复制到 N 台 机器，这里的 N 是每套 Dynamo 可以自己配置的。</p>
<p>上节介绍到， <strong>每个 key <code>k</code>，会被分配一个 coordinator（协调者）</strong> 节点。 coordinator  <strong>负责落到它管理的范围内的数据的复制</strong> 。它除了自己存储一份之外，还会 在环上顺时针方向的其他 <code>N-1</code> 个节点存储一份副本。因此在系统中，每个节点要负责从 它自己往后的一共 N 个节点。</p>
<p>例如，图 2 中，B 除了自己存储一份之外，还会将其复制到 C 和 D 节点。因此，D 实际 存储的数据，其 key 的范围包括 <code>(A, B]</code>、<code>(B, C]</code> 和 <code>(C, D]</code>（例如，落在 <code>(A, B]</code> 范围内的 key 会沿顺时针方向找到第一个值比它大的节点，因此找到的是 B，而 B 会 将自己存储的数据复制到 C 和 D，因此 D 会包含 key 在 <code>(A, B]</code> 范围内的对象。其他 几个范围也是类似的。译者注）。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/YJoSj8.png"></p>
<p>图 2 Dynamo 哈希环上 key 的分散（partition）和复制（replication）</p>
<p>存储某个特定 key 的所有节点组成一个列表，称为  <strong>preference list</strong> （优先列表）。 我们在 4.8 节会看到，Dynamo 的设计是， <strong>对于给定的 key，每个节点都能决定哪些 节点可以进入这个列表</strong> 。 <strong>为了应对节点失败的情况，preference list 会包含多余 N 个节 点</strong> 。</p>
<p>另外注意，由于我们引入了虚拟节点，存储一个 key 的 N 个节点，实际上对应的物理节 点可能少于 N 个（例如，一个节点可能会占用环上的不止一个节点）。为了避免这个问题 ， <strong>preference list 在选择节点的时候会跳过一些位置，以保证 list 里面的节点都在不 同的物理节点上</strong> 。</p>
<h3 id="4-4-数据版本化（Data-Versioning）"><a href="#4-4-数据版本化（Data-Versioning）" class="headerlink" title="4.4 数据版本化（Data Versioning）"></a>4.4 数据版本化（Data Versioning）</h3><p>Dynamo 提供最终一致性，所有更新操作会异步地传递给所有的副本。</p>
<p><code>put()</code> 操作返回时，数据（更新）可能还没有应用到所有副本，因此紧接着的 <code>get()</code> 操作可能获取不到最新数据。在没有故障的情况下，传递更新的耗时有一个上限；但在特定 故障场景下（例如服务器宕机或网络分裂），更新可能会在限定的时间内无法传递到所有副 本。</p>
<p>Amazon 有些应用是可以容忍这种不一致性的，应用在这种情况下能继续运行。例如，购物 车应用要求“添加到购物车”的请求永远不能被丢失或拒绝。如果购物车的最新状态不可用， 而用户对一个稍老版本的购物车状态做了修改，那这种修改也是有意义的，需要保留；但它 不能直接覆盖最新的状态，因为最新的状态中可能也有一些修改需要保留。这里要注意，不 管是“添加到购物车”还是“从购物车删除”，在系统中转换成的都是 Dynamo 的 <code>put()</code> 操作 。如果最新的状态不可用，而用户又基于稍的大版本做了修改，那这两个版本都需要保留， 由随后的步骤来处理更新冲突。</p>
<h4 id="如何解决更新冲突"><a href="#如何解决更新冲突" class="headerlink" title="如何解决更新冲突"></a>如何解决更新冲突</h4><p>为了满足以上需求，Dynamo  <strong>将每次修改结果都作为一个新的、不可变的版本</strong> 。</p>
<blockquote>
<p>Dynamo treats the result of each modification as a new and immutable version of the data.</p>
</blockquote>
<p>即，允许系统中同时存在多个不同版本。</p>
<h5 id="冲突调和（使一致化）方式"><a href="#冲突调和（使一致化）方式" class="headerlink" title="冲突调和（使一致化）方式"></a>冲突调和（使一致化）方式</h5><ul>
<li>syntactic reconciliation（ <strong>基于句法的调和</strong> ）</li>
<li>semantic reconciliation（ <strong>基于语义的调和</strong> ）</li>
</ul>
<p>在<strong>大部分情况下，新版本都包含老版本的数据，而且系统自己可以判断哪个是权威版本</strong> （syntactic reconciliation）。</p>
<p>但是，在发生故障并且存在并发更新的场景下，版本会发生分叉（version branching）， 导致冲突的对象版本。 <strong>系统本身无法处理这种情况，需要客户端介入，将多个分支合并成 一个</strong> （semantic reconciliation）。一个典型的例子是：合并多个不同版本的购物车。 有了这种调和机制（reconciliation mechanism），“添加到购物车”操作就永远不会失败 ；但是，这种情况会导致 <strong>已经删除的商品偶尔又在购物车中冒出来</strong> （resurface）。</p>
<p>有很重要的一点需要注意：某些故障模式（failure mode）会导致存在多个冲突的版本，而 不仅仅是两个。服务器故障或网络分裂会导致一个对象有多个版本，每个版本有各自的子历 史（version sub-histories），随后要由系统来将它们一致化。这需要<strong>将应用 设计为：显式承认多版本存在的可能性（以避免丢失任何更新）</strong></p>
<h5 id="向量时钟"><a href="#向量时钟" class="headerlink" title="向量时钟"></a>向量时钟</h5><p><strong>Dynamo 使用向量时钟（vector clock）[12] 来跟踪同一对象不同版本之间的因果性</strong> 。 一个向量时钟就是一个 <code>(node, counter)</code> 列表。一个向量时钟关联了一个对象的所有版 本，可以通过它来判断对象的两个版本是否在并行的分支上，或者它们是否有因果关系。  <strong>如果对象的第一个时钟上的所有 counter 都小于它的第二个时钟上的 counter，那第一个 时钟就是第二的祖先，可以安全的删除；否则，这两个修改就是有冲突的，需要 reconciliation</strong> 。</p>
<p>在 Dynamo 中， <strong>客户端更新一个对象时，必须指明基于哪个版本进行更新</strong> 。流程是先执 行读操作，拿到 context，其中包含了 vector clock 信息，然后写的时候带上这个 context。</p>
<p>在处理读请求的时候，如果 Dynamo 能够访问到多个版本，并且无法 reconcile 这些版本 ，那它就会返回所有版本，并在 context 中附带各自的 vector clock 信息。  <strong>基于 context 指定版本更新的方式解决了冲突</strong> ，将多个分支重新合并为一个唯 一的新分支。</p>
<blockquote>
<p>An update using this context is considered to have reconciled the divergent versions and the branches are collapsed into a single new version.</p>
</blockquote>
<h4 id="一个具体例子"><a href="#一个具体例子" class="headerlink" title="一个具体例子"></a>一个具体例子</h4><p>我们通过 图 3 来展示 vector clock 是如何工作的。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/OA86UT.png"></p>
<p>图 3 一个对象在一段时间内的版本演进</p>
<p>首先，客户端写入一个对象。处理这个 key 的写请求的节点 <code>Sx</code> 增加 key 的序列号（计 数），并用这个序列号创建对象的 vector clock。至此，系统有了一个对象 <code>D1</code> 和它的 时钟 <code>[(Sx, 1)]</code>。</p>
<p>第二步，客户端更新这个对象。假设还是 <code>Sx</code> 处理这个请求。此时，系统有了对象 <code>D2</code> 和它的时钟 <code>[(Sx, 2)]</code>。<code>D2</code> 是 <code>D1</code> 的后代，因此可以覆盖 <code>D1</code>； <strong>但是，<code>D1</code> 在 其他节点上的副本可能还没有看到 <code>D2</code> 这次更新</strong> 。</p>
<p>第三步，假设还是这个客户端，再次更新了对象，并且这次是由另外的一个节点 <code>Sy</code> 处理 请求。此时，系统有了 <code>D3</code> 和它的时钟 <code>[(Sx, 2), (Sy, 1)]</code>.</p>
<p>接下来，假设另一个客户端读取 <code>D2</code>，并尝试更新它，写请求由另一个节点 <code>Sz</code> 处理。 现在，系统有 <code>D4</code>（<code>D2</code> 的后代），版本 clock 是 <code>[(Sx, 2), (Sz, 1)]</code>。如果一个节 点知道 <code>D1</code> 和 <code>D2</code>，那它收到 <code>D4</code> 和它的 clock 后，就可以断定 <code>D1</code> 和 <code>D2</code> 被同 一个新数据覆盖了，因此可以安全地删除 D1 和 D2。但如果一个节点只知道 <code>D3</code>，那它受 到 <code>D4</code> 后就看不出这两个版本有何因果关系。 <strong>换言之，<code>D3</code> 和 <code>D4</code> 各自的改动并没 有反映在对方之中。因此这两个版本都应当被保留，然后交给客户端，由客户端（在下一次 读到时候）执行 semantic reconciliation</strong> 。</p>
<p>现在，假设一些客户端把 <code>D3</code> 和 <code>D4</code> 都读到了（<code>context</code> 会同时显示 <code>D3</code> 和 <code>D4</code> ）。读操作返回的 <code>context</code> 综合了 <code>D3</code> 和 <code>D4</code> 的 clock，即 <code>[(Sx, 2), (Sy, 1), (Sz, 1)]</code>。如果客户端执行 reconciliation，并且节点 <code>Sx</code> 执行协调写（coordinates the write），<code>Sx</code> 会更新自己在 clock 中的序列号。最终新生成的数据 <code>D5</code> 的 clock 格式如下：<code>[(Sx, 3), (Sy, 1), (Sz, 1)]</code>。</p>
<h4 id="Vector-clock-的潜在问题"><a href="#Vector-clock-的潜在问题" class="headerlink" title="Vector clock 的潜在问题"></a>Vector clock 的潜在问题</h4><p>vector clock 的一个潜在问题是： <strong>如果有多个节点先后 coordinate 同一个对象 的写操作，那这个对象的 clock vector 会变得很长</strong> 。但在实际中这不太可能发生，因为 写操作 coordination 只会由 preference list 中前 N 个 节点中的一个来执行。 只有在网络分裂或多台服务器挂掉的情况下，写操作才可能由非 preference list 前 N 个 节点来执行，导致 vector clock 变长。在这种情况下，应该要限制 vector clock 的长度 。</p>
<p>Dynamo 采用了一种 clock 截断方案（clock truncation scheme）： 另外保存一个和 <code>(node, counter)</code> 对应的时间戳，记录对应的节点最后一次更新该记录 的时间。当 vector clock 里的 <code>(node, counter)</code> 数量达到一个阈值（例如，10）时， 就删除最老的一项。</p>
<p>显然，这种截断方案会给 reconciliation 带来一定问题，因为截断后可能无法精确判断部 分后代的因果关系。但到目前为止，我们还没有在生产环境遇到这个问题，因此没有继续深 入研究下去。</p>
<h3 id="4-5-get-和-put-的执行过程"><a href="#4-5-get-和-put-的执行过程" class="headerlink" title="4.5 get() 和 put() 的执行过程"></a>4.5 <code>get()</code> 和 <code>put()</code> 的执行过程</h3><p><strong>在 Dynamo 中，任何存储节点都可以接受任何 key 的 <code>get</code> 和 <code>put</code> 操作请求</strong> 。</p>
<blockquote>
<p>Any storage node in Dynamo is eligible to receive client get and put operations for any key.</p>
</blockquote>
<p>本节先介绍在无故障场景下这些操作是如何执行的，下一节介绍有故障的场景。</p>
<p><code>get</code> 和 <code>put</code> 操作由 Amazon 基础设施相关的请求处理框架发起，使用 HTTP。 客户端有两种选择：</p>
<ol>
<li>将请求路由到负载均衡器，由后者根据负载信息选择一个后端节点</li>
<li>使用能感知 partition 的客户端，直接将请求路由到某 coordinator 节点</li>
</ol>
<p>第一种方式的好处是使用客户端的应用不需要了解任何 Dynamo 相关的代码，第二种的好处 是延迟更低，因为跳过了一次潜在的转发步骤。</p>
<p><strong>负责处理读或写请求的节点称为 coordinator</strong> 。 <strong>通常情况下</strong> ，这是 preference list 内前 N 个节点中的 <strong>第一个节点</strong> 。如果请求是经过负载均衡器转发的，那这个请求 可能会被转发到环上的任意一个节点。在这种情况下，如果收到请求的节点不是 preference list 的 前 N 个节点中的一个，那它就不会处理这个请求，而是将其转发到 preference list 前 N 个节点中的第一个节点。</p>
<p><strong>读或写操作需要 preference list 中前 N 个节点处于健康状态</strong> ，如果有 down 或不可 访问状态的节点，要跳过。如果所有节点都是健康的，那就取 preference list 的前 N 个 节点。如果发生节点故障或网络分裂，优先访问 preference list 中编号较小的节点。</p>
<h4 id="读写操作仲裁算法"><a href="#读写操作仲裁算法" class="headerlink" title="读写操作仲裁算法"></a>读写操作仲裁算法</h4><p>为了保证副本的一致性，Dynamo 使用了一种类似仲裁系统（quorum systems）的一致性协议。 这个协议有两个配置参数：<code>R</code> 和 <code>W</code>：</p>
<ul>
<li><code>R</code>：允许执行一次读操作所需的最少投票者</li>
<li><code>W</code>：允许执行一次写操作所需的最少投票者</li>
</ul>
<p><strong>设置 <code>R + W &gt; N</code></strong> （<code>R</code> 或 <code>W</code> 至少有一个超过半数 N&#x2F;2，译者注）， <strong>就得到了一 个类似仲裁的系统</strong> 。</p>
<p>在这种模型下，一次 <code>get</code> （或 <code>put</code>）的延迟由 <code>R</code>（或 <code>W</code>）个 <strong>副本中最慢的一个决 定</strong> 。因此，为了降低延迟，<code>R</code> 和 <code>W</code> 通常设置的比 <code>N</code> 小。</p>
<h4 id="写和读过程"><a href="#写和读过程" class="headerlink" title="写和读过程"></a>写和读过程</h4><p>当收到一个 <code>put()</code> 请求后，coordinator 会为新版本生成 vector clock，并将其保存到 节点本地；然后，将新版本（及对应的新 vector clock）发送给 N 个排在最前面的、可到 达的节点。只要有至少 <code>W-1</code> 个节点返回成功，这次写操作就认为是成功了。</p>
<p>类似地，对于一次 <code>get()</code> 请求，coordinator 会向排在最前面的 N 个（highest-ranked ）可访问的节点请求这个 key 对应的数据的版本，等到 R 个响应之后，就将结果返回给客 户端。如果 coordinator 收集到了多个版本，它会 <strong>将所有它认为没有因果关系的版本返 回给客户端</strong> 。客户端需要对版本进行 reconcile，合并成一个最新版本，然后将结果写回 Dynamo。</p>
<h3 id="4-6-短时故障处理-Hinted-Handoff（移交给其他节点临时保存）"><a href="#4-6-短时故障处理-Hinted-Handoff（移交给其他节点临时保存）" class="headerlink" title="4.6 短时故障处理: Hinted Handoff（移交给其他节点临时保存）"></a>4.6 短时故障处理: Hinted Handoff（移交给其他节点临时保存）</h3><p>如果使用传统仲裁算法，Dynamo 无法在服务器宕机或网络分裂的时候仍然保持可用，而且 在遇到最简单故障情况下，持久性（durability）也会降低。</p>
<p>因此，Dynamo 采用了一种 <strong>宽松的仲裁机制</strong> （sloppy quorum）： <strong>所有读和写操作在 preference list 的前 N 个健康节点上执行</strong> ；注意这 N 个节点不一定就是前 N 个节点， 因为遇到不健康的节点，会沿着一致性哈希环的顺时针方向顺延。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/N5pDVS.png"></p>
<p>图 2 Dynamo 哈希环上 key 的分散（partition）和复制（replication）</p>
<p>以图 2 的配置为例，其中 N&#x3D;3。 <strong>如果 A 临时不可用，正常情况下应该到达 A 的写请求就 会发送到 D</strong> 。这样设计是为了保证期望达到的可用性和持久性。 <strong>发送到 D 的副本的元 数据中会提示（hint）这个副本本来应该发送给谁</strong> （这里是 A），然后这个数据会被 D 保存到本地的一个独立数据库中，并且有一个 <strong>定期任务不断扫描，一旦 A 可用了，就将 这个数据发送回 A</strong> ，然后 D 就可以从本地数据库中将其删除了，这样系统内的副本数还 是保持不变。</p>
<p>使用这种 hinted handoff 的方式，Dynamo  <strong>保证了在节点或网络发生短时故障时读和写 操作不会失败</strong> 。希望可用性最高的应用可以将 <code>W</code> 设为 1，这样可以保证只要一个节点 完成写，这次写操作就被系统接受了。在这种情况下，除非全部节点都不可用，否则写操作 就不会被拒绝。但实际上，大部分 Amazon 的应用都是设置一个比 1 大的值，以达到期望 的持久性（durability）等级。我们会在第 6 节更深入地讨论 <code>N</code>、<code>R</code> 和 <code>W</code> 的配置。</p>
<p><strong>高度可用的存储系统必须能够处理整个数据中心挂掉的情况。</strong> 掉电、制冷失效、网络故 障以及自然灾难都会导致整个数据中心发生故障。Dynamo 可以配置 <strong>向多个数据中心同步 副本</strong> ，只要 <strong>将 preference list 里的节点分散到不同数据中心</strong> 。这些数据中心之间 通过高速网络互连。这使得我们可以在整个数据中心挂掉的情况下仍然可以提供服务。</p>
<h3 id="4-7-持久（permanent）故障处理-副本跨数据中心同步"><a href="#4-7-持久（permanent）故障处理-副本跨数据中心同步" class="headerlink" title="4.7 持久（permanent）故障处理: 副本跨数据中心同步"></a>4.7 持久（permanent）故障处理: 副本跨数据中心同步</h3><p>在节点成员变动较小、节点故障只是短时的情况下，hinted handoff 方式工作良好。但也 有一些场景，在 hinted 副本移交给原本应该存储这个副本的节点之前，该副本就不可用了 。为了解决这个问题，以及其他威胁到持久性（durability）的场景，Dynamo 实现了一种 <strong>逆熵（副本同步）协议</strong>来 <strong>保证副本是同步的</strong> 。</p>
<blockquote>
<p>To handle this and other threats to durability, Dynamo implements an anti-entropy (replica synchronization) protocol to keep the replicas synchronized.</p>
</blockquote>
<h4 id="Merkle-Tree"><a href="#Merkle-Tree" class="headerlink" title="Merkle Tree"></a>Merkle Tree</h4><p>为了实现 <strong>快速检测副本之间的不一致性，以及最小化转移的数据量</strong> ，Dynamo 使用了 Merkle trees [13].</p>
<p>一个 Merkle tree 就是一个 <strong>哈希树</strong> ，其叶子节点是  <strong>key 对应的 value 的哈希值</strong> 。  <strong>父节点是其子节点的哈希</strong> 。</p>
<p>Merkle tree 的主要优点是：</p>
<ul>
<li>每个分支都可以独立查看（check），节点无需下载整棵树或者整个数据集</li>
<li>减少检查副本一致性时所需传输的数据量</li>
</ul>
<p><strong>例如，如果两棵树的根节点的哈希值相同，那这两棵树的叶子节点必然相同，这两台 node 之间就无需任何同步</strong> ；否则，就说明两台 node 之间的某些副本是不同的，这种情 况下两台 node 就需要交换树的子节点哈希值，直到到达叶子节点，就找到了未同步（out of sync）的 key。Merkle tree 最小化了同步时需要转移的数据量， <strong>减少了逆熵过程中 读取磁盘的次数</strong> 。</p>
<p>Dynamo 使用 Merkle tree 实现<strong>逆熵的过程</strong>如下： <strong>每个节点为每段 key range（一台 虚拟节点所覆盖的 key 的范围）维护了一棵单独的 Merkle tree</strong> 。</p>
<p>这使得节点之间可以比较 key range，确定其维护的 range 内的 key 是否是最新的（up to date）。在这种方案中，两个节点会交换他们都有的 key range 所对应的 Merkle tree 的 根节点。然后，基于前面提到的树遍历方式， node 可以判断是是否有不一致，如果有，就 执行同步。</p>
<p>这种方案的缺点是： <strong>每当有节点加入或离开系统时，一些 key range 会变，因此对应的 tree 需要重新计算</strong> 。我们会在 6.2 节介绍如何通过改进的 partitioning scheme 解决 这个问题。</p>
<h3 id="4-8-节点成员（Membership）管理和故障检测"><a href="#4-8-节点成员（Membership）管理和故障检测" class="headerlink" title="4.8 节点成员（Membership）管理和故障检测"></a>4.8 节点成员（Membership）管理和故障检测</h3><h4 id="4-8-1-哈希环（ring）成员"><a href="#4-8-1-哈希环（ring）成员" class="headerlink" title="4.8.1 哈希环（ring）成员"></a>4.8.1 哈希环（ring）成员</h4><p>在 Amazon 的环境中，节点服务不可用（故障或维护导致的）通常情况下持续时间都很短， 但也存在中断比较长的情况。一个节点服务中断并不能说明这个节点永久性的离开了系统， 因此不应该导致系统对 partition 进行再平衡（rebalance），或者修复无法访问的副本。 与此类似，无意的手动操作可能导致新的节点加入到 Dynamo。</p>
<p>因此，为了避免以上这些问题，我们决定 <strong>使用显式机制（explicit mechanism）来向 Dynamo Ring 增删节点</strong> 。管理员通过命令行或 web 方式连接到 Dynamo node，然后下发 一个成员变更命令，来将这个 node 添加到 ring 或从 ring 删除。负责处理这个请求的 node 将成员变动信息和对应的时间写入持久存储。成员变动会形成历史记录，因为一个节 点可能会多次从系统中添加和删除。Dynamo  <strong>使用一个 gossip-based 的算法通告（ propagete）成员变动信息</strong> ，维护成员的一份最终一致视图。</p>
<p>每个节点每秒会随机选择另一个节点作为对端，这两个节点会高效地 reconcile 它们的成 员变动历史。</p>
<p><strong>一个节点第一次起来时，首先会选择它的 token 集合</strong> （一致性哈希空间内的虚拟节点 ），然后 <strong>将节点映射到各自的 token 集合</strong> 。</p>
<blockquote>
<p>When a node starts for the first time, it chooses its set of tokens (virtual nodes in the consistent hash space) and maps nodes to their respective token sets.</p>
</blockquote>
<p><strong>映射关系会持久存储到磁盘上</strong> ，初始时只包含本节点（local node）和 token set。存 储在不同 Dynamo 节点上的 <strong>映射关系，会在节点交换成员变动历史时被 reconcile</strong> 。因 此，partitioning 和 placement（数据的放置信息）也会通过 gossip 协议进行扩散， <strong>最 终每个节点都能知道其他节点负责的 token 范围</strong> 。</p>
<blockquote>
<p>The mappings stored at different Dynamo nodes are reconciled during the same communication exchange that reconciles the membership change histories.</p>
<p>Therefore, partitioning and placement information also propagates via the gossip-based protocol and each storage node is aware of the token ranges handled by its peers.</p>
</blockquote>
<p>这<strong>使得每个节点可以将一个 key 的读&#x2F;写操作直接发送给正确的节点</strong>进行处理。</p>
<h4 id="4-8-2-系统外部发现（External-Discovery）和种子节点"><a href="#4-8-2-系统外部发现（External-Discovery）和种子节点" class="headerlink" title="4.8.2 系统外部发现（External Discovery）和种子节点"></a>4.8.2 系统外部发现（External Discovery）和种子节点</h4><p>以上机制 <strong>可能导致 Dynamo ring 在逻辑上临时分裂</strong> 。</p>
<p>例如，管理员先联系 node A，将 A 将入 ring，然后又联系 node B 加入 ring。在这种情 况下，A 和 B 都会认为它们自己是 ring 的成员，但不会立即感知到对方。</p>
<p><strong>为了避免逻辑分裂，我们会将一些 Dynamo 节点作为种子节点</strong> 。种子节点是通过外部机 制（external mechanism）发现的，所有节点都知道种子节点的存在。因为所有节点最终都 会和种子节点 reconcile 成员信息，所以逻辑分裂就几乎不可能发生了。</p>
<p>种子或者从静态配置文件中获取，或者从一个配置中心获取。通常情况下，种子节点具有普 通节点的全部功能。</p>
<h4 id="4-8-3-故障检测"><a href="#4-8-3-故障检测" class="headerlink" title="4.8.3 故障检测"></a>4.8.3 故障检测</h4><p>故障检测在 Dynamo 中用于如下场景下跳过不可达的节点：</p>
<ul>
<li><code>get()</code> 和 <code>put()</code> 操作时</li>
<li>转移 partition 和 hinted replica 时</li>
</ul>
<p>要避免尝试与不可达节点通信，一个<strong>纯本地概念（pure local notion）的故障检测</strong>就 足够了：节点 B 只要没有应答节点 A 的消息，A 就可以认为 B 不可达（即使 B 可以应答 C 的消息）。</p>
<p>在客户端有持续频率的请求的情况下，Dynamo ring 的节点之间就会有持续的交互；因此只 要 B 无法应答消息，A 可以很快就可以发现；在这种情况下，A 可以选择和与 B 同属一个 partition 的其他节点来处理请求，并定期地检查 B 是否活过来了。</p>
<p><strong>在没有持续的客户端请求的情况下，两个节点都不需要知道另一方是否可达。</strong></p>
<blockquote>
<p>In the absence of client requests to drive traffic between two nodes, neither node really needs to know whether the other is reachable and responsive.</p>
</blockquote>
<p><strong>去中心化故障检测协议使用简单的 gossip 风格协议，使得系统内的每个节点都可以感知 到其他节点的加入或离开</strong> 。想详细了解去中心化故障检测机制及其配置，可以参考 [8]。</p>
<p>Dynamo 的早期设计中使用了一个去中心化的故障检测器来维护故障状态的全局一致视图 （globally consistent view of failure state）。</p>
<p>后来我们发现，我们<strong>显式的节点加入和离开机制</strong>使得这种全局一致视图变得多余了。因 为节点的真正（permanent）加入和离开消息，依靠的是我们的显式添加和删除节点机制， 而临时的加入和离开，由于节点之间的互相通信（转发请求时），它们自己就会发现。</p>
<h3 id="4-9-添加-x2F-移除存储节点"><a href="#4-9-添加-x2F-移除存储节点" class="headerlink" title="4.9 添加&#x2F;移除存储节点"></a>4.9 添加&#x2F;移除存储节点</h3><p>当一个新节点 <code>X</code> 加入到系统后，它会 <strong>获得一些随机分散在 ring 上的 token</strong> 。对每 个分配给 <code>X</code> 的 key range，当前可能已经有一些（小于等于 <code>N</code> 个）节点在负责处理了 。因此,将 key range 分配给 <code>X</code> 后，这些节点就不需要处理这些 key 对应的请求了，而 要将 keys 转给 <code>X</code>。</p>
<p>考虑一个简单的情况：<code>X</code> 加入 图 2 中 <code>A</code> 和 <code>B</code> 之间。这样，<code>X</code> 就负责处理落到 <code>(F, G], (G, A] and (A, X]</code> 之间的 key。结果，<code>B</code>、<code>C</code> 和 <code>D</code> 节点就不需负责相应 range 了。因此，在收到 <code>X</code> 的转移 key 请求之后， <strong><code>B</code>、<code>C</code> 和 <code>D</code> 会向 X 转移相 应的 key</strong> 。当移除一个节点时，key 重新分配的顺序和刚才相反。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/CBf8Tj.png"></p>
<p>我们的实际运行经验显示，这种方式 <strong>可以在存储节点之间保持 key 的均匀分布</strong> ，这对 于保证延迟需求和快速 bootstrapping 是非常重要的。另外，在源和目的节点之间加了确 认（转移），可以保证不会转移重复的 key range。</p>
<h2 id="5-实现"><a href="#5-实现" class="headerlink" title="5. 实现"></a>5. 实现</h2><p>Dynamo 中的 <strong>每个存储节点上主要有三个组件</strong> ，都是用 Java 实现的：</p>
<ul>
<li>request coordination（请求协调）组件</li>
<li>成员验证和故障检测组件</li>
<li>本地持久存储引擎</li>
</ul>
<h3 id="本地存储引擎"><a href="#本地存储引擎" class="headerlink" title="本地存储引擎"></a>本地存储引擎</h3><p>Dynamo 的本地持久存储组件支持以插件的方式使用不同的存储引擎。在使用的引擎包括：</p>
<ul>
<li>Berkeley Database (BDB) Transactional Data Store2</li>
<li>BDB Java Edition</li>
<li>MySQL</li>
<li>an in-memory buffer with persistent backing store</li>
</ul>
<p>将其设计为可插拔的原因是： <strong>为不同应用访问类型选择最合适的存储引擎</strong> 。例如，BDB 通常用于处理几十 KB 大小的对象，而 MySQL 可以处理更大的对象。应用可以根据它们的 对象大小分布选择合适的持久化引擎。</p>
<p>我们生产环境的 Dynamo 大部分使用的都是 BDB Transactional Data Store。</p>
<h3 id="请求协调"><a href="#请求协调" class="headerlink" title="请求协调"></a>请求协调</h3><p>request coordination 组件构建在一个事件驱动的消息系统之上，其中的消息处理 pipeline 分为多个阶段，和 SEDA 架构类似 [24]。所有通信都基于 Java NIO channel 实现。</p>
<p><strong>coordinator 代替客户端执行读和写请求</strong> ：读操作时会从一个或多个节点收集数据，写操作 时会向一个或多个节点存储数据。每个客户端请求都会 <strong>在收到这个请求的节点上创建一个状 态机</strong> 。这个状态机包含了识别 key 对应的节点、发送请求、等待响应、重试、处理响应和 组合响应返回给客户端等所有逻辑。</p>
<h4 id="read-coordination"><a href="#read-coordination" class="headerlink" title="read coordination"></a>read coordination</h4><p>每个状态机处理且只处理一个客户端请求。例如，一个读操作实现了包含如下步骤的状态机：</p>
<ol>
<li>发送读请求给节点</li>
<li>等待所需的最少数量响应</li>
<li>如果在规定的上限时间内收到的响应数量太少，认定请求失败</li>
<li>否则，收集对象的所有版本，确定应该返回哪些</li>
<li>如果打开了版本化（versioning）配置，执行 syntactic reconciliation，生成一个不 透明的写上下文（context），其中包含了合并之后的版本对应的的 vector clock</li>
</ol>
<p>为了描述的简单，以上没有提及故障处理和重试的步骤。</p>
<p><strong>读操作的响应发送给调用方之后，状态机会继续等待一小段时间，接收可能的有效响应</strong> （ outstanding responses，例如最小数量响应之外的其他节点的响应，译者注）。</p>
<p>如果返回中有过期版本（stale version），coordinator 就需要合并版本，并将最新版本 更新回这些节点。这个过程称为 <strong>“读时修复”（read repair）</strong> ，因为它 <strong>在一个乐观的 时间点</strong> （at an opportunistic time） <strong>修复了那些错过了最新更新的副本</strong> （replicas that have missed a recent update）， <strong>减少了逆熵协议的工作</strong> （本来应该是稍后由逆 熵协议做的）。</p>
<h4 id="write-coordination"><a href="#write-coordination" class="headerlink" title="write coordination"></a>write coordination</h4><p>前面提到过，写请求是由 preference list 内的前 N 个节点中的任意一个 coordinate 的 。总是让 N 个节点中的第一个来 coordinate 有一些好处，例如可以使得在同一个地方完 成写操作的顺序化（serializing all writes），但是，这种方式也有缺点：它会导致不均 匀的负载分布，损害 SLA。这是因为对象请求并不是均匀分布的（request load is not uniformly distributed across objects）。</p>
<p>为了解决这个问题， <strong>preference list 内的所有 N 个节点都可以 coordinate 写操作</strong> 。 而且，因为一个写操作之前通常有一个读操作，因此写操作的 coordinator 都选择为： <strong>前 一次读操作返回最快的那个节点</strong> ，这个信息存储在读操作返回的上下文中。</p>
<p>这项优化还使在下一次读取时，前一次读操作选中的存储这个数据的节点更容易被选中，提 高了“读取刚写入的数据”（“read-your-writes”）的概率。</p>
<blockquote>
<p>This optimization enables us to pick the node that has the data that was read by the preceding read operation thereby increasing the chances of getting “read-your-writes” consistency.</p>
</blockquote>
<p>同时，还降低了请求处理性能的抖动性，提高了 <code>P99.9</code> 性能。</p>
<h2 id="6-测试结果及学到的经验"><a href="#6-测试结果及学到的经验" class="headerlink" title="6. 测试结果及学到的经验"></a>6. 测试结果及学到的经验</h2><p>Dynamo 被几种不同类型的服务使用，每种场景下的配置不同。这些不同体现在 vesion reconciliation 逻辑和读&#x2F;写仲裁特点上。几种主要的场景：</p>
<ul>
<li><strong>业务逻辑相关的 reconciliation</strong> ：这种场景使用很广。每个数据对象都会复制到不同节 点上，发生 <strong>版本冲突时由应用执行自己的 reconciliation 逻辑</strong> 。前文提到的购物 车服务就是一个典型的例子，应用自己来合并冲突的购物车版本</li>
<li><strong>基于时间戳的 reconciliation</strong> ：和第一种的不同仅仅是 reconciliation 机制。当 发生版本冲突时，Dynamo 根据 <strong>“最后一次写胜出”</strong> （last write wins）机制，例如， 选择时间戳最近的一个版本作为最终版本。一个例子是维护客户 session 信息的服务</li>
<li><strong>高性能读引擎</strong> ：虽然 Dynamo 设计为永远可写（always writeable） 数据仓库, 但 一些服务通过 <strong>对 Dynamo 的仲裁特性进行调优（tuning），而将其作为一个高性能读引 擎使用</strong> 。典型情况下，这类服务有很高的读频率和很小的写频率。 <strong>在这种配置中， <code>R</code> 一般设为 1，<code>W</code> 设为 <code>N</code></strong> 。对于这些服务，Dynamo 提供了 partition 和数据跨 多节点复制的能力，因而提供了增量可扩展性。 <strong>数据的权威持久缓存</strong> （the authoritative persistence cache for data）存储在更重量级的后端存储中（more heavy weight backing stores）。<strong>维护产品目录和促销商品的服务</strong>会用到这种类型 的 Dynamo 配置</li>
</ul>
<p>Dynamo 的最大优势是： <strong>客户端应用可以通过对 N、R 和 W 三个参数进行调优来达到期 望的性能、可用性和持久性等级</strong> 。</p>
<blockquote>
<p>The main advantage of Dynamo is that its client applications can tune the values of N, R and W to achieve their desired levels of performance, availability and durability.</p>
</blockquote>
<p>例如，N 的大小决定了每个对象的持久性。Dynamo 用户最常用的 N 配置是 3。</p>
<p>W 和 R 的值会影响对象的可用性、持久性和一致性。例如，如果 W 设为 1，那只要系统还 有一台正常的 node，写操作就不会被拒绝。但是，太小的 W 和 R 配置会增加不一致的风 险，因为一次写操作即使在没有大多数副本都写成功的情况下，还是会给客户端返回成功。 这也导致存在一个 <strong>风险窗口</strong> （vulnerability window）： <strong>一次写操作即使只在少量节 点上完成了持久化，也会向客户端返回成功</strong> 。</p>
<p>传统观点认为，持久性和可用性是相伴而生（go hand in hand）的，但在这里不一定成立。 例如，增加 W 就会减小持久性的风险窗口；但是，这可能会增加请求被拒绝的概率（因此 降低了可用性），因为这种情况下需要更多的健康存储节点来处理写请求。</p>
<p>我们 <strong>最常用的 Dynamo 集群 <code>(N,R,W)</code> 配置是 <code>(3,2,2)</code></strong> 。这个配置符合我们所需的 性能、持久性、一致性和可用性（SLA）等级。</p>
<p>本节所有的数据都是从一套线上 Dynamo 环境获得的，配置是 <code>(3,2,2)</code>， 有几百台节点（a couple hundred nodes），配置利用到了异构硬件信息。</p>
<p>之前我们提到，每套 Dynamo 的节点都是跨数据中心部署的，这些数据中心之间通过高速网 络互联。执行一次成功的 <code>get</code> （或 <code>put</code>）需要 <code>R</code> （或 <code>W</code>）个节点向 coordinator 发送响应，因此很明显，数据中心之间的时延会影响到响应时间，因此在选择节点（以及它 所在的数据中心的位置）的时候要特别注意，以保证能满足应用期望的 SLA。</p>
<h3 id="6-1-性能和持久性的平衡"><a href="#6-1-性能和持久性的平衡" class="headerlink" title="6.1 性能和持久性的平衡"></a>6.1 性能和持久性的平衡</h3><p>虽然 Dynamo 的首要设计目标是一个高可用数据仓库，但性能指标在 Amazon 也同样重要。 前面提到过，为了提供一致的用户体验，Amazon 的服务会设置一个很高的用百分比衡量的 （例如 <code>P99.9</code> 或 <code>P99.99</code>）性能指标。典型的 SLA 指标是：读和写操作的 <code>P99.9</code> 要 在 <code>300ms</code> 以内成。</p>
<p>由于 Dynamo 是在<strong>通用硬件</strong>上运行的，和高端企业级服务器相比， <strong>I&#x2F;O 吞吐性能要差 很多</strong> ，因此提供一致的高性能读写并不是一项简单的工作。而且，每次读&#x2F;写操作都要涉 及多台节点，给这项工作带来了更大的挑战性，因为 <strong>最终的性能受限于最慢的那个副本所 在的节点</strong> 。</p>
<h4 id="通用配置下的性能"><a href="#通用配置下的性能" class="headerlink" title="通用配置下的性能"></a>通用配置下的性能</h4><p>图 4 显示了 30 天内 Dynamo 的读和写操作延迟平均值和 <code>P99.9</code>：</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/0qxHhL.png"></p>
<p>图 4 2006 年 12 月峰值请求季的读写延迟平均值和 P99.9。 X 轴一个刻度 12 小时。延迟走势和每天的请求量走势一致，延迟的 P99.9 比平均值要大一个数量级。</p>
<p>从图上可以看出，延迟曲线每天的走势（diurnal pattern）都类似，这和平台每天的请求 量走势也是一致的（例如，白天和晚上的请求量明显不一样）。另外，写延迟明显高于读延 迟，因为 <strong>写操作永远需要访问磁盘</strong> 。另外， <strong><code>P99.9</code> 大约为 <code>200ms</code>，比平均值高一 个数量级</strong> 。这是因为 P99.9 有很多影响因素，例如请求负载变化、对象大小和 locality patterns。</p>
<h4 id="低延迟配置下的性能"><a href="#低延迟配置下的性能" class="headerlink" title="低延迟配置下的性能"></a>低延迟配置下的性能</h4><p>以上性能对很多服务来说都足够了，但有少数面向用户的服务，它们对性能有更高的要求。 对于这种情况，Dynamo 提供了<strong>牺牲持久性换性能</strong>的能力。具体来说，每个存储节点会  <strong>在主内存中维护一个对象缓存</strong> （object buffer），写操作将数据存储到缓存直接返回， 另有一个独立的写线程定期将数据写入磁盘。读操作会先检查缓存中是否有，如果有，就直 接从缓存读，从而避免了访问存储引擎。</p>
<p>这项优化可以 <strong>将峰值流量期间的 P99.9 降低到原来的 <code>1/5</code></strong> ，即使只使用一个很小的 、只能存放 1000 个对象的缓存，见图 5。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/bnWNMX.png"></p>
<p>图 5 带缓存和不带缓存的 P99.9 性能对比，时间跨度 24 小时，X 轴一个刻度一个小时</p>
<p>另外，从图中可以看到，缓存写（write buffering）可以对百分比延迟进行平滑。显然， 这种方案中持久性和性能之间做了折中：一台 <strong>节点挂掉会导致缓存里还未落盘的数据丢失</strong> 。 为了减小这种风险，写操作进行了优化（refine），由 coordinator  <strong>从 <code>N</code> 个副本中选择 一个进行持久化写入</strong> （durable write）。因为 coordinator 只等待 <code>W</code> 个写操作，因此整 体的写操作不受这次写盘操作的影响。</p>
<blockquote>
<p>以上优化的意思是，每次写操作到达 coordinator 时，它会将请求转发给相应个节点， 这些节点都是写完内存 buffer 就直接返回的；除此之外，coordinator 还会挑一个节点 进行持久写入，跟其他节点的写是并行进行的，这样可以降低其他节点挂掉时内存数据丢 失的风险。由于 coordinator 只等待 W 个结果就返回了，因此虽然这个执行持久写的节 点（相对）很慢，但 coordinator 并不会依赖它的结果才返回，因此文中说对写性能来 说是没有影响的，译者注。</p>
</blockquote>
<h3 id="6-2-均匀负载分布（Uniform-Load-distribution）"><a href="#6-2-均匀负载分布（Uniform-Load-distribution）" class="headerlink" title="6.2 均匀负载分布（Uniform Load distribution）"></a>6.2 均匀负载分布（Uniform Load distribution）</h3><p>Dynamo 通过一致性哈希将它的 key 空间进行 partition，保证负载分布的均匀性。 只要 key 的访问不是极度不均衡，均匀的 key 分布就可以帮助我们实现负载的均衡分布。 特别地，即使出现了明显的 key 访问不平衡的情况，只要这些 key 足够多，Dynamo 也能 保证这些 key 在后端节点之间是均衡分散的。 本节介绍 Dynamo 中的负载不平衡问题，几种解决策略及其对负载分布的影响。</p>
<p>为了研究负载不平衡（load imbalance）以及它和请求负载（request load）的相关性，我 们测量了 24 个小时内每台节点收到的请求量，以 30 分钟作为一个点。在规定的时间内， 只要节点收到的请求量偏离平均值的程度不超过一个阈值（例如，15%），这台节点就认为 是平衡的（inbalance）；否则，就是不平衡的（out of balance）。</p>
<p>图 6 展示了不平衡的节点所占的比例（imbalance ratio）：</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/pdKfD4.png"></p>
<p>图 6 不平衡节点比例，及其负载（请求数），X 轴一个刻度 30 分钟</p>
<p>作为参考，图中也画出了这段期间系统的总负载（请求量）。从图中可以看出，随着请求量 的上升，不平衡的比例在下降。例如，低负载期间的不平衡比例高达 20%，而高负载期间降 到了 10%。直观上可以解释：随着负载（请求量）的上升，大量的活跃 key 的访问会均匀 的分发到节点，导致负载平衡分布。而低峰期间（请求量只有峰值的 1&#x2F;8），只有很少的 活跃 key 访问，导致负载非常不平衡。</p>
<p>本节接下来介绍 Dynamo 的 partition scheme 是如何随时间演进的，以及它对负载分布的 影响。</p>
<h4 id="策略-1：每个节点-T-个随机-token，按-token-值分散"><a href="#策略-1：每个节点-T-个随机-token，按-token-值分散" class="headerlink" title="策略 1：每个节点 T 个随机 token，按 token 值分散"></a>策略 1：每个节点 T 个随机 token，按 token 值分散</h4><p>这是生产环境最早部署的策略（在 4.2 节介绍过了）。</p>
<p>在这种策略中，会 <strong>给每个节点（从哈希空间）随机分配 T 个 token</strong> 。所有节点的 token 在哈希空间中是有序的（按 token 值）。 <strong>两个相邻的 token 定义一个范围</strong> （ key range）。最后一个 token 和第一个 token 收尾相连。</p>
<p>因为 token 是随机选择的，因此范围有大有小。 <strong>当有节点加入或离开系统的时，token 集合会变化，导致范围也会跟着变</strong> 。注意， <strong>每个节点用来维护成员信息所需的空间随着 系统中的节点数线性增长</strong> 。</p>
<p>这种策略在使用过程中发现如下几个问题。</p>
<p>首先，一个 <strong>新节点加入到系统后，需要从其他节点“偷”出它要用的 key range</strong> 。 这会导致那些需要将一部分 key range 移交给新节点的节点， <strong>扫描它们全部的本地持久存 储</strong> ，以过滤出所需的数据。在生产环境环境执行这种扫描操作是很棘手的，因为它 会 <strong>占用大量磁盘 IO</strong> ；为了不影响正常的请求处理，需要把这个任务放到后台。 这要求我们只能将新节点加入集群的任务调到最低优先级。这带来的后果就是， <strong>节点上线的 速度非常慢</strong> ，尤其是购物高峰季每天处理百万请求时，上线一台节点需要花费几乎一整天时 间。</p>
<p>第二，一个节点加入或离开系统时，很多节点负责的 key range 会发生变化，对应的  <strong>Merkle tree 需要重新计算</strong> 。对于生产环境来说，这也是一项不小的工作。</p>
<p>最后，由于 key range 的随机性， <strong>无法快速地对整个 key 空间进行快照</strong> （snapshot）。 这使得存档（备份）工作变得复杂。在这种方案下，我们进行一次快照需要分别从所有节 点获取 key，非常低效。</p>
<p><strong>这种策略的根本问题出在：数据的 partition 和 placement 方案混在了一起</strong> （ intertwined）。例如，在某些场景下希望通过增加节点应对请求量的上涨，但是在这种方 案中， <strong>无法做到添加新节点不影响数据 partition</strong> 。</p>
<p>理想情况下，应该使用独立的数据 partition 和 placement 方案。为此，我们考察了下面的几种方案。</p>
<h4 id="Strategy-2-每个节点-T-个随机-token，平均分散"><a href="#Strategy-2-每个节点-T-个随机-token，平均分散" class="headerlink" title="Strategy 2: 每个节点 T 个随机 token，平均分散"></a>Strategy 2: 每个节点 T 个随机 token，平均分散</h4><p>这种策略将哈希空间分为 <code>Q</code> 个相同大小的 partition&#x2F;range，每个节点分配 <code>T</code> 个 随 机 token。<code>Q</code> 的选择通常要满足：<code>Q &gt;&gt; N</code> 和 <code>Q &gt;&gt; S*T</code>（<code>&gt;&gt;</code>：远大于，译者注）， 其中 <code>S</code> 是系统中节点的数量。</p>
<p>在这种策略中，token 仅用于<strong>哈希空间的值映射到有序节点列表</strong>的过程，并 <strong>不影响数 据 partition</strong> 。</p>
<p>一个 partition 会放在从该 partition 末尾开始 <strong>沿顺时针方向得到的前 N 个独立节点</strong> 。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/PzpOTk.png"></p>
<p>图 7 三种策略中 key 的 partition 和 placement。N&#x3D;3，A、B、 C 是 key k1 的 preference list 中的三个独立节点。阴影区域表示 preference list 是 [A,B,C] 的 key range，箭头表示不同节点对应的 token 位置</p>
<p>图 7 展示了 <code>N=3</code> 时这种策略的示意图。</p>
<p>这种策略的主要优点：</p>
<ol>
<li>将数据的 partition 和 placement 解耦</li>
<li>提供了在运行时更改 placement 方案的能力</li>
</ol>
<h4 id="Strategy-3-每个节点-Q-S-个-token-平均分散"><a href="#Strategy-3-每个节点-Q-S-个-token-平均分散" class="headerlink" title="Strategy 3: 每个节点 Q/S 个 token, 平均分散"></a>Strategy 3: 每个节点 <code>Q/S</code> 个 token, 平均分散</h4><p>和策略 2 类似，策略 3 也将哈希空间等分为 <code>Q</code> 个 partition，而且 placement 从 partition 解耦。不同的是，每个节点会分配 <code>Q/S</code> 个 token，其中 <code>S</code> 是系统中的节点 数量。</p>
<p>当一个节点离开时，它的 token 会随机地分配给其他节点，因此 <code>Q/S</code> 个 token 的特性 还是能成立。类似地，当一个节点加入系统时，它会从其他节点“偷”一些 token 过来，同 时保证 <code>Q/S</code> 特性仍然成立。</p>
<h4 id="几种策略的性能对比"><a href="#几种策略的性能对比" class="headerlink" title="几种策略的性能对比"></a>几种策略的性能对比</h4><p>对一套 <code>S=30</code>，<code>N=3</code> 的 Dynamo 测试了以上三种策略。需要说明的是，公平地比较这三 种策略的性能是很难做到的，因为它们有各自特殊的配置可以调优。例如，策略 1 的负载 分布特性取决于 token 的数量（例如 <code>T</code>），而策略 3 取决于 partition 的数量（例如 <code>Q</code>）。</p>
<p>一种比较公平的方式是： <strong>所有的策略都使用相同大小的空间存储成员信息时，测量它们的 负载分布倾斜度</strong> （skew in load distribution）。例如，策略 1 中每个节点需要为环上 的全部节点维护各自的 token 位置，而策略 3 中每个节点需要维护系统分配给每个节点的 partition 信息。</p>
<p>实验中我们将通过改变相关的参数（<code>T</code> 和 <code>Q</code>）来评估这三种策略。测试每个节点需要维 护的成员信息的大小（size）不同时，几种策略的 <strong>负载均衡效率</strong> 。其中负载均衡效率（ load balancing efficiency）的定义是：每个节点平均处理的请求数 <code>/</code> 负载最高的节点处 理的请求数。</p>
<p>结果如图 8 所示。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/DBaLIm.png"></p>
<p>图 8 三种策略的负载均衡效率对比，30 个几点，N&#x3D;3，每个节点维护相同大小的元数据</p>
<p>如图所示， <strong>策略 3 取得了最好的负载均衡性能，策略 2 最差</strong> 。在某段较短的时期内， 策略 2 充当了将线上的一些 Dynamo 从策略 1 迁移到策略 3 的过渡策略。</p>
<p>和 策略 1 相比，策略 3 性能更好，而且减少了每个节点所需维护的成员信息的大小。</p>
<p><strong>虽然存储这些成员信息并不会占用太多存储，但是，节点通过 gossip 协议定期地将成员 信息发送给其他节点</strong> （gossip the membership information periodically），因此<strong>保 持这些信息越紧凑越好。</strong></p>
<p>此外，策略 3 部署更加方便，原因包括：</p>
<ol>
<li><strong>bootstrap 和恢复更快</strong> ：因为  <strong>partition 范围是固定的</strong> ，因此可以将其存放 到 <strong>单独的文件</strong> ，这样下次 relocation 的时候可以直接将<strong>整个文件</strong>发送给其他节点 （避免了为了定位特点的数据而进行的 <strong>随机访问</strong> ）。简化了 bootstrap 和恢复的过程</li>
<li><strong>易于存档</strong> ：定期对数据集（dataset）进行存档是 Amazon 存储服务的硬性要求之一 。在策略 3 中，存档过程会变得更容易，因为 partition 文件可以单独存档。作为对 比，在策略 1 中，token 是随机选取的，存档的时候需要从所有节点分别获取它们存储 的 key 信息，通常非常低效，速度也很慢。</li>
</ol>
<p>策略 3 的不足： <strong>变更节点成员时，需要 coordination</strong> ，以保持平均分配所需的前提特 性（preserve the properties required of the assignment）。</p>
<h3 id="6-3-版本分叉：什么时候？有多少？"><a href="#6-3-版本分叉：什么时候？有多少？" class="headerlink" title="6.3 版本分叉：什么时候？有多少？"></a>6.3 版本分叉：什么时候？有多少？</h3><p>我们已经提到过，Dynamo 是通过牺牲一些一致性（consistency）来换可用性（ availability）的。要准确地理解不同类型的一致性失败带来的影响需要考虑很多因素：故障时 常（outage length）、失败类型（type of failures）、组件可靠性、负载等等。 详细地展示这些数据超出了本文范围。但是，本节可以提供一个很好的总结指标：一份真实 的生产环境里 <strong>应用看到的分叉版本数量</strong> （number of divergent versions seen by the application）。</p>
<p>有两种情况会出现数据版本的分叉：</p>
<ol>
<li>遇到节点失败、数据中心故障或网络分裂等故障场景</li>
<li>同一数据对象的大量并发写操作，不同节点都在 coordinating 写操作</li>
</ol>
<p>从使用性（usability）和效率的角度，最好在任何时间都保证分叉的版本数尽量小。</p>
<p>如果冲突的版本无法仅通过向量时钟做句法调和（syntactically reconcile），那就需要 将它们交给业务逻辑，执行语义调和（semantic reconciliation）。</p>
<blockquote>
<p>If the versions cannot be syntactically reconciled based on vector clocks alone, they have to be passed to the business logic for semantic reconciliation.</p>
</blockquote>
<p><strong>Semantic reconciliation 会给服务引入额外的负担</strong> ，因此应当越少越好。</p>
<p>我们采集了 24 小时内返回到购物车应用的版本数量。结果显示在这段时间内，<code>99.94%</code> 的请求看到的都是一个版本（无冲突）；<code>0.00057%</code> 的请求看到能 2 个，<code>0.00047%</code> 能看 到 3 个，<code>0.00009%</code> 的能看到 4 个。这说明版本分叉的概率还是相当小的。</p>
<p>实验还显示，导致分叉版本数量增多的并不是故障，而是并发写数量的增加。并发写数据上 升通常都是 busy robots（自动化客户端程序）导致的，极少是人（的应用）导致的。由于 涉及商业机密，在此不再就这一问题进行更深入的讨论。</p>
<h3 id="6-4-客户端驱动或服务端驱动的-Coordination"><a href="#6-4-客户端驱动或服务端驱动的-Coordination" class="headerlink" title="6.4 客户端驱动或服务端驱动的 Coordination"></a>6.4 客户端驱动或服务端驱动的 Coordination</h3><p>第 5 节提到，Dynamo 有一个 request coordination 组件，利用状态机处理收到的请求。</p>
<h4 id="服务端驱动"><a href="#服务端驱动" class="headerlink" title="服务端驱动"></a>服务端驱动</h4><p>客户请求会通过负载均衡器均匀地分发给哈希环上的所有节点。每个节点都可以作为读请求 的 coordinator，而写操作的 coordinator 必须由 key 的 preference list 里面的节点 才能充当。有这种限制是因为，preference list 中的这些节点 <strong>被赋予了额外的职责：创 建一个新的版本戳（version stamp），在因果关系上包含被它的写操作更新的版本</strong> 。注 意，如果 Dynamo 的版本化方案使用的是物理时间戳（physical timestamps），那任何节 点都可以 coordinate 写操作。</p>
<h4 id="客户端驱动"><a href="#客户端驱动" class="headerlink" title="客户端驱动"></a>客户端驱动</h4><p>另一中 coordinate request 的方式是： <strong>将状态机前移到客户端</strong> （move the state machine to the client nodes）。在这种方式中，客户端应用使用库（library）在本地执 行请求 coordination。每个客户端定期地随机选择一个 Dynamo 节点，下载它的系统成员 状态（Dynamo membership state）的当前视图（current view）。有了这个信息，客户端 就可以知道任何 key 对应的 preference list 由哪些节点组成。</p>
<p>读请求可以在客户端节点（client node）coordinate，因此如果请求是被负载均衡器随机 分给一个 Dynamo 节点，那这种方式可以避免额外的网络转发跳数。写操作或者转发给 key 对应的 preference list 里面的一个节点，或者，如果使用的是基于时间戳的版本化方式 ，可以在本地 coordinate。</p>
<p>客户端驱动的一个重要<strong>优势</strong>是：不再需要一个负载均衡器才能均匀地分发客户负载。 在存储节点上近乎均匀分布的 key，暗含了（implicitly guaranteed）负载的均匀分布。</p>
<p>显然，这种方式的效率取决于客户端侧的成员信息的新鲜程度（how fresh the membership information）。当前，每个客户端会每隔 <code>10s</code> 随机地轮询（poll）一个 Dynamo 节点， 获取成员更新（membership updates）。这里选用 pull 而不是 push 模型是考虑前者在大 量客户端的情况下可扩展性更好，而且相比于客户端侧，只需在服务端侧维护很少的状态信 息。</p>
<p>然而，在最差的情况下，客户端的 membership 信息会有 <code>10s</code> 的脏数据。 因此，如果客户端检测到它的成员表（membership table）过期了（例如，当一些成员不可 达的时候），它会立即更新它的成员信息。</p>
<h4 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h4><p>表 2 显示了客户端驱动比服务端驱动的 coordination 的性能提升，测量时间为 24 个小时。</p>
<p>表 2 客户端驱动和服务端驱动的 coordination 性能对比</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/5FqeZu.png"></p>
<p>从中可以看出，客户端驱动的方式比服务端方式 <code>P99.9</code> 减少了至少 <code>30ms</code>，平均值减少 了 <code>3ms~4ms</code>。</p>
<p>延迟降低是因为客户端驱动的方式没有了负载均衡器的开销，而且减少了可能的将请求转发 给一个随机节点的网络跳数。</p>
<p>另外从表中还可以看出，平均延迟远远小于 <code>P99.9</code>。这是因为 Dynamo 的存储引擎缓存（ storage engine caches）和写缓存（write buffer）命中率很高。</p>
<p>另外，由于负载均衡器和网络会给延迟引入额外的抖动性，因此 <code>P99.9</code> 的性能提升要比 均值更明显。</p>
<h3 id="6-5-平衡后台和前台任务"><a href="#6-5-平衡后台和前台任务" class="headerlink" title="6.5 平衡后台和前台任务"></a>6.5 平衡后台和前台任务</h3><p>每个节点除了执行正常的前台 <code>put</code>&#x2F;<code>get</code> 操作之外，还需要为副本同步和数据移交（ handoff）（由于 hinting 或添加&#x2F;删除节点）执行不同种类的后台任务。</p>
<p>在早期的生产系统中，这些后台任务触发了资源竞争问题，影响了常规的 <code>get</code>&#x2F;<code>put</code> 操 作性能。</p>
<p>因此，必须在保证常规的关键操作不受明显影响的情况下，才允许执行后台任务。为此，我 们将后台任务关联了一种 <strong>许可控制机制</strong> （admission control mechanism）。每个后台 任务通过这个控制器 <strong>申请资源（例如数据库）的运行时时间片</strong> （runtime slice），这 些资源是在所有后台任务之间共享的。对前台任务性能的监控会通过<strong>反馈机制</strong>改变后台 任务可以使用的时间片数量。</p>
<p>许可控制器（admission controller）在执行一个前台 <code>put</code>&#x2F;<code>get</code> 操作的时候，会持续 监控资源访问的状况。<strong>监控的指标</strong>包括磁盘操作延迟、锁竞争和事务超时导致的数据库 访问失败次数，以及请求队列的等待时间。这些信息用于判断在给定的时间窗口之内的延迟 （或失败）性能是否在可接受的范围内。例如，后台控制器检查数据库（过去 <code>60s</code>）的 <code>P99</code> 读延迟是否离预设的阈值（例如 <code>50ms</code>）足够近。控制器正是根据这些对比信息为 前台操作评估资源的可用性，然后决定给后台任务分配多少时间片，因此利用反馈回路限制 了后台任务的侵入性（intrusiveness ）。[4] 也研究了类似的后台任务管理问题。</p>
<h3 id="6-6-讨论"><a href="#6-6-讨论" class="headerlink" title="6.6 讨论"></a>6.6 讨论</h3><p>本节总结我们在开发和维护 Dynamo 的过程中获得的一些经验。</p>
<p>很多 Amazon 的内部服务在过去的两年都开始使用 Dynamo，它给应用提供了非常高等级（ significant levels）的可用性。具体来说，使用 Dynamo 的应用，响应成功率（不包括超 时？）达到了 <code>99.9995%</code>（ <strong>applications have received successful responses (without timing out) for <code>99.9995%</code> of its requests</strong> ），并且到目前位置还没有发 生过丢失数据的情况。</p>
<p>Dynamo 的主要优势是：给应用提供了配置能力，应用可以根据自己的需求对 <code>(N,R,W)</code> 进 行调优。</p>
<p>和流行的商业数据仓库不同，Dynamo 将数据一致性和 reconciliation 逻辑开放给了开发 者。刚开始时，有人可能会觉得这样会使应用逻辑变得更复杂。但从传统来看（ historically），Amazon 平台就是为高可用设计的，很多 <strong>应用在设计的时候就考虑了如 何处理可能出现的各种故障模式（failure modes）和不一致问题</strong> 。对于这类应用来说， 适配 Dynamo 相对还是比较简单的。对于想要使用 Dynamo 的新应用，就需要首先花一些时 间做一些分析，在开发初期，选择满足业务需求的合适的冲突解决机制（conflict resolution mechanisms）。</p>
<p>最后，Dynamo 采用了一种 <strong>full membership model</strong> （完整成员模型），在这种模型中， 每个节点都知道它的对端（peer）节点存储哪些数据。在实现中，每个节点要主动将完整路 由表 gossip 给系统内的其他节点。这个模型 <strong>对几百台、上千台节点的规模很适用</strong> 。但 对于上万台节点的规模就不适应了，因为维护这么大一个系统的路由表开销会大大增加。 但是，可以通过向 Dynamo 引入 <strong>hierarchical extensions</strong> （层级扩展）来解决这个限制。 <code>O(1)</code> 复杂度的的动态哈希树系统（DHS）（例如 [14]）解决的就是这种问题。</p>
<blockquote>
<p>this problem is actively addressed by O(1) DHT systems(e.g., [14]).</p>
</blockquote>
<h2 id="7-结束语"><a href="#7-结束语" class="headerlink" title="7. 结束语"></a>7. 结束语</h2><p>本文介绍了 Dynamo，一个高可用、高可扩展的数据存储，在 Amazon 电商平台用于存储许多核心服务的状态数据。</p>
<p>Dynamo 提供了期望的可用性和性能等级，可以正确地处理服务器故障、数据中心故障和网 络分裂。</p>
<p>Dynamo 可以增量扩展，允许服务所有者根据负载高低动态的对 Dynamo 系统进行扩缩容； 允许服务所有者根据他们的性能、持久性和一致性 SLA 需求，通过调优 <code>N``R``W</code> 三个参 数来定制化它们的存储系统。</p>
<p>过去几年 Dynamo 在生产环境的实践表明：一些去中心化技术结合起来，可以提供一个高度 可用的系统。这种在极具挑战性的应用环境的成功也表明，  <strong>&#x3D;最终一致性存储系统可以作为高可用应用（highly available applications）的一块基石&#x3D;</strong> 。</p>
<blockquote>
<p>The production use of Dynamo for the past year demonstrates that decentralized techniques can be combined to provide a single highly-available system. Its success in one of the most challenging application environments shows that an eventualconsistent storage system can be a building block for highlyavailable applications.</p>
</blockquote>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>dynamo</tag>
        <tag>distributed</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis Sentinel 的高可用性</title>
    <url>/2022/04/28/database/Redis%20Sentinel%20%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7/</url>
    <content><![CDATA[<p>非集群Redis的高可用</p>
<p>Redis Sentinel 在不使用<a href="https://redis.io/docs/manual/scaling">Redis Cluster</a> 时为 Redis 提供高可用性。</p>
<p>Redis Sentinel 还提供其他附带任务，例如监控、通知并充当客户端的配置提供程序。</p>
<p>这是宏观层面（即 <em>大图</em> ）的 Sentinel 功能的完整列表：</p>
<ul>
<li><strong>监控</strong> 。Sentinel 不断检查您的主实例和副本实例是否按预期工作。</li>
<li><strong>通知</strong> 。Sentinel 可以通过 API 通知系统管理员或其他计算机程序，其中一个受监控的 Redis 实例出现问题。</li>
<li><strong>自动故障转移</strong> 。如果 master 没有按预期工作，Sentinel 可以启动一个故障转移过程，其中一个副本被提升为 master，其他额外的副本被重新配置为使用新的 master，并且使用 Redis 服务器的应用程序被告知要使用的新地址连接时。</li>
<li><strong>配置提供商</strong> 。Sentinel 充当客户端服务发现的权威来源：客户端连接到 Sentinels 以询问负责给定服务的当前 Redis master 的地址。如果发生故障转移，Sentinels 将报告新地址。</li>
</ul>
<span id="more"></span>

<h2 id="Sentinel-作为分布式系统"><a href="#Sentinel-作为分布式系统" class="headerlink" title="Sentinel 作为分布式系统"></a>Sentinel 作为分布式系统</h2><p>Redis Sentinel 是一个分布式系统：</p>
<p>Sentinel 本身设计为在多个 Sentinel 进程协同工作的配置中运行。让多个 Sentinel 进程协作的优点如下：</p>
<ol>
<li>当多个 Sentinels 就给定的 master 不再可用这一事实达成一致时，将执行故障检测。这降低了误报的可能性。</li>
<li>即使并非所有 Sentinel 进程都在工作，Sentinel 也能正常工作，从而使系统对故障具有鲁棒性。毕竟，拥有一个本身就是单点故障的故障转移系统毫无乐趣可言。</li>
</ol>
<p>Sentinels、Redis 实例（masters 和 replicas）以及连接到 Sentinel 和 Redis 的客户端的总和，也是一个更大的分布式系统，具有特定的属性。在本文档中，将逐步介绍概念，从了解 Sentinel 的基本属性所需的基本信息开始，到更复杂的信息（可选）以了解 Sentinel 的工作原理。</p>
<h2 id="哨兵快速启动"><a href="#哨兵快速启动" class="headerlink" title="哨兵快速启动"></a>哨兵快速启动</h2><h3 id="获得哨兵"><a href="#获得哨兵" class="headerlink" title="获得哨兵"></a>获得哨兵</h3><p>Sentinel 的当前版本称为 <strong>Sentinel 2</strong> 。它使用更强大且更易于预测的算法（在本文档中进行了解释）重写了初始 Sentinel 实现。</p>
<p>Redis Sentinel 的稳定版本从 Redis 2.8 开始发布。</p>
<p>新的开发是在<em>不稳定</em>的分支中进行的，并且新功能有时会在被认为稳定后立即移植到最新的稳定分支中。</p>
<p>Redis Sentinel 版本 1，随 Redis 2.6 一起提供，已弃用，不应使用。</p>
<h3 id="运行哨兵"><a href="#运行哨兵" class="headerlink" title="运行哨兵"></a>运行哨兵</h3><p>如果您正在使用<code>redis-sentinel</code>可执行文件（或者如果您有指向<code>redis-server</code>可执行文件的同名符号链接），您可以使用以下命令行运行 Sentinel：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">redis-sentinel /path/to/sentinel.conf</span><br></pre></td></tr></table></figure>

<p>否则，您可以直接使用<code>redis-server</code>以 Sentinel 模式启动它的可执行文件：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">redis-server /path/<span class="selector-tag">to</span>/sentinel<span class="selector-class">.conf</span> <span class="attr">--sentinel</span></span><br></pre></td></tr></table></figure>

<p>两种方式都一样。</p>
<p>但是，在运行 Sentinel 时<strong>必须</strong>使用配置文件，因为系统将使用此文件来保存当前状态，以便在重新启动时重新加载。如果没有给出配置文件或者配置文件路径不可写，Sentinel 将简单地拒绝启动。</p>
<p>Sentinels 默认运行 <strong>侦听 TCP 端口 26379 的连接</strong> ，因此要使 Sentinels 工作，您的服务器的端口 26379<strong>必须打开</strong>以接收来自其他 Sentinel 实例的 IP 地址的连接。否则 Sentinels 无法交谈，也无法就该做什么达成一致，因此永远不会执行故障转移。</p>
<h3 id="部署前需要了解的有关-Sentinel-的基本知识"><a href="#部署前需要了解的有关-Sentinel-的基本知识" class="headerlink" title="部署前需要了解的有关 Sentinel 的基本知识"></a>部署前需要了解的有关 Sentinel 的基本知识</h3><ol>
<li>您至少需要三个 Sentinel 实例才能进行可靠的部署。</li>
<li>三个 Sentinel 实例应该放置在被认为以独立方式发生故障的计算机或虚拟机中。因此，例如在不同可用区上执行的不同物理服务器或虚拟机。</li>
<li>Sentinel + Redis 分布式系统不保证在故障期间保留已确认的写入，因为 Redis 使用异步复制。然而，有一些部署 Sentinel 的方法可以使窗口丢失写入限制在某些时刻，同时还有其他不太安全的部署方法。</li>
<li>您的客户需要 Sentinel 支持。流行的客户端库有 Sentinel 支持，但不是全部。</li>
<li>如果您不时不时地在开发环境中进行测试，则没有任何 HA 设置是安全的，如果可以的话，在生产环境中如果它们可以工作则更好。您可能有一个错误配置，只有在为时已晚（凌晨 3 点，当您的主机停止工作时）才会变得明显。</li>
<li><strong>Sentinel、Docker 或其他形式的网络地址转换或端口映射应小心混合</strong> ：Docker 执行端口重新映射，打破 Sentinel 自动发现其他 Sentinel 进程和主节点的副本列表。查看本文档后面<a href="https://redis.io/docs/management/sentinel/#sentinel-docker-nat-and-possible-issues">有关<em>Sentinel 和 Docker的部分以获取更多信息。</em></a></li>
</ol>
<h3 id="配置哨兵"><a href="#配置哨兵" class="headerlink" title="配置哨兵"></a>配置哨兵</h3><p>Redis 源代码分发包含一个名为的文件，该文件<code>sentinel.conf</code> 是一个自我记录的示例配置文件，您可以使用它来配置 Sentinel，但是典型的最小配置文件如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">sentinel</span> <span class="string">monitor</span> <span class="string">mymaster</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="number">6379 </span><span class="number">2</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">down-after-milliseconds</span> <span class="string">mymaster</span> <span class="number">60000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">failover-timeout</span> <span class="string">mymaster</span> <span class="number">180000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">parallel-syncs</span> <span class="string">mymaster</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="string">sentinel</span> <span class="string">monitor</span> <span class="string">resque</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.3</span> <span class="number">6380 </span><span class="number">4</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">down-after-milliseconds</span> <span class="string">resque</span> <span class="number">10000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">failover-timeout</span> <span class="string">resque</span> <span class="number">180000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">parallel-syncs</span> <span class="string">resque</span> <span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>您只需要指定要监控的主控，为每个分离的主控（可能有任意数量的副本）指定一个不同的名称。无需指定自动发现的副本。Sentinel 将使用有关副本的附加信息自动更新配置（以便在重启时保留信息）。每次在故障转移期间将副本提升为主服务器以及每次发现新的 Sentinel 时，配置也会被重写。</p>
<p>上面的示例配置基本上监控两组 Redis 实例，每个实例由一个主实例和未定义数量的副本组成。一组实例称为<code>mymaster</code>，另一组实例称为<code>resque</code>。</p>
<p><code>sentinel monitor</code>语句参数的含义如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">sentinel monitor <span class="tag">&lt;<span class="name">master-group-name</span>&gt;</span> <span class="tag">&lt;<span class="name">ip</span>&gt;</span> <span class="tag">&lt;<span class="name">port</span>&gt;</span> <span class="tag">&lt;<span class="name">quorum</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>为了清楚起见，让我们逐行检查配置选项的含义：</p>
<p>第一行用于告诉 Redis 监控一个名为<em>mymaster</em>的主机，地址为 127.0.0.1，端口为 6379，法定人数为 2。一切都很明显，但<strong>法定人数</strong>参数：</p>
<ul>
<li><strong>法定人数</strong>是需要就 master 不可达这一事实达成一致的哨兵数量，以便真正将 master 标记为失败，并在可能的情况下最终启动故障转移程序。</li>
<li>然而 <strong>，仲裁仅用于检测故障</strong> 。为了实际执行故障转移，其中一个哨兵需要被选为故障转移的领导者并被授权继续进行。这只会发生在<strong>大多数 Sentinel 进程</strong>的投票中。</li>
</ul>
<p>因此，例如，如果您有 5 个 Sentinel 进程，并且给定 master 的 quorum 设置为 2 的值，则会发生以下情况：</p>
<ul>
<li>如果两个 Sentinels 同时同意 master 不可达，则两者之一将尝试启动故障转移。</li>
<li>如果总共至少有三个 Sentinels 可以访问，则故障转移将被授权并实际开始。</li>
</ul>
<p>实际上，这意味着在故障期间， <strong>如果大多数 Sentinel 进程无法通信</strong> （也就是少数分区中没有故障转移），Sentinel 永远不会启动故障转移。</p>
<h3 id="其他哨兵选项"><a href="#其他哨兵选项" class="headerlink" title="其他哨兵选项"></a>其他哨兵选项</h3><p>其他选项几乎总是采用以下形式：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">sentinel <span class="tag">&lt;<span class="name">option_name</span>&gt;</span> <span class="tag">&lt;<span class="name">master_name</span>&gt;</span> <span class="tag">&lt;<span class="name">option_value</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>并用于以下目的：</p>
<ul>
<li><code>down-after-milliseconds</code>是以毫秒为单位的时间，对于一个开始认为它已关闭的哨兵来说，一个实例应该无法访问（要么不回复我们的 PING，要么它正在回复一个错误）。</li>
<li><code>parallel-syncs</code>设置在故障转移后可以重新配置为同时使用新主服务器的副本数量。数字越低，完成故障转移过程所需的时间就越多，但是如果副本配置为提供旧数据，您可能不希望所有副本同时与主服务器重新同步。虽然副本的复制过程大部分是非阻塞的，但有时它会停止从主服务器加载批量数据。您可能希望通过将此选项设置为值 1 来确保一次只能访问一个副本。</li>
</ul>
<p>其他选项在本文档的其余部分进行了描述，并记录在<code>sentinel.conf</code>Redis 发行版附带的示例文件中。</p>
<p>配置参数可以在运行时修改：</p>
<ul>
<li>使用 .master 特定的配置参数进行修改<code>SENTINEL SET</code>。</li>
<li>全局配置参数使用<code>SENTINEL CONFIG SET</code>.</li>
</ul>
<p>有关详细信息，请参阅<a href="https://redis.io/docs/management/sentinel/#reconfiguring-sentinel-at-runtime"><em>在运行时重新配置 Sentinel</em>部分</a> 。</p>
<h3 id="Sentinel-部署示例"><a href="#Sentinel-部署示例" class="headerlink" title="Sentinel 部署示例"></a>Sentinel 部署示例</h3><p>现在您了解了有关 Sentinel 的基本信息，您可能想知道应该在哪里放置 Sentinel 进程、需要多少个 Sentinel 进程等等。本节展示了一些示例部署。</p>
<p>我们使用 ASCII 艺术，以便以<em>图形</em> 格式向您展示配置示例，这就是不同符号的含义：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> This <span class="keyword">is</span> a computer <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">or</span> VM that fails   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> independently. We  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">call</span> it a &quot;box&quot;    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br></pre></td></tr></table></figure>

<p>我们在框内写下它们正在运行的内容：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="addition">+-------------------+</span></span><br><span class="line">| Redis master M1   |</span><br><span class="line">| Redis Sentinel S1 |</span><br><span class="line"><span class="addition">+-------------------+</span></span><br></pre></td></tr></table></figure>

<p>不同的盒子用线连接起来，表示它们会说话：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">+<span class="comment">-------------+               +-------------+</span></span><br><span class="line">| Sentinel S1 |<span class="comment">---------------| Sentinel S2 |</span></span><br><span class="line">+<span class="comment">-------------+               +-------------+</span></span><br></pre></td></tr></table></figure>

<p>网络分区显示为使用斜线的中断线：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">+<span class="comment">-------------+                +-------------+</span></span><br><span class="line">| Sentinel S1 |<span class="comment">------ // ------| Sentinel S2 |</span></span><br><span class="line">+<span class="comment">-------------+                +-------------+</span></span><br></pre></td></tr></table></figure>

<p>另请注意：</p>
<ul>
<li>大师被称为M1，M2，M3，…，Mn。</li>
<li>副本称为 R1、R2、R3、…、Rn（R 代表 <em>副本</em> ）。</li>
<li>哨兵被称为 S1、S2、S3、…、Sn。</li>
<li>客户端称为 C1、C2、C3、…、Cn。</li>
<li>当一个实例因为 Sentinel 的动作而改变角色时，我们将其放在方括号内，因此 [M1] 表示一个实例由于 Sentinel 的干预而现在是主实例。</li>
</ul>
<p>请注意，我们永远不会显示 <strong>仅使用两个哨兵的设置</strong> ，因为哨兵总是需要<strong>与大多数人交谈</strong>才能启动故障转移。</p>
<h4 id="示例-1：只有两个哨兵，不要这样做"><a href="#示例-1：只有两个哨兵，不要这样做" class="headerlink" title="示例 1：只有两个哨兵，不要这样做"></a>示例 1：只有两个哨兵，不要这样做</h4><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">+<span class="comment">----+         +----+</span></span><br><span class="line">| M1 |<span class="comment">---------| R1 |</span></span><br><span class="line">| S1 |         | S2 |</span><br><span class="line">+<span class="comment">----+         +----+</span></span><br><span class="line"></span><br><span class="line">Configuration: quorum = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<ul>
<li>在此设置中，如果主节点 M1 发生故障，则 R1 将被提升，因为两个 Sentinels 可以就故障达成一致（显然将 quorum 设置为 1）并且还可以授权故障转移，因为多数是两个。所以很明显它可以表面上工作，但是检查接下来的几点以了解为什么这个设置被破坏了。</li>
<li>如果运行 M1 的盒子停止工作，则 S1 也停止工作。在另一个盒子 S2 中运行的 Sentinel 将无法授权故障转移，因此系统将变得不可用。</li>
</ul>
<p>请注意，需要大多数才能订购不同的故障转移，然后将最新配置传播到所有哨兵。另请注意，在没有任何协议的情况下，在上述设置的单侧进行故障转移的能力将非常危险：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">+<span class="comment">----+           +------+</span></span><br><span class="line">| M1 |<span class="comment">----//-----| [M1] |</span></span><br><span class="line">| S1 |           | S2   |</span><br><span class="line">+<span class="comment">----+           +------+</span></span><br></pre></td></tr></table></figure>

<p>在上面的配置中，我们以完全对称的方式创建了两个主节点（假设 S2 可以在未经授权的情况下进行故障转移）。客户端可能会无限期地向两侧写入，并且无法了解分区何时恢复，哪种配置是正确的，以防止 <em>永久性的脑裂情况</em> 。</p>
<p>因此，请始终<strong>在三个不同的盒子中部署至少三个 Sentinels 。</strong></p>
<h4 id="示例-2：三个盒子的基本设置"><a href="#示例-2：三个盒子的基本设置" class="headerlink" title="示例 2：三个盒子的基本设置"></a>示例 2：三个盒子的基本设置</h4><p>这是一个非常简单的设置，其优点是易于调整以提高安全性。它基于三个盒子，每个盒子都运行一个 Redis 进程和一个 Sentinel 进程。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">       +<span class="comment">----+</span></span><br><span class="line">       | M1 |</span><br><span class="line">       | S1 |</span><br><span class="line">       +<span class="comment">----+</span></span><br><span class="line">          |</span><br><span class="line">+<span class="comment">----+    |    +----+</span></span><br><span class="line">| R2 |<span class="comment">----+----| R3 |</span></span><br><span class="line">| S2 |         | S3 |</span><br><span class="line">+<span class="comment">----+         +----+</span></span><br><span class="line"></span><br><span class="line">Configuration: quorum = <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>如果主 M1 发生故障，S2 和 S3 将就故障达成一致，并能够授权故障转移，使客户端能够继续。</p>
<p>在每个 Sentinel 设置中，由于 Redis 使用异步复制，因此始终存在丢失某些写入的风险，因为给定的已确认写入可能无法到达提升为 master 的副本。然而，在上面的设置中，由于客户端被旧 master 分区，因此存在更高的风险，如下图所示：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">         +<span class="comment">----+</span></span><br><span class="line">         | M1 |</span><br><span class="line">         | S1 | &lt;- C1 (writes will be lost) </span><br><span class="line">         +<span class="comment">----+</span></span><br><span class="line">            |</span><br><span class="line">            /</span><br><span class="line">            /</span><br><span class="line">+<span class="comment">------+    |    +----+</span></span><br><span class="line">| [M2] |<span class="comment">----+----| R3 |</span></span><br><span class="line">| S2   |         | S3 |</span><br><span class="line">+<span class="comment">------+         +----+</span></span><br></pre></td></tr></table></figure>

<p>在这种情况下，网络分区隔离了旧的主节点 M1，因此副本 R2 被提升为主节点。但是，与旧 master 位于同一分区中的客户端（如 C1）可能会继续向旧 master 写入数据。这些数据将永远丢失，因为当分区恢复时，master 将被重新配置为新 master 的副本，并丢弃其数据集。</p>
<p>使用以下 Redis 复制功能可以缓解此问题，如果主服务器检测到它不再能够将其写入传输到指定数量的副本，则允许停止接受写入。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="built_in">min</span>-replicas-to-<span class="built_in">write</span> <span class="number">1</span></span><br><span class="line"><span class="built_in">min</span>-replicas-<span class="built_in">max</span>-lag <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>通过以上配置（请参阅 Redis 发行版中的自我注释<code>redis.conf</code>示例以获取更多信息），当 Redis 实例充当主实例时，如果它不能写入至少 1 个副本，将停止接受写入。由于复制是异步<em>的，因此无法写入</em>实际上意味着副本已断开连接，或者在超过指定<code>max-lag</code>秒数的时间内未向我们发送异步确认。</p>
<p>使用此配置，上例中的旧 Redis 主节点 M1 将在 10 秒后变得不可用。当分区恢复后，Sentinel 配置将汇聚到新配置，客户端 C1 将能够获取有效配置并继续使用新的 master。</p>
<p>然而天下没有免费的午餐。通过这种改进，如果两个副本都宕机了，master 将停止接受写入。这是一个权衡。</p>
<h4 id="示例-3：客户端框中的哨兵"><a href="#示例-3：客户端框中的哨兵" class="headerlink" title="示例 3：客户端框中的哨兵"></a>示例 3：客户端框中的哨兵</h4><p>有时我们只有两个 Redis box 可用，一个用于 master，一个用于 replica。示例 2 中的配置在这种情况下不可行，因此我们可以求助于以下内容，将 Sentinels 放置在客户端所在的位置：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">      +<span class="comment">----+         +----+</span></span><br><span class="line">      | M1 |<span class="comment">----+----| R1 |</span></span><br><span class="line">      |    |    |    |    |</span><br><span class="line">      +<span class="comment">----+    |    +----+</span></span><br><span class="line">                |</span><br><span class="line">   +<span class="comment">------------+------------+</span></span><br><span class="line">   |            |            |</span><br><span class="line">   |            |            |</span><br><span class="line">+<span class="comment">----+        +----+      +----+</span></span><br><span class="line">| C1 |        | C2 |      | C3 |</span><br><span class="line">| S1 |        | S2 |      | S3 |</span><br><span class="line">+<span class="comment">----+        +----+      +----+</span></span><br><span class="line"></span><br><span class="line">Configuration: quorum = <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>在此设置中，Sentinels 的观点与客户端相同：如果大多数客户端都可以访问 master，那很好。这里的C1、C2、C3是通用客户端，并不代表C1标识的是连接Redis的单个客户端。它更像是一个应用程序服务器、Rails 应用程序或类似的东西。</p>
<p>如果运行 M1 和 S1 的机器发生故障，故障转移将毫无问题地发生，但是很容易看出不同的网络分区会导致不同的行为。例如，如果客户端和 Redis 服务器之间的网络断开连接，则 Sentinel 将无法设置，因为 Redis 主服务器和副本服务器都将不可用。</p>
<p>请注意，如果 C3 与 M1 分区（对于上述网络几乎不可能，但对于不同的布局更有可能，或者由于软件层的故障），我们会遇到与示例 2 中描述的类似问题，不同之处在于在这里我们没有办法打破对称性，因为只有副本和主控，所以当主控与副本断开连接时不能停止接受查询，否则主控在副本故障期间将永远不可用。</p>
<p>所以这是一个有效的设置，但示例 2 中的设置具有优势，例如 Redis 的 HA 系统运行在与 Redis 本身相同的盒子中，这可能更易于管理，并且能够限制时间量少数分区中的master可以接收写入。</p>
<h4 id="示例-4：少于三个客户端的-Sentinel-客户端"><a href="#示例-4：少于三个客户端的-Sentinel-客户端" class="headerlink" title="示例 4：少于三个客户端的 Sentinel 客户端"></a>示例 4：少于三个客户端的 Sentinel 客户端</h4><p>如果客户端中的框少于三个（例如三个 Web 服务器），则无法使用示例 3 中描述的设置。在这种情况下，我们需要采用如下混合设置：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">      +<span class="comment">----+         +----+</span></span><br><span class="line">      | M1 |<span class="comment">----+----| R1 |</span></span><br><span class="line">      | S1 |    |    | S2 |</span><br><span class="line">      +<span class="comment">----+    |    +----+</span></span><br><span class="line">                |</span><br><span class="line">         +<span class="comment">------+-----+</span></span><br><span class="line">         |            |</span><br><span class="line">         |            |</span><br><span class="line">      +<span class="comment">----+        +----+</span></span><br><span class="line">      | C1 |        | C2 |</span><br><span class="line">      | S3 |        | S4 |</span><br><span class="line">      +<span class="comment">----+        +----+</span></span><br><span class="line"></span><br><span class="line">Configuration: quorum = <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>这类似于示例 3 中的设置，但在这里我们在可用的四个框中运行四个哨兵。如果主 M1 变得不可用，其他三个 Sentinels 将执行故障转移。</p>
<p>从理论上讲，此设置可以删除运行 C2 和 S4 的框，并将仲裁设置为 2。但是，如果我们的应用程序层没有高可用性，我们不太可能希望 Redis 端具有高可用性。</p>
<h3 id="Sentinel、Docker、NAT-和可能的问题"><a href="#Sentinel、Docker、NAT-和可能的问题" class="headerlink" title="Sentinel、Docker、NAT 和可能的问题"></a>Sentinel、Docker、NAT 和可能的问题</h3><p>Docker 使用一种称为端口映射的技术：与程序认为使用的端口相比，在 Docker 容器内运行的程序可能会暴露出不同的端口。这对于在同一服务器上同时使用相同端口运行多个容器很有用。</p>
<p>Docker 不是唯一发生这种情况的软件系统，还有其他网络地址转换设置可能会重新映射端口，有时不是端口而是 IP 地址。</p>
<p>重新映射端口和地址会以两种方式导致 Sentinel 出现问题：</p>
<ol>
<li>Sentinel 对其他 Sentinel 的自动发现不再有效，因为它基于<em>hello</em>消息，每个 Sentinel 在其中宣布它们正在侦听连接的端口和 IP 地址。但是 Sentinels 无法理解地址或端口被重新映射，因此它会通告一个不正确的信息以供其他 Sentinels 连接。</li>
<li>副本<a href="https://redis.io/commands/info"><code>INFO</code></a> 以类似的方式列在 Redis 主服务器的输出中：地址由主服务器检测，检查 TCP 连接的远程对等点，而端口由副本服务器在握手期间公布，但端口可能是错误的出于与第 1 点相同的原因。</li>
</ol>
<p>由于 Sentinels auto detect replicas using masters <a href="https://redis.io/commands/info"><code>INFO</code></a> output information，检测到的副本将无法访问，并且 Sentinel 将永远无法对 master 进行故障转移，因为从系统的角度来看没有好的副本，所以目前没有办法使用 Sentinel 监视一组使用 Docker 部署的主实例和副本实例， <strong>除非您指示 Docker 映射端口 1:1</strong> 。</p>
<p>对于第一个问题，如果您想使用带有转发端口的 Docker 运行一组 Sentinel 实例（或任何其他端口被重新映射的 NAT 设置），您可以使用以下两个 Sentinel 配置指令来强制 Sentinel 宣布一个具体的一组IP和端口：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">sentinel announce-ip <span class="tag">&lt;<span class="name">ip</span>&gt;</span></span><br><span class="line">sentinel announce-port <span class="tag">&lt;<span class="name">port</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>请注意，Docker 能够在 <em>主机网络模式下运行</em> （查看<code>--net=host</code>选项了解更多信息）。这应该不会产生任何问题，因为在此设置中不会重新映射端口。</p>
<h3 id="IP-地址和-DNS-名称"><a href="#IP-地址和-DNS-名称" class="headerlink" title="IP 地址和 DNS 名称"></a>IP 地址和 DNS 名称</h3><p>旧版本的 Sentinel 不支持主机名并且需要在任何地方指定 IP 地址。从版本 6.2 开始，Sentinel 可以<em>选择</em>支持主机名。</p>
<p><strong>默认情况下禁用此功能。如果您要启用 DNS&#x2F;主机名支持，请注意：</strong></p>
<ol>
<li>Redis 和 Sentinel 节点上的名称解析配置必须可靠并且能够快速解析地址。地址解析的意外延迟可能会对 Sentinel 产生负面影响。</li>
<li>您应该在任何地方都使用主机名，并避免混合使用主机名和 IP 地址。为此，分别对所有 Redis 和 Sentinel 实例使用<code>replica-announce-ip &lt;hostname&gt;</code>和<code>sentinel announce-ip &lt;hostname&gt;</code>。</li>
</ol>
<p>启用<code>resolve-hostnames</code>全局配置允许 Sentinel 接受主机名：</p>
<ul>
<li>作为<code>sentinel monitor</code>命令的一部分</li>
<li>作为副本地址，如果副本使用主机名值<code>replica-announce-ip</code></li>
</ul>
<p>Sentinel 将接受主机名作为有效输入并解析它们，但在宣布实例、更新配置文件等时仍会引用 IP 地址。</p>
<p>启用<code>announce-hostnames</code>全局配置会使 Sentinel 使用主机名。这会影响对客户端的回复、写入配置文件的值、<a href="https://redis.io/commands/replicaof"><code>REPLICAOF</code></a> 向副本发出的命令等。</p>
<p>此行为可能与所有可能明确需要 IP 地址的 Sentinel 客户端不兼容。</p>
<p>当客户端使用 TLS 连接到实例并且需要名称而不是 IP 地址来执行证书 ASN 匹配时，使用主机名可能很有用。</p>
<h2 id="快速教程"><a href="#快速教程" class="headerlink" title="快速教程"></a>快速教程</h2><p>在本文档的下一部分中，将逐步介绍有关<a href="https://redis.io/docs/management/sentinel/#sentinel-api"><em>Sentinel API 、配置和语义的所有详细信息。</em></a> 然而，对于想要尽快使用该系统的人来说，本节是一个教程，展示了如何配置 3 个 Sentinel 实例并与之交互。</p>
<p>这里我们假设实例在端口 5000、5001、5002 上执行。我们还假设您在端口 6379 上有一个正在运行的 Redis 主服务器，在端口 6380 上运行一个副本。我们将在整个过程中到处使用 IPv4 环回地址 127.0.0.1教程，假设您正在个人计算机上运行模拟。</p>
<p>三个 Sentinel 配置文件应如下所示：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">port</span> <span class="number">5000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">monitor</span> <span class="string">mymaster</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="number">6379 </span><span class="number">2</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">down-after-milliseconds</span> <span class="string">mymaster</span> <span class="number">5000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">failover-timeout</span> <span class="string">mymaster</span> <span class="number">60000</span></span><br><span class="line"><span class="string">sentinel</span> <span class="string">parallel-syncs</span> <span class="string">mymaster</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>其他两个配置文件将相同，但使用 5001 和 5002 作为端口号。</p>
<p>上述配置需要注意的几点：</p>
<ul>
<li>主集称为<code>mymaster</code>。它标识主服务器及其副本。由于每个<em>主集</em>都有不同的名称，因此 Sentinel 可以同时监视不同的主集和副本集。</li>
<li>quorum 被设置为值 2（<code>sentinel monitor</code>配置指令的最后一个参数）。</li>
<li>该<code>down-after-milliseconds</code>值为 5000 毫秒，即 5 秒，因此一旦我们在此时间内未收到来自 ping 的任何回复，master 将被检测为发生故障。</li>
</ul>
<p>启动三个 Sentinels 后，您会看到它们记录的一些消息，例如：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="addition">+monitor master mymaster 127.0.0.1 6379 quorum 2</span></span><br></pre></td></tr></table></figure>

<p>这是一个 Sentinel 事件，如果您使用稍后在发布&#x2F;订阅消息部分<a href="https://redis.io/commands/subscribe"><code>SUBSCRIBE</code></a> 中指定的事件名称，您可以通过发布&#x2F;订阅接收此类事件。<a href="https://redis.io/docs/management/sentinel/#pubsub-messages"></a> </p>
<p>Sentinel 在故障检测和故障转移期间生成并记录不同的事件。</p>
<h2 id="向-Sentinel-询问-master-的状态"><a href="#向-Sentinel-询问-master-的状态" class="headerlink" title="向 Sentinel 询问 master 的状态"></a>向 Sentinel 询问 master 的状态</h2><p>开始使用 Sentinel 最明显的事情是检查它正在监控的 master 是否运行良好：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>redis-cli -p <span class="number">5000</span></span><br><span class="line"><span class="meta prompt_">127.0.0.1:5000&gt;</span> sentinel master mymaster</span><br><span class="line"> <span class="number">1</span>)  <span class="string">&quot;name&quot;</span></span><br><span class="line"> <span class="number">2</span>)  <span class="string">&quot;mymaster&quot;</span></span><br><span class="line"> <span class="number">3</span>)  <span class="string">&quot;ip&quot;</span></span><br><span class="line"> <span class="number">4</span>)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line"> <span class="number">5</span>)  <span class="string">&quot;port&quot;</span></span><br><span class="line"> <span class="number">6</span>)  <span class="string">&quot;6379&quot;</span></span><br><span class="line"> <span class="number">7</span>)  <span class="string">&quot;runid&quot;</span></span><br><span class="line"> <span class="number">8</span>)  <span class="string">&quot;953ae6a589449c13ddefaee3538d356d287f509b&quot;</span></span><br><span class="line"> <span class="number">9</span>)  <span class="string">&quot;flags&quot;</span></span><br><span class="line"><span class="number">10</span>)  <span class="string">&quot;master&quot;</span></span><br><span class="line"><span class="number">11</span>)  <span class="string">&quot;link-pending-commands&quot;</span></span><br><span class="line"><span class="number">12</span>)  <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="number">13</span>)  <span class="string">&quot;link-refcount&quot;</span></span><br><span class="line"><span class="number">14</span>)  <span class="string">&quot;1&quot;</span></span><br><span class="line"><span class="number">15</span>)  <span class="string">&quot;last-ping-sent&quot;</span></span><br><span class="line"><span class="number">16</span>)  <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="number">17</span>)  <span class="string">&quot;last-ok-ping-reply&quot;</span></span><br><span class="line"><span class="number">18</span>)  <span class="string">&quot;735&quot;</span></span><br><span class="line"><span class="number">19</span>)  <span class="string">&quot;last-ping-reply&quot;</span></span><br><span class="line"><span class="number">20</span>)  <span class="string">&quot;735&quot;</span></span><br><span class="line"><span class="number">21</span>)  <span class="string">&quot;down-after-milliseconds&quot;</span></span><br><span class="line"><span class="number">22</span>)  <span class="string">&quot;5000&quot;</span></span><br><span class="line"><span class="number">23</span>)  <span class="string">&quot;info-refresh&quot;</span></span><br><span class="line"><span class="number">24</span>)  <span class="string">&quot;126&quot;</span></span><br><span class="line"><span class="number">25</span>)  <span class="string">&quot;role-reported&quot;</span></span><br><span class="line"><span class="number">26</span>)  <span class="string">&quot;master&quot;</span></span><br><span class="line"><span class="number">27</span>)  <span class="string">&quot;role-reported-time&quot;</span></span><br><span class="line"><span class="number">28</span>)  <span class="string">&quot;532439&quot;</span></span><br><span class="line"><span class="number">29</span>)  <span class="string">&quot;config-epoch&quot;</span></span><br><span class="line"><span class="number">30</span>)  <span class="string">&quot;1&quot;</span></span><br><span class="line"><span class="number">31</span>)  <span class="string">&quot;num-slaves&quot;</span></span><br><span class="line"><span class="number">32</span>)  <span class="string">&quot;1&quot;</span></span><br><span class="line"><span class="number">33</span>)  <span class="string">&quot;num-other-sentinels&quot;</span></span><br><span class="line"><span class="number">34</span>)  <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="number">35</span>)  <span class="string">&quot;quorum&quot;</span></span><br><span class="line"><span class="number">36</span>)  <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="number">37</span>)  <span class="string">&quot;failover-timeout&quot;</span></span><br><span class="line"><span class="number">38</span>)  <span class="string">&quot;60000&quot;</span></span><br><span class="line"><span class="number">39</span>)  <span class="string">&quot;parallel-syncs&quot;</span></span><br><span class="line"><span class="number">40</span>)  <span class="string">&quot;1&quot;</span></span><br></pre></td></tr></table></figure>

<p>如您所见，它打印了一些关于 master 的信息。我们特别感兴趣的有一些：</p>
<ol>
<li><code>num-other-sentinels</code>是 2，所以我们知道 Sentinel 已经为这个 master 检测到另外两个 Sentinel。如果您检查日志，您将看到<code>+sentinel</code>生成的事件。</li>
<li><code>flags</code>只是<code>master</code>. 如果 master 宕机了，我们也可以在这里看到<code>s_down</code>或<code>o_down</code>标记。</li>
<li><code>num-slaves</code>正确设置为 1，因此 Sentinel 还检测到我们的 master 有一个附加的副本。</li>
</ol>
<p>为了进一步了解此实例，您可能想尝试以下两个命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SENTINEL replicas mymaster</span><br><span class="line">SENTINEL sentinels mymaster</span><br></pre></td></tr></table></figure>

<p>第一个将提供有关连接到 master 的副本的类似信息，第二个将提供有关其他 Sentinels 的信息。</p>
<h2 id="获取当前master的地址"><a href="#获取当前master的地址" class="headerlink" title="获取当前master的地址"></a>获取当前master的地址</h2><p>正如我们已经指定的那样，Sentinel 还充当想要连接到一组主副本的客户端的配置提供程序。由于可能的故障转移或重新配置，客户端不知道谁是给定实例集的当前活动主机，因此 Sentinel 导出一个 API 来询问这个问题：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">5000</span>&gt; SENTINEL <span class="keyword">get</span>-master-addr-<span class="keyword">by</span>-name mymaster</span><br><span class="line"><span class="number">1</span>)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line"><span class="number">2</span>)  <span class="string">&quot;6379&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="测试故障转移"><a href="#测试故障转移" class="headerlink" title="测试故障转移"></a>测试故障转移</h3><p>此时我们的玩具 Sentinel 部署已准备好进行测试。我们可以杀死我们的主人并检查配置是否更改。为此，我们可以这样做：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">redis-cli -p 6379 DEBUG <span class="built_in">sleep</span> 30</span><br></pre></td></tr></table></figure>

<p>这个命令将使我们的主人不再可达，休眠 30 秒。它基本上模拟了由于某种原因而挂起的大师。</p>
<p>如果您查看 Sentinel 日志，您应该能够看到很多操作：</p>
<ol>
<li>每个 Sentinel 检测到 master 因<code>+sdown</code>事件而宕机。</li>
<li>此事件后来升级为<code>+odown</code>，这意味着多个 Sentinels 同意无法访问 master 的事实。</li>
<li>Sentinels 投票选出一个将开始第一次故障转移尝试的 Sentinel。</li>
<li>发生故障转移。</li>
</ol>
<p>如果您再次询问 的当前主地址是什么<code>mymaster</code>，最终我们这次应该会得到不同的答复：</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">5000</span>&gt; SENTINEL <span class="keyword">get</span>-master-addr-<span class="keyword">by</span>-name mymaster</span><br><span class="line"><span class="number">1</span>)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line"><span class="number">2</span>)  <span class="string">&quot;6380&quot;</span></span><br></pre></td></tr></table></figure>

<p>到目前为止一切顺利……此时您可以跳转到创建 Sentinel 部署，或者可以阅读更多内容以了解所有 Sentinel 命令和内部结构。</p>
<h2 id="哨兵-API"><a href="#哨兵-API" class="headerlink" title="哨兵 API"></a>哨兵 API</h2><p>Sentinel 提供 API 以检查其状态、检查受监控的主服务器和副本的健康状况、订阅以接收特定通知以及在运行时更改 Sentinel 配置。</p>
<p>默认情况下，Sentinel 使用 TCP 端口 26379 运行（请注意，6379 是正常的 Redis 端口）。Sentinels 使用 Redis 协议接受命令，因此您可以使用<code>redis-cli</code>或任何其他未修改的 Redis 客户端来与 Sentinel 对话。</p>
<p>可以直接查询 Sentinel，从它的角度检查受监视的 Redis 实例的状态，查看它知道的其他 Sentinel，等等。或者，使用 Pub&#x2F;Sub，可以在每次发生某些事件（如故障转移或实例进入错误状态等）时从 Sentinels接收<em>推送式通知。</em></p>
<h3 id="哨兵命令"><a href="#哨兵命令" class="headerlink" title="哨兵命令"></a>哨兵命令</h3><p>该<code>SENTINEL</code>命令是 Sentinel 的主要 API。以下是其子命令的列表（在适用的地方注明了最小版本）：</p>
<ul>
<li><strong>SENTINEL CONFIG GET<code>&lt;name&gt;</code></strong> ( <code>&gt;= 6.2</code>)  获取全局 Sentinel 配置参数的当前值。指定的名称可以是通配符，类似于 Redis<a href="https://redis.io/commands/config-get"><code>CONFIG GET</code></a> 命令。</li>
<li><strong>SENTINEL CONFIG SET<code>&lt;name&gt;</code> <code>&lt;value&gt;</code></strong> ( <code>&gt;= 6.2</code>)  设置全局 Sentinel 配置参数的值。</li>
<li><strong>SENTINEL CKQUORUM<code>&lt;master name&gt;</code></strong> 检查当前 Sentinel 配置是否能够达到故障转移 master 所需的法定人数，以及授权故障转移所需的多数。该命令应用于监控系统，以检查 Sentinel 部署是否正常。</li>
<li><strong>SENTINEL FLUSHCONFIG</strong>强制 Sentinel 重写其在磁盘上的配置，包括当前的 Sentinel 状态。通常，每次状态发生变化时，Sentinel 都会重写配置（在重启后持久保存在磁盘上的状态子集的上下文中）。但是有时由于操作错误、磁盘故障、软件包升级脚本或配置管理器，配置文件可能会丢失。在这些情况下，强制 Sentinel 重写配置文件的方法很方便。即使以前的配置文件完全丢失，此命令也能正常工作。</li>
<li><strong>SENTINEL FAILOVER<code>&lt;master name&gt;</code></strong> 强制进行故障转移，就好像 master 无法访问一样，并且不征求其他 Sentinels 的同意（但是将发布新版本的配置，以便其他 Sentinels 更新其配置）。</li>
<li><strong>SENTINEL GET-MASTER-ADDR-BY-NAME<code>&lt;master name&gt;</code></strong> 返回具有该名称的主机的 ip 和端口号。如果此主节点的故障转移正在进行或成功终止，它会返回提升副本的地址和端口。</li>
<li><strong>SENTINEL INFO-CACHE</strong> ( ) 从主服务器和副本服务器<code>&gt;= 3.2</code>返回缓存的输出。<a href="https://redis.io/commands/info"><code>INFO</code></a> </li>
<li>**SENTINEL IS-MASTER-DOWN-BY-ADDR **从当前 Sentinel 的角度检查 ip:port 指定的主机是否已关闭。此命令主要供内部使用。</li>
<li><strong>SENTINEL MASTER<code>&lt;master name&gt;</code></strong> 显示指定主机的状态和信息。</li>
<li><strong>SENTINEL MASTERS</strong>显示受监控主机及其状态的列表。</li>
<li><strong>SENTINEL MONITOR</strong>启动 Sentinel 的监控。有关详细信息，请参阅<a href="https://redis.io/docs/management/sentinel/#reconfiguring-sentinel-at-runtime"><em>在运行时重新配置 Sentinel</em>部分</a> 。</li>
<li><strong>SENTINEL MYID</strong> ( <code>&gt;= 6.2</code>)  返回 Sentinel 实例的 ID。</li>
<li><strong>SENTINEL PENDING-SCRIPTS</strong>此命令返回有关挂起脚本的信息。</li>
<li><strong>SENTINEL REMOVE</strong>停止 Sentinel 的监控。有关详细信息，请参阅<a href="https://redis.io/docs/management/sentinel/#reconfiguring-sentinel-at-runtime"><em>在运行时重新配置 Sentinel</em>部分</a> 。</li>
<li><strong>SENTINEL REPLICAS<code>&lt;master name&gt;</code></strong> ( <code>&gt;= 5.0</code>)  显示该主节点的副本列表及其状态。</li>
<li><strong>SENTINEL SENTINELS<code>&lt;master name&gt;</code></strong> 显示该主节点的哨兵实例列表及其状态。</li>
<li><strong>SENTINEL SET</strong>设置 Sentinel 的监控配置。有关详细信息，请参阅<a href="https://redis.io/docs/management/sentinel/#reconfiguring-sentinel-at-runtime"><em>在运行时重新配置 Sentinel</em>部分</a> 。</li>
<li>**SENTINEL SIMULATE-FAILURE (crash-after-election|crash-after-promotion|help) ** ( <code>&gt;= 3.2</code>)  此命令模拟不同的 Sentinel 崩溃场景。</li>
<li><strong>SENTINEL RESET<code>&lt;pattern&gt;</code></strong> 此命令将重置所有具有匹配名称的主机。pattern 参数是一个 glob 风格的模式。重置过程会清除 master 中的任何先前状态（包括正在进行的故障转移），并删除已发现并与 master 关联的每个副本和哨兵。</li>
</ul>
<p>出于连接管理和管理目的，Sentinel 支持以下 Redis 命令子集：</p>
<ul>
<li><strong>ACL</strong> ( <code>&gt;= 6.2</code>)  此命令管理 Sentinel 访问控制列表。有关详细信息，请参阅<a href="https://redis.io/topics/acl">ACL</a> 文档页面和<a href="https://redis.io/docs/management/sentinel/#sentinel-access-control-list-authentication"><em>Sentinel 访问控制列表身份验证</em></a> 。</li>
<li><strong>AUTH</strong> ( <code>&gt;= 5.0.1</code>)  验证客户端连接。有关详细信息，请参阅<a href="https://redis.io/commands/auth"><code>AUTH</code></a> 命令和<a href="https://redis.io/docs/management/sentinel/#configuring-sentinel-instances-with-authentication"><em>使用身份验证配置 Sentinel 实例</em>部分</a> 。</li>
<li><strong>CLIENT</strong>此命令管理客户端连接。有关详细信息，请参阅其子命令的页面。</li>
<li><strong>COMMAND</strong> ( <code>&gt;= 6.2</code>)  此命令返回有关命令的信息。有关详细信息，请参阅该<a href="https://redis.io/commands/command"><code>COMMAND</code></a> 命令及其各种子命令。</li>
<li><strong>HELLO</strong> ( <code>&gt;= 6.0</code>)  切换连接的协议。有关详细信息，请参阅<a href="https://redis.io/commands/hello"><code>HELLO</code></a> 命令。</li>
<li><strong>INFO</strong>返回有关 Sentinel 服务器的信息和统计信息。有关详细信息，请参阅<a href="https://redis.io/commands/info"><code>INFO</code></a> 命令。</li>
<li><strong>PING</strong>此命令仅返回 PONG。</li>
<li><strong>ROLE</strong>此命令返回字符串“sentinel”和受监控的主机列表。有关详细信息，请参阅<a href="https://redis.io/commands/role"><code>ROLE</code></a> 命令。</li>
<li><strong>SHUTDOWN</strong>关闭 Sentinel 实例。</li>
</ul>
<p>最后，Sentinel 还支持、<a href="https://redis.io/commands/subscribe"><code>SUBSCRIBE</code></a> 和<a href="https://redis.io/commands/unsubscribe"><code>UNSUBSCRIBE</code></a> 命令。有关详细信息，请参阅发布&#x2F;订阅消息部分。<a href="https://redis.io/commands/psubscribe"><code>PSUBSCRIBE</code></a> <a href="https://redis.io/commands/punsubscribe"><code>PUNSUBSCRIBE</code></a> <a href="https://redis.io/docs/management/sentinel/#pubsub-messages"></a> </p>
<h3 id="在运行时重新配置-Sentinel"><a href="#在运行时重新配置-Sentinel" class="headerlink" title="在运行时重新配置 Sentinel"></a>在运行时重新配置 Sentinel</h3><p>从 Redis 版本 2.8.4 开始，Sentinel 提供了一个 API 来添加、删除或更改给定 master 的配置。请注意，如果您有多个哨兵，则应将更改应用于所有实例，以使 Redis Sentinel 正常工作。这意味着更改单个 Sentinel 的配置不会自动将更改传播到网络中的其他 Sentinel。</p>
<p>以下是<code>SENTINEL</code>用于更新 Sentinel 实例配置的子命令列表。</p>
<ul>
<li><strong>SENTINEL MONITOR<code>&lt;name&gt;</code> <code>&lt;ip&gt;</code> <code>&lt;port&gt;</code> <code>&lt;quorum&gt;</code></strong> 此命令告诉 Sentinel 开始监视具有指定名称、ip、端口和仲裁的新主控。它与配置文件中的<code>sentinel monitor</code>配置指令相同<code>sentinel.conf</code>，不同之处在于您不能在 as 中使用主机名<code>ip</code>，但您需要提供 IPv4 或 IPv6 地址。</li>
<li><strong>SENTINEL REMOVE<code>&lt;name&gt;</code></strong> 用于移除指定的master：master将不再被监控，将完全从Sentinel的内部状态中移除，因此不再被列出<code>SENTINEL masters</code>等等。</li>
<li><strong>SENTINEL SET <code>&lt;name&gt;</code>[ <code>&lt;option&gt;</code> <code>&lt;value&gt;</code>…]</strong> SET 命令与 Redis 的命令非常相似，<a href="https://redis.io/commands/config-set"><code>CONFIG SET</code></a> 用于更改特定 master 的配置参数。可以指定多个选项&#x2F;值对（或根本不指定）。所有可以通过配置的配置参数也可以<code>sentinel.conf</code>使用 SET 命令配置。</li>
</ul>
<p>以下是<code>SENTINEL SET</code>命令示例，用于修改<code>down-after-milliseconds</code>名为 master 的配置<code>objects-cache</code>：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">SENTINEL <span class="keyword">SET</span> objects<span class="operator">-</span>cache<span class="operator">-</span>master down<span class="operator">-</span>after<span class="operator">-</span>milliseconds <span class="number">1000</span></span><br></pre></td></tr></table></figure>

<p>如前所述，<code>SENTINEL SET</code>可用于设置启动配置文件中可设置的所有配置参数。<code>SENTINEL REMOVE</code>此外，可以只更改 master quorum 配置，而无需删除并重新添加 master <code>SENTINEL MONITOR</code>，只需使用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">SENTINEL <span class="keyword">SET</span> objects<span class="operator">-</span>cache<span class="operator">-</span>master quorum <span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>请注意，没有等效的 GET 命令，因为<code>SENTINEL MASTER</code>它以易于解析的格式（作为字段&#x2F;值对数组）提供所有配置参数。</p>
<p>从 Redis 6.2 版本开始，Sentinel 还允许获取和设置全局配置参数，这些参数仅在之前的配置文件中受支持。</p>
<ul>
<li><strong>SENTINEL CONFIG GET<code>&lt;name&gt;</code></strong> 获取全局 Sentinel 配置参数的当前值。指定的名称可以是通配符，类似于 Redis<a href="https://redis.io/commands/config-get"><code>CONFIG GET</code></a> 命令。</li>
<li><strong>SENTINEL CONFIG SET<code>&lt;name&gt;</code> <code>&lt;value&gt;</code></strong> 设置全局 Sentinel 配置参数的值。</li>
</ul>
<p>可以操纵的全局参数包括：</p>
<ul>
<li><code>resolve-hostnames</code>, <code>announce-hostnames</code>. 请参阅<a href="https://redis.io/docs/management/sentinel/#ip-addresses-and-dns-names"><em>IP 地址和 DNS 名称</em></a> 。</li>
<li><code>announce-ip</code>, <code>announce-port</code>. 请参阅<a href="https://redis.io/docs/management/sentinel/#sentinel-docker-nat-and-possible-issues"><em>Sentinel、Docker、NAT 和可能的问题</em></a> 。</li>
<li><code>sentinel-user</code>, <code>sentinel-pass</code>. 请参阅<a href="https://redis.io/docs/management/sentinel/#configuring-sentinel-instances-with-authentication"><em>使用身份验证配置 Sentinel 实例</em></a> 。</li>
</ul>
<h3 id="添加或删除哨兵"><a href="#添加或删除哨兵" class="headerlink" title="添加或删除哨兵"></a>添加或删除哨兵</h3><p>由于 Sentinel 实施的自动发现机制，将新的 Sentinel 添加到您的部署是一个简单的过程。您需要做的就是启动配置为监视当前活动主节点的新 Sentinel。在 10 秒内，Sentinel 将获取其他 Sentinel 的列表和附加到 master 的副本集。</p>
<p>如果需要一次添加多个Sentinels，建议一个接一个添加，等待所有其他Sentinels都知道第一个再添加下一个。这对于仍然保证只能在分区的一侧实现多数是有用的，因为在添加新哨兵的过程中可能会发生失败。</p>
<p>这可以通过在没有网络分区的情况下延迟 30 秒添加每个新的 Sentinel 来轻松实现。</p>
<p>在该过程结束时，可以使用该命令 <code>SENTINEL MASTER mastername</code>来检查是否所有哨兵都同意监视主站的哨兵总数。</p>
<p>删除 Sentinel 有点复杂： <strong>Sentinels 永远不会忘记已经看到的 Sentinels</strong> ，即使它们很长时间都无法访问，因为我们不想动态更改授权故障转移和创建新配置所需的多数数字。因此，为了删除 Sentinel，应在没有网络分区的情况下执行以下步骤：</p>
<ol>
<li>停止要删除的 Sentinel 的 Sentinel 进程。</li>
<li><code>SENTINEL RESET *</code>向所有其他 Sentinel 实例发送命令（<code>*</code>如果您只想重置一个主机，则可以使用确切的主机名称）。一个接一个，实例之间至少等待 30 秒。</li>
<li>通过检查每个哨兵的输出，检查所有哨兵是否同意当前活跃的哨兵数量<code>SENTINEL MASTER mastername</code>。</li>
</ol>
<h3 id="删除旧的-master-或无法访问的副本"><a href="#删除旧的-master-或无法访问的副本" class="headerlink" title="删除旧的 master 或无法访问的副本"></a>删除旧的 master 或无法访问的副本</h3><p>哨兵永远不会忘记给定主人的副本，即使他们长时间无法访问。这很有用，因为哨兵应该能够在网络分区或故障事件后正确地重新配置返回的副本。</p>
<p>此外，在故障转移之后，故障转移的主服务器实际上被添加为新主服务器的副本，这样它将被重新配置为在它再次可用时立即与新主服务器一起复制。</p>
<p>然而，有时你想从 Sentinels 监控的副本列表中永远删除一个副本（可能是旧的 master）。</p>
<p>为此，您需要向所有 Sentinels 发送命令：它们将在接下来的 10 秒内刷新副本列表，仅添加从当前主输出中<code>SENTINEL RESET mastername</code>列为正确复制的副本。<a href="https://redis.io/commands/info"><code>INFO</code></a> </p>
<h3 id="发布-x2F-订阅消息"><a href="#发布-x2F-订阅消息" class="headerlink" title="发布&#x2F;订阅消息"></a>发布&#x2F;订阅消息</h3><p>客户端可以将 Sentinel 用作与 Redis 兼容的 Pub&#x2F;Sub 服务器（但您不能使用<a href="https://redis.io/commands/publish"><code>PUBLISH</code></a> ）来发送<a href="https://redis.io/commands/subscribe"><code>SUBSCRIBE</code></a> 或<a href="https://redis.io/commands/psubscribe"><code>PSUBSCRIBE</code></a> 发送通道并获得有关特定事件的通知。</p>
<p>频道名称与事件名称相同。例如，指定的通道<code>+sdown</code>将收到与实例相关的所有通知，这些通知进入一个<code>SDOWN</code>（SDOWN 意味着从您正在查询的 Sentinel 的角度来看该实例不再可访问）条件。</p>
<p>要获取所有消息，只需使用订阅即可<code>PSUBSCRIBE *</code>。</p>
<p>以下是您可以使用此 API 接收的频道和消息格式的列表。第一个字是频道&#x2F;事件名称，其余是数据的格式。</p>
<p>注意：在指定<em>实例详细信息</em>的地方，这意味着提供了以下参数来标识目标实例：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">instance-type</span>&gt;</span> <span class="tag">&lt;<span class="name">name</span>&gt;</span> <span class="tag">&lt;<span class="name">ip</span>&gt;</span> <span class="tag">&lt;<span class="name">port</span>&gt;</span> @ <span class="tag">&lt;<span class="name">master-name</span>&gt;</span> <span class="tag">&lt;<span class="name">master-ip</span>&gt;</span> <span class="tag">&lt;<span class="name">master-port</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>标识 master 的部分（从 @ 参数到末尾）是可选的，仅当实例本身不是 master 时才指定。</p>
<ul>
<li><strong>+reset-master</strong> <code>&lt;instance details&gt;</code> – master 被重置。</li>
<li><strong>+slave</strong> <code>&lt;instance details&gt;</code> – 检测到并附加了一个新的副本。</li>
<li><strong>+failover-state-reconf-slaves</strong> <code>&lt;instance details&gt;</code> – 故障转移状态更改为<code>reconf-slaves</code>状态。</li>
<li><strong>+failover-detected</strong> <code>&lt;instance details&gt;</code> – 检测到由另一个 Sentinel 或任何其他外部实体启动的故障转移（连接的副本变成主服务器）。</li>
<li><strong>+slave-reconf-sent</strong> <code>&lt;instance details&gt;</code> – leader sentinel<a href="https://redis.io/commands/replicaof"><code>REPLICAOF</code></a> 向这个实例发送命令，以便为新副本重新配置它。</li>
<li><strong>+slave-reconf-inprog</strong> <code>&lt;instance details&gt;</code> – 被重新配置的副本显示为新主 ip:port 对的副本，但同步过程尚未完成。</li>
<li><strong>+slave-reconf-done</strong> <code>&lt;instance details&gt;</code> – 副本现在与新的主服务器同步。</li>
<li><strong>-dup-sentinel</strong> <code>&lt;instance details&gt;</code> – 指定主站的一个或多个哨兵被删除为重复（这发生在哨兵实例重新启动时）。</li>
<li><strong>+sentinel</strong> <code>&lt;instance details&gt;</code> – 检测到并附加了此 master 的新哨兵。</li>
<li><strong>+sdown</strong> <code>&lt;instance details&gt;</code> – 指定的实例现在处于 Subjectively Down 状态。</li>
<li><strong>-sdown</strong> <code>&lt;instance details&gt;</code> – 指定的实例不再处于 Subjectively Down 状态。</li>
<li><strong>+odown</strong> <code>&lt;instance details&gt;</code> – 指定的实例现在处于 Objectively Down 状态。</li>
<li><strong>-odown</strong> <code>&lt;instance details&gt;</code> – 指定的实例不再处于 Objectively Down 状态。</li>
<li><strong>+new-epoch</strong> <code>&lt;instance details&gt;</code> – 当前纪元已更新。</li>
<li><strong>+try-failover</strong> <code>&lt;instance details&gt;</code> – 正在进行新的故障转移，等待被多数人选出。</li>
<li><strong>+elected-leader</strong> <code>&lt;instance details&gt;</code> – 赢得了指定时期的选举，可以进行故障转移。</li>
<li><strong>+failover-state-select-slave</strong> <code>&lt;instance details&gt;</code> – 新的故障转移状态是<code>select-slave</code>：我们正在尝试找到合适的副本进行升级。</li>
<li><strong>no-good-slave</strong> <code>&lt;instance details&gt;</code> – 没有好的副本可以提升。目前我们将在一段时间后尝试，但可能这会改变并且在这种情况下状态机将完全中止故障转移。</li>
<li><strong>selected-slave</strong> <code>&lt;instance details&gt;</code> – 我们找到了要提升的指定好的副本。</li>
<li><strong>failover-state-send-slaveof-noone——</strong> <code>&lt;instance details&gt;</code>我们正在尝试将提升的副本重新配置为主副本，等待它切换。</li>
<li><strong>failover-end-for-timeout——</strong> <code>&lt;instance details&gt;</code>故障转移因超时而终止，副本最终将被配置为与新的主服务器一起复制。</li>
<li><strong>failover-</strong> <code>&lt;instance details&gt;</code> end——故障转移成功终止。所有的副本似乎都被重新配置为与新的主人一起复制。</li>
<li><strong>switch-master</strong> <code>&lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</code> – master 的新 IP 和地址是配置更改后指定的。这是 <strong>大多数外部用户感兴趣的消息</strong> 。</li>
<li><strong>+tilt</strong> – 倾斜模式进入。</li>
<li><strong>-tilt</strong> – 倾斜模式退出。</li>
</ul>
<h3 id="处理-BUSY-状态"><a href="#处理-BUSY-状态" class="headerlink" title="处理 -BUSY 状态"></a>处理 -BUSY 状态</h3><p>当 Lua 脚本运行时间超过配置的 Lua 脚本时间限制时，Redis 实例返回 -BUSY 错误。当在触发故障转移之前发生这种情况时，Redis Sentinel 将尝试发送<a href="https://redis.io/commands/script-kill"><code>SCRIPT KILL</code></a>  命令，只有在脚本是只读的情况下才会成功。</p>
<p>如果在这次尝试之后实例仍然处于错误状态，它最终将被故障转移。</p>
<h2 id="副本优先级"><a href="#副本优先级" class="headerlink" title="副本优先级"></a>副本优先级</h2><p>Redis 实例有一个名为<code>replica-priority</code>. 此信息由 Redis 副本实例在其<a href="https://redis.io/commands/info"><code>INFO</code></a> 输出中公开，Sentinel 使用它来从可用于故障转移主服务器的副本中选择一个副本：</p>
<ol>
<li>如果副本优先级设置为 0，则副本永远不会提升为主副本。</li>
<li>Sentinel 优先选择优先级<em>较低</em>的副本。</li>
</ol>
<p>例如当前master同一个数据中心有一个副本S1，另一个数据中心有另一个副本S2，可以设置S1的优先级为10，S2的优先级为100，这样如果master 失败，S1 和 S2 都可用，S1 将是首选。</p>
<p>有关副本选择方式的更多信息，请查看本文档的<a href="https://redis.io/docs/management/sentinel/#replica-selection-and-priority"><em>副本选择和优先级</em>部分</a> 。</p>
<h3 id="Sentinel-和-Redis-身份验证"><a href="#Sentinel-和-Redis-身份验证" class="headerlink" title="Sentinel 和 Redis 身份验证"></a>Sentinel 和 Redis 身份验证</h3><p>当主服务器配置为需要来自客户端的身份验证时，作为一种安全措施，副本也需要知道凭据以便与主服务器进行身份验证并创建用于异步复制协议的主副本连接。</p>
<h2 id="Redis-访问控制列表身份验证"><a href="#Redis-访问控制列表身份验证" class="headerlink" title="Redis 访问控制列表身份验证"></a>Redis 访问控制列表身份验证</h2><p>从 Redis 6 开始，用户身份验证和权限由<a href="https://redis.io/topics/acl">访问控制列表 (ACL) </a> 管理。</p>
<p>为了让哨兵在配置了 ACL 时连接到 Redis 服务器实例，哨兵配置必须包括以下指令：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">sentinel auth-user <span class="tag">&lt;<span class="name">master-group-name</span>&gt;</span> <span class="tag">&lt;<span class="name">username</span>&gt;</span></span><br><span class="line">sentinel auth-pass <span class="tag">&lt;<span class="name">master-group-name</span>&gt;</span> <span class="tag">&lt;<span class="name">password</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>访问组实例的用户名和密码<code>&lt;username&gt;</code>在哪里？<code>&lt;password&gt;</code>应在组的所有 Redis 实例上提供这些凭据，并具有最小控制权限。例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ACL SETUSER sentinel-user ON &gt;somepassword allchannels +multi +slaveof +ping +<span class="built_in">exec</span> +subscribe +config|rewrite +role +publish +info +client|setname +client|<span class="built_in">kill</span> +script|<span class="built_in">kill</span></span><br></pre></td></tr></table></figure>

<h3 id="Redis-仅密码身份验证"><a href="#Redis-仅密码身份验证" class="headerlink" title="Redis 仅密码身份验证"></a>Redis 仅密码身份验证</h3><p>在 Redis 6 之前，身份验证是使用以下配置指令实现的：</p>
<ul>
<li><code>requirepass</code>在 master 中，为了设置身份验证密码，并确保实例不会处理未经身份验证的客户端的请求。</li>
<li><code>masterauth</code>在副本中，以便副本与主服务器进行身份验证，以便从中正确复制数据。</li>
</ul>
<p>当使用 Sentinel 时，没有单一的主控，因为在故障转移后副本可能扮演主控的角色，并且可以重新配置旧的主控以充当副本，所以你要做的是在中设置上述指令您所有的实例，包括主实例和副本。</p>
<p>这通常也是一个明智的设置，因为您不想只保护主服务器中的数据，而在副本中可以访问相同的数据。</p>
<p>但是，在不常见的情况下，您需要一个无需身份验证即可访问的副本，您仍然可以通过将<strong>副本优先级设置为 0</strong>来实现，以防止将此副本提升为主副本，并在此副本中仅配置<code>masterauth</code>指令，不使用该<code>requirepass</code>指令，以便未经身份验证的客户端可以读取数据。</p>
<p>为了让 Sentinels 在配置时连接到 Redis 服务器实例<code>requirepass</code>，Sentinel 配置必须包含 <code>sentinel auth-pass</code>指令，格式为：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">sentinel auth-pass <span class="tag">&lt;<span class="name">master-group-name</span>&gt;</span> <span class="tag">&lt;<span class="name">password</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="使用身份验证配置-Sentinel-实例"><a href="#使用身份验证配置-Sentinel-实例" class="headerlink" title="使用身份验证配置 Sentinel 实例"></a>使用身份验证配置 Sentinel 实例</h2><p>Sentinel 实例本身可以通过要求客户端通过<a href="https://redis.io/commands/auth"><code>AUTH</code></a> 命令进行身份验证来保护。从 Redis 6.2 开始，<a href="https://redis.io/topics/acl">访问控制列表 (ACL) </a> 可用，而以前的版本（从 Redis 5.0.1 开始）支持仅密码身份验证。</p>
<p>请注意，Sentinel 的身份验证配置应<strong>应用于</strong>部署中的每个实例，并且 <strong>所有实例都应使用相同的配置</strong> 。此外，ACL 和仅密码身份验证不应一起使用。</p>
<h3 id="Sentinel-访问控制列表身份验证"><a href="#Sentinel-访问控制列表身份验证" class="headerlink" title="Sentinel 访问控制列表身份验证"></a>Sentinel 访问控制列表身份验证</h3><p>使用 ACL 保护 Sentinel 实例的第一步是防止对其进行任何未经授权的访问。为此，您需要禁用默认超级用户（或至少为其设置一个强密码）并创建一个新超级用户并允许其访问 Pub&#x2F;Sub 频道：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">127.0.0.1:5000&gt;</span> <span class="variable constant_">ACL</span> <span class="variable constant_">SETUSER</span> admin <span class="variable constant_">ON</span> &gt;admin-password allchannels +<span class="variable">@all</span></span><br><span class="line"><span class="variable constant_">OK</span></span><br><span class="line"><span class="meta prompt_">127.0.0.1:5000&gt;</span> <span class="variable constant_">ACL</span> <span class="variable constant_">SETUSER</span> default off</span><br><span class="line"><span class="variable constant_">OK</span></span><br></pre></td></tr></table></figure>

<p>Sentinel 使用默认用户连接到其他实例。您可以使用以下配置指令提供另一个超级用户的凭据：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">sentinel sentinel-user <span class="tag">&lt;<span class="name">username</span>&gt;</span></span><br><span class="line">sentinel sentinel-pass <span class="tag">&lt;<span class="name">password</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><code>&lt;username&gt;</code>Sentinel 的超级用户和<code>&lt;password&gt;</code>密码分别在哪里（例如<code>admin</code>，<code>admin-password</code>在上面的示例中）。</p>
<p>最后，为了验证传入的客户端连接，您可以创建一个 Sentinel 受限用户配置文件，如下所示：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">5000</span><span class="operator">&gt;</span> ACL SETUSER sentinel<span class="operator">-</span><span class="keyword">user</span> <span class="keyword">ON</span> <span class="operator">&gt;</span><span class="keyword">user</span><span class="operator">-</span>password <span class="operator">-</span><span class="variable">@all</span> <span class="operator">+</span>auth <span class="operator">+</span>client<span class="operator">|</span>getname <span class="operator">+</span>client<span class="operator">|</span>id <span class="operator">+</span>client<span class="operator">|</span>setname <span class="operator">+</span>command <span class="operator">+</span>hello <span class="operator">+</span>ping <span class="operator">+</span>role <span class="operator">+</span>sentinel<span class="operator">|</span><span class="keyword">get</span><span class="operator">-</span>master<span class="operator">-</span>addr<span class="operator">-</span><span class="keyword">by</span><span class="operator">-</span>name <span class="operator">+</span>sentinel<span class="operator">|</span>master <span class="operator">+</span>sentinel<span class="operator">|</span>myid <span class="operator">+</span>sentinel<span class="operator">|</span>replicas <span class="operator">+</span>sentinel<span class="operator">|</span>sentinels</span><br></pre></td></tr></table></figure>

<p>有关更多信息，请参阅您选择的 Sentinel 客户端的文档。</p>
<h3 id="Sentinel-仅密码身份验证"><a href="#Sentinel-仅密码身份验证" class="headerlink" title="Sentinel 仅密码身份验证"></a>Sentinel 仅密码身份验证</h3><p>要使用仅密码身份验证的 Sentinel，请将<code>requirepass</code>配置指令添加到<strong>所有</strong>Sentinel 实例，如下所示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">requirepass <span class="string">&quot;your_password_here&quot;</span></span><br></pre></td></tr></table></figure>

<p>当以这种方式配置时，哨兵将做两件事：</p>
<ol>
<li>客户端需要密码才能向 Sentinels 发送命令。这是显而易见的，因为这通常是这种配置指令在 Redis 中的工作方式。</li>
<li>此外，配置用于访问本地 Sentinel 的相同密码将由该 Sentinel 实例使用，以便对其连接的所有其他 Sentinel 实例进行身份验证。</li>
</ol>
<p>这意味着 <strong>您必须<code>requirepass</code>在所有 Sentinel 实例中配置相同的密码</strong> 。这样，每个 Sentinel 都可以与其他所有 Sentinel 通信，而无需为每个 Sentinel 配置访问所有其他 Sentinel 的密码，这是非常不切实际的。</p>
<p>在使用此配置之前，请确保您的客户端库可以将<a href="https://redis.io/commands/auth"><code>AUTH</code></a> 命令发送到 Sentinel 实例。</p>
<h3 id="哨兵客户端实现"><a href="#哨兵客户端实现" class="headerlink" title="哨兵客户端实现"></a>哨兵客户端实现</h3><hr>
<p>Sentinel 需要明确的客户端支持，除非系统配置为执行一个脚本，该脚本将所有请求透明重定向到新的主实例（虚拟 IP 或其他类似系统）。客户端库实现的主题包含在文档<a href="https://redis.io/topics/sentinel-clients">Sentinel 客户端指南</a> 中。</p>
<h2 id="更高级的概念"><a href="#更高级的概念" class="headerlink" title="更高级的概念"></a>更高级的概念</h2><p>在以下部分中，我们将介绍有关 Sentinel 工作原理的一些细节，而无需诉诸将在本文档最后部分介绍的实现细节和算法。</p>
<h3 id="SDOWN-和-ODOWN-故障状态"><a href="#SDOWN-和-ODOWN-故障状态" class="headerlink" title="SDOWN 和 ODOWN 故障状态"></a>SDOWN 和 ODOWN 故障状态</h3><p>Redis Sentinel 有两个不同的<em>停机</em>概念，一个称为<em>主观停机</em>条件 (SDOWN) ，是给定 Sentinel 实例本地的停机条件。另一个称为<em>客观停机</em> 条件 (ODOWN) ，当足够多的 Sentinels（至少配置为<code>quorum</code>受监控主机的参数的数量）具有 SDOWN 条件并使用该<code>SENTINEL is-master-down-by-addr</code>命令从其他 Sentinels 获得反馈时，就会达到此条件。</p>
<p><code>is-master-down-after-milliseconds</code> 从 Sentinel 的角度来看，当它在配置中作为参数指定的秒数内没有收到对 PING 请求的有效回复时，就达到了 SDOWN 条件。</p>
<p>对 PING 的可接受回复是以下之一：</p>
<ul>
<li>PING 回复 +PONG。</li>
<li>PING 回复 -LOADING 错误。</li>
<li>PING 回复 -MASTERDOWN 错误。</li>
</ul>
<p>任何其他回复（或根本不回复）均被视为无效。但是请注意， <strong>在 INFO 输出中将自己通告为副本的逻辑主机被认为已关闭</strong> 。</p>
<p>请注意，SDOWN 要求在配置的整个时间间隔内未收到可接受的回复，因此例如，如果时间间隔为 30000 毫秒（30 秒）并且我们每 29 秒收到一次可接受的 ping 回复，则该实例被认为正在运行。</p>
<p>SDOWN 不足以触发故障转移：它仅意味着单个 Sentinel 认为 Redis 实例不可用。要触发故障转移，必须达到 ODOWN 状态。</p>
<p>要从 SDOWN 切换到 ODOWN，没有使用强共识算法，而只是一种八卦形式：如果给定的 Sentinel 收到报告， <strong>在给定的时间范围内</strong> ，master 没有从足够的 Sentinels 工作，则 SDOWN 被提升为 ODOWN。如果此确认稍后丢失，则清除该标志。</p>
<p>为了真正开始故障转移，需要使用实际多数的更严格的授权，但如果不达到 ODOWN 状态，则不会触发故障转移。</p>
<p>ODOWN 条件 <strong>仅适用于 masters</strong> 。对于其他类型的实例，哨兵不需要采取行动，因此副本和其他哨兵永远不会达到 ODOWN 状态，但只有 SDOWN 可以。</p>
<p>然而，SDOWN 也有语义含义。例如，处于 SDOWN 状态的副本未被选择由执行故障转移的 Sentinel 提升。</p>
<h2 id="哨兵和副本自动发现"><a href="#哨兵和副本自动发现" class="headerlink" title="哨兵和副本自动发现"></a>哨兵和副本自动发现</h2><p>Sentinels 与其他 Sentinels 保持连接，以相互检查彼此的可用性并交换消息。但是，您不需要在运行的每个 Sentinel 实例中配置其他 Sentinel 地址的列表，因为 Sentinel 使用 Redis 实例发布&#x2F;订阅功能来发现监视相同主节点和副本的其他 Sentinel。</p>
<p>此功能是通过将<em>问候消息发送</em>到名为 的频道 来实现的<code>__sentinel__:hello</code>。</p>
<p>同样，您不需要配置附加到主服务器的副本列表，因为 Sentinel 会自动发现此列表以查询 Redis。</p>
<ul>
<li>每个哨兵<code>__sentinel__:hello</code>每两秒向每个受监控的主控和副本 Pub&#x2F;Sub 通道发布一条消息，通过 ip、端口、runid 宣布它的存在。</li>
<li>每个 Sentinel 都订阅了<code>__sentinel__:hello</code>每个 master 和 replica 的 Pub&#x2F;Sub 频道，寻找未知的 sentinel。当检测到新的 sentinel 时，它们将被添加为该 master 的 sentinel。</li>
<li>Hello 消息还包括 master 的完整当前配置。如果接收 Sentinel 的给定 master 的配置比收到的要旧，它会立即更新为新配置。</li>
<li>在向主服务器添加新哨兵之前，哨兵总是检查是否已经存在具有相同 runid 或相同地址（ip 和端口对）的哨兵。在这种情况下，所有匹配的哨兵都将被删除，并添加新的。</li>
</ul>
<h2 id="在故障转移过程之外对实例进行-Sentinel-重新配置"><a href="#在故障转移过程之外对实例进行-Sentinel-重新配置" class="headerlink" title="在故障转移过程之外对实例进行 Sentinel 重新配置"></a>在故障转移过程之外对实例进行 Sentinel 重新配置</h2><p>即使没有进行故障转移，Sentinels 也会始终尝试在受监控的实例上设置当前配置。具体来说：</p>
<ul>
<li>声称是主人的副本（根据当前配置）将被配置为与当前主人一起复制的副本。</li>
<li>连接到错误主机的副本将被重新配置为与正确的主机复制。</li>
</ul>
<p>对于重新配置副本的哨兵，必须观察错误配置一段时间，该时间大于用于广播新配置的时间。</p>
<p>这可以防止具有陈旧配置的哨兵（例如，因为它们刚刚从分区重新加入）在接收更新之前尝试更改副本配置。</p>
<p>还要注意始终尝试强加当前配置的语义如何使故障转移对分区更具抵抗力：</p>
<ul>
<li>故障转移的主机在恢复可用时被重新配置为副本。</li>
<li>在分区期间分区的副本一旦可访问就会重新配置。</li>
</ul>
<p>关于本节要记住的重要教训是： <strong>Sentinel 是一个系统，其中每个进程将始终尝试将最后的逻辑配置强加给受监视实例集</strong> 。</p>
<h3 id="副本选择和优先级"><a href="#副本选择和优先级" class="headerlink" title="副本选择和优先级"></a>副本选择和优先级</h3><p>当一个 Sentinel 实例准备执行故障转移时，由于 master 处于<code>ODOWN</code>状态并且 Sentinel 从大多数已知的 Sentinel 实例中获得了故障转移的授权，因此需要选择一个合适的副本。</p>
<p>副本选择过程评估有关副本的以下信息：</p>
<ol>
<li>与主站断开连接的时间。</li>
<li>副本优先级。</li>
<li>已处理复制偏移量。</li>
<li>运行标识。</li>
</ol>
<p>发现与主服务器断开连接的副本超过配置的主服务器超时（毫秒后关闭选项）的十倍，加上从执行故障转移的 Sentinel 的角度来看主服务器也不可用的时间，被认为不适合故障转移并被跳过。</p>
<p>更严格地说，一个副本的<a href="https://redis.io/commands/info"><code>INFO</code></a> 输出表明它与主服务器断开连接的时间超过：</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">(down-after-milliseconds * <span class="number">10</span>)  + milliseconds_since_master_is_in_SDOWN_state</span><br></pre></td></tr></table></figure>

<p>被认为是不可靠的，完全被忽视。</p>
<p>副本选择只考虑通过上述测试的副本，并根据上述标准对其进行排序，顺序如下。</p>
<ol>
<li>副本按照Redis 实例文件中的<code>replica-priority</code>配置排序。<code>redis.conf</code>较低的优先级将是首选。</li>
<li>如果优先级相同，则检查副本处理的复制偏移量，并选择从主服务器接收到更多数据的副本。</li>
<li>如果多个副本具有相同的优先级并处理来自主服务器的相同数据，则执行进一步检查，选择具有字典序较小运行 ID 的副本。具有较低的运行 ID 对于副本来说并不是真正的优势，但有助于使副本选择过程更具确定性，而不是求助于选择随机副本。</li>
</ol>
<p>在大多数情况下，<code>replica-priority</code>不需要显式设置，因此所有实例都将使用相同的默认值。如果有特定的故障转移首选项，则<code>replica-priority</code>必须在所有实例上设置，包括主实例，因为主实例可能会在未来的某个时间点成为副本 - 然后它将需要适当的<code>replica-priority</code>设置。</p>
<p>Redis 实例可以配置<code>replica-priority</code>为零，以便Sentinels<strong>永远不会选择</strong>它作为新的主实例。然而，以这种方式配置的副本仍然会被 Sentinels 重新配置，以便在故障转移后与新的 master 进行复制，唯一的区别是它永远不会成为 master 本身。</p>
<h2 id="算法和内部"><a href="#算法和内部" class="headerlink" title="算法和内部"></a>算法和内部</h2><p>在接下来的部分中，我们将探索 Sentinel 行为的细节。用户并不需要了解所有细节，但深入了解 Sentinel 可能有助于以更有效的方式部署和操作 Sentinel。</p>
<h3 id="法定人数"><a href="#法定人数" class="headerlink" title="法定人数"></a>法定人数</h3><p>前面的部分显示了 Sentinel 监控的每个 master 都与配置的<strong>quorum</strong>相关联。它指定需要就 master 的不可达或错误条件达成一致以触发故障转移的 Sentinel 进程的数量。</p>
<p>但是，在触发故障转移之后，为了让故障转移真正进行， <strong>至少必须有过半数的 Sentinel 授权 Sentinel 进行故障转移</strong> 。Sentinel 从不在存在少数 Sentinel 的分区中执行故障转移。</p>
<p>让我们试着让事情更清楚一点：</p>
<ul>
<li>Quorum：需要检测错误条件以便将 master 标记为<strong>ODOWN</strong>的 Sentinel 进程数。</li>
<li>故障转移由<strong>ODOWN</strong>状态触发。</li>
<li>一旦故障转移被触发，试图进行故障转移的哨兵需要向大多数哨兵请求授权（或者超过多数，如果法定人数设置为大于多数的数字）。</li>
</ul>
<p>差异可能看起来很微妙，但实际上很容易理解和使用。例如，如果您有 5 个 Sentinel 实例，并且仲裁设置为 2，一旦 2 个 Sentinels 认为 master 不可达，就会触发故障转移，但是两个 Sentinels 中的一个只有在它到达时才能进行故障转移至少来自 3 个哨兵的授权。</p>
<p>相反，如果 quorum 配置为 5，则所有 Sentinels 必须就主错误条件达成一致，并且需要所有 Sentinels 的授权才能进行故障转移。</p>
<p>这意味着可以通过两种方式使用仲裁来调整 Sentinel：</p>
<ol>
<li>如果 quorum 设置的值小于我们部署的大多数哨兵，我们基本上是在让哨兵对 master 故障更加敏感，即使只有少数哨兵不再能够与 master 通信，也会立即触发故障转移。</li>
<li>如果法定人数设置为大于大多数哨兵的值，我们将使哨兵仅在有大量（大于多数）连接良好的哨兵同意主站已关闭时才能进行故障转移。</li>
</ol>
<h3 id="配置纪元"><a href="#配置纪元" class="headerlink" title="配置纪元"></a>配置纪元</h3><p>出于以下几个重要原因，哨兵需要获得多数人的授权才能开始故障转移：</p>
<p>当一个 Sentinel 被授权时，它会为它正在故障转移的 master 获得一个唯一的 <strong>配置纪元</strong> 。这是一个数字，将用于在故障转移完成后对新配置进行版本控制。因为大多数人同意将给定版本分配给给定 Sentinel，所以其他 Sentinel 将无法使用它。这意味着每个故障转移的每个配置都使用唯一版本进行版本控制。我们将了解为什么这如此重要。</p>
<p>此外，Sentinel 有一个规则：如果一个 Sentinel 投票给另一个 Sentinel 来进行给定 master 的故障转移，它将等待一段时间再次尝试对同一个 master 进行故障转移。此延迟是<code>2 * failover-timeout</code>您可以在中配置的<code>sentinel.conf</code>。这意味着 Sentinels 不会同时尝试对同一个 master 进行故障转移，第一个请求获得授权的将尝试，如果失败，另一个将在一段时间后尝试，依此类推。</p>
<p>Redis Sentinel 保证了<em>活性</em>属性，即如果大多数 Sentinel 能够对话，最终一个将被授权在 master 宕机时进行故障转移。</p>
<p>Redis Sentinel 还保证了<em>安全</em>属性，即每个 Sentinel 都将使用不同的<em>配置 epoch</em>对同一个 master 进行故障转移。</p>
<h3 id="配置传播"><a href="#配置传播" class="headerlink" title="配置传播"></a>配置传播</h3><p>一旦 Sentinel 能够成功地对 master 进行故障转移，它将开始广播新配置，以便其他 Sentinel 更新它们关于给定 master 的信息。</p>
<p>要将故障转移视为成功，它需要 Sentinel 能够将<code>REPLICAOF NO ONE</code>命令发送到选定的副本，并且稍后在主服务器的<a href="https://redis.io/commands/info"><code>INFO</code></a> 输出中观察到切换到主服务器。</p>
<p>此时，即使replicas的reconfiguration正在进行中，也认为failover成功了，需要所有的Sentinels开始上报新的配置。</p>
<p>传播新配置的方式是我们需要为每个 Sentinel 故障转移授权不同版本号（配置纪元）的原因。</p>
<p>每个 Sentinel 都使用 Redis Pub&#x2F;Sub 消息在主服务器和所有副本中持续广播其主服务器配置版本。同时，所有哨兵都在等待消息，以查看其他哨兵公布的配置是什么。</p>
<p>配置在<code>__sentinel__:hello</code>Pub&#x2F;Sub 频道中广播。</p>
<p>因为每个配置都有不同的版本号，所以较大的版本总是胜过较小的版本。</p>
<p>因此，例如，master 的配置<code>mymaster</code>以所有 Sentinels 认为 master 位于 192.168.1.50:6379 开始。此配置具有版本 1。一段时间后，Sentinel 被授权使用版本 2 进行故障转移。如果故障转移成功，它将开始广播新配置，例如 192.168.1.50:9000，版本 2。所有其他实例将看到此配置并将相应地更新其配置，因为新配置具有更高版本。</p>
<p>这意味着 Sentinel 保证了第二个活性属性：一组能够通信的 Sentinel 将全部收敛到具有更高版本号的相同配置。</p>
<p>基本上，如果网络是分区的，每个分区都会收敛到更高的本地配置。在没有分区的特殊情况下，只有一个分区，每个 Sentinel 都会就配置达成一致。</p>
<h3 id="分区下的一致性"><a href="#分区下的一致性" class="headerlink" title="分区下的一致性"></a>分区下的一致性</h3><p>Redis Sentinel 配置最终是一致的，因此每个分区都会收敛到可用的更高配置。然而，在使用 Sentinel 的真实世界系统中，存在三个不同的参与者：</p>
<ul>
<li>Redis 实例。</li>
<li>哨兵实例。</li>
<li>客户。</li>
</ul>
<p>为了定义系统的行为，我们必须考虑所有这三个方面。</p>
<p>以下是一个简单的网络，其中有 3 个节点，每个节点运行一个 Redis 实例和一个 Sentinel 实例：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">            +<span class="comment">-------------+</span></span><br><span class="line">            | Sentinel <span class="number">1</span>  |<span class="comment">----- Client A</span></span><br><span class="line">            | Redis <span class="number">1</span> (M)  |</span><br><span class="line">            +<span class="comment">-------------+</span></span><br><span class="line">                    |</span><br><span class="line">                    |</span><br><span class="line">+<span class="comment">-------------+     |          +------------+</span></span><br><span class="line">| Sentinel <span class="number">2</span>  |<span class="comment">-----+-- // ----| Sentinel 3 |----- Client B</span></span><br><span class="line">| Redis <span class="number">2</span> (S)  |                | Redis <span class="number">3</span> (M) |</span><br><span class="line">+<span class="comment">-------------+                +------------+</span></span><br></pre></td></tr></table></figure>

<p>在这个系统中，原始状态是 Redis 3 是主服务器，而 Redis 1 和 2 是副本。发生了一个分区，隔离了旧的主人。Sentinel 1 和 2 开始故障转移，将 Sentinel 1 提升为新的主节点。</p>
<p>Sentinel 属性保证 Sentinel 1 和 2 现在具有主站的新配置。但是 Sentinel 3 仍然具有旧配置，因为它位于不同的分区中。</p>
<p>我们知道 Sentinel 3 将在网络分区修复时更新其配置，但是如果有客户端与旧主分区分区，在分区期间会发生什么？</p>
<p>客户仍然可以向老主人 Redis 3 写入数据。当分区重新加入时，Redis 3 将变成 Redis 1 的副本，分区期间写入的所有数据都将丢失。</p>
<p>根据您的配置，您可能希望或不希望这种情况发生：</p>
<ul>
<li>如果您使用 Redis 作为缓存，那么客户端 B 仍然能够写入旧的 master 可能会很方便，即使它的数据会丢失。</li>
<li>如果您将 Redis 用作存储，这并不好，您需要配置系统以部分防止此问题。</li>
</ul>
<p>由于 Redis 是异步复制的，因此在这种情况下无法完全防止数据丢失，但是您可以使用以下 Redis 配置选项限制 Redis 3 和 Redis 1 之间的差异：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="built_in">min</span>-replicas-to-<span class="built_in">write</span> <span class="number">1</span></span><br><span class="line"><span class="built_in">min</span>-replicas-<span class="built_in">max</span>-lag <span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>通过以上配置（请参阅 Redis 发行版中的自我注释<code>redis.conf</code>示例以获取更多信息），当 Redis 实例充当主实例时，如果它不能写入至少 1 个副本，将停止接受写入。由于复制是异步<em>的，因此无法写入</em>实际上意味着副本已断开连接，或者在超过指定<code>max-lag</code>秒数的时间内未向我们发送异步确认。</p>
<p>使用此配置，上例中的 Redis 3 将在 10 秒后变得不可用。当分区修复后，Sentinel 3 配置将汇聚到新配置，客户端 B 将能够获取有效配置并继续。</p>
<p>一般来说Redis+Sentinel作为一个整体是一个 <strong>最终一致的系统</strong> ，merge函数是 <strong>last failover wins</strong> ，丢弃旧master的数据复制当前master的数据，所以总有一个丢失确认写入的窗口。这是由于 Redis 异步复制和系统“虚拟”合并功能的丢弃性质。请注意，这不是 Sentinel 本身的限制，如果您使用高度一致的复制状态机来编排故障转移，则相同的属性仍将适用。只有两种方法可以避免丢失已确认的写入：</p>
<ol>
<li>使用同步复制（和适当的共识算法来运行复制状态机）。</li>
<li>使用最终一致的系统，可以合并同一对象的不同版本。</li>
</ol>
<p>Redis 目前无法使用以上任何一个系统，目前不在开发目标之内。然而，有代理在 Redis 存储之上实现解决方案“2”，例如 SoundCloud <a href="https://github.com/soundcloud/roshi">Roshi</a> 或 Netflix <a href="https://github.com/Netflix/dynomite">Dynomite</a> 。</p>
<h2 id="哨兵持久状态"><a href="#哨兵持久状态" class="headerlink" title="哨兵持久状态"></a>哨兵持久状态</h2><p>哨兵状态保存在哨兵配置文件中。例如，每次接收到或创建（leader Sentinels）新配置时，master 都会将配置与配置纪元一起保存在磁盘上。这意味着停止和重新启动 Sentinel 进程是安全的。</p>
<h3 id="倾斜模式"><a href="#倾斜模式" class="headerlink" title="倾斜模式"></a>倾斜模式</h3><p>Redis Sentinel 严重依赖于计算机时间：例如，为了了解实例是否可用，它会记住最近成功回复 PING 命令的时间，并将其与当前时间进行比较以了解它有多旧。</p>
<p>但是，如果计算机时间以意想不到的方式更改，或者如果计算机非常繁忙，或者由于某种原因进程被阻塞，Sentinel 可能会开始以意想不到的方式运行。</p>
<p>TILT 模式是一种特殊的“保护”模式，当检测到可能降低系统可靠性的异常情况时，Sentinel 可以进入该模式。Sentinel 计时器中断通常每秒调用 10 次，因此我们预计两次调用计时器中断之间将间隔大约 100 毫秒。</p>
<p>Sentinel 所做的是记录上一次调用定时器中断的时间，并将其与当前调用进行比较：如果时间差为负或意外大（2 秒或更多），则进入 TILT 模式（或者如果它已经进入 TILT 模式的退出被推迟）。</p>
<p>在 TILT 模式下，Sentinel 将继续监控所有内容，但是：</p>
<ul>
<li>它根本停止行动。</li>
<li>它开始对<code>SENTINEL is-master-down-by-addr</code>请求做出否定答复，因为检测故障的能力不再受信任。</li>
</ul>
<p>如果在 30 秒内一切正常，则退出 TILT 模式。</p>
<p>在 Sentinel TILT 模式下，如果我们发送 INFO 命令，我们可以得到以下响应：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">$ redis-cli -p 26379</span><br><span class="line"><span class="section">127.0.0.1:26379&gt; info</span></span><br><span class="line">(Other information from Sentinel server skipped.) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Sentinel</span></span><br><span class="line"><span class="section">sentinel_masters:1</span></span><br><span class="line"><span class="section">sentinel_tilt:0</span></span><br><span class="line"><span class="section">sentinel_tilt_since_seconds:-1</span></span><br><span class="line"><span class="section">sentinel_running_scripts:0</span></span><br><span class="line"><span class="section">sentinel_scripts_queue_length:0</span></span><br><span class="line"><span class="section">sentinel_simulate_failure_flags:0</span></span><br><span class="line"><span class="section">master0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=0,sentinels=1</span></span><br></pre></td></tr></table></figure>

<p>“sentinel_tilt_since_seconds”字段表示 Sentinel 已经处于 TILT 模式的秒数。如果它不在 TILT 模式下，该值将为 -1。</p>
<p>请注意，在某些方面，可以使用许多内核提供的单调时钟 API 替换 TILT 模式。然而，目前尚不清楚这是否是一个好的解决方案，因为当前系统避免了进程刚刚挂起或长时间未被调度程序执行时出现的问题。</p>
<p><strong>关于本手册页中使用的单词 slave 的注释</strong> ：从 Redis 5 开始，如果不是为了向后兼容，Redis 项目不再使用单词 slave。不幸的是，在此命令中，slave 一词是协议的一部分，因此只有在自然弃用此 API 时，我们才能删除此类事件。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote>
<p><a href="https://redis.io/docs/management/sentinel/">https://redis.io/docs/management/sentinel/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis高级数据结构</title>
    <url>/2022/04/21/database/Redis%E9%9B%86%E7%BE%A4%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<h2 id="设计的主要特性和原理"><a href="#设计的主要特性和原理" class="headerlink" title="设计的主要特性和原理"></a>设计的主要特性和原理</h2><h3 id="Redis-集群目标"><a href="#Redis-集群目标" class="headerlink" title="Redis 集群目标"></a>Redis 集群目标</h3><p>Redis Cluster 是 Redis 的分布式实现，按照设计中的重要性顺序具有以下目标：</p>
<ul>
<li>高性能和线性可扩展性高达 1000 个节点。没有代理，使用异步复制，不对值执行合并操作。</li>
<li>可接受的写入安全程度：系统尝试（以最大努力的方式）保留所有来自与大多数主节点连接的客户端的写入。通常有一些小窗口，其中确认的写入可能会丢失。当客户端位于少数分区中时，丢失已确认写入的窗口更大。</li>
<li>可用性：Redis 集群能够在大多数主节点可访问的分区中存活下来，并且每个不再可访问的主节点至少有一个可访问的副本。此外，使用 <em>replicas migration</em> ，不再被任何副本复制的 masters 将从被多个副本覆盖的 master 接收一个。</li>
</ul>
<p>本文档中描述的内容在 Redis 3.0 或更高版本中实现。</p>
<span id="more"></span>

<h3 id="实现的子集"><a href="#实现的子集" class="headerlink" title="实现的子集"></a>实现的子集</h3><p>Redis Cluster 实现了非分布式 Redis 版本中可用的所有单键命令。执行复杂的多键操作（如集合并集和交集）的命令是针对操作中涉及的所有键散列到同一个槽的情况实现的。</p>
<p>Redis Cluster 实现了一个称为<strong>散列标签</strong>的概念，可用于强制将某些键存储在同一个散列槽中。但是，在手动重分片过程中，多键操作可能会在一段时间内不可用，而单键操作始终可用。</p>
<p>Redis Cluster 不像 Redis 的独立版本那样支持多数据库。我们只支持数据库<code>0</code>；该<a href="https://redis.io/commands/select"><code>SELECT</code></a>  命令是不允许的。</p>
<h2 id="Redis-集群协议中的客户端和服务器角色"><a href="#Redis-集群协议中的客户端和服务器角色" class="headerlink" title="Redis 集群协议中的客户端和服务器角色"></a>Redis 集群协议中的客户端和服务器角色</h2><p>在 Redis 集群中，节点负责保存数据并获取集群的状态，包括将键映射到正确的节点。集群节点还能够自动发现其他节点，检测非工作节点，并在需要时将副本节点提升为主节点，以便在发生故障时继续运行。</p>
<p>为了执行它们的任务，所有集群节点都使用 TCP 总线和称为<strong>Redis Cluster Bus</strong>的二进制协议连接。每个节点都使用集群总线连接到集群中的每个其他节点。节点使用八卦协议传播有关集群的信息以发现新节点，发送 ping 数据包以确保所有其他节点正常工作，并发送信号特定条件所需的集群消息。集群总线还用于跨集群传播 Pub&#x2F;Sub 消息，并在用户请求时协调手动故障转移（手动故障转移不是由 Redis 集群故障检测器发起的故障转移，而是由系统管理员直接发起）。</p>
<p>由于集群节点无法代理请求，客户端可能会使用重定向错误<code>-MOVED</code>和<code>-ASK</code>. 理论上，客户端可以自由地向集群中的所有节点发送请求，如果需要则进行重定向，因此客户端不需要保存集群的状态。然而，能够缓存键和节点之间的映射的客户端可以以明智的方式提高性能。</p>
<h3 id="写入安全"><a href="#写入安全" class="headerlink" title="写入安全"></a>写入安全</h3><p>Redis Cluster节点间采用异步复制，<strong>最后故障转移胜</strong>隐式合并功能。这意味着最后选出的主数据集最终会替换所有其他副本。总有一个时间窗口可能会在分区期间丢失写入。然而，对于连接到大多数 master 的客户端和连接到少数 master 的客户端，这些窗口非常不同。</p>
<p>与在少数方面执行的写入相比，Redis 集群更努力地保留由连接到大多数主服务器的客户端执行的写入。以下是导致故障期间大多数分区中接收到的已确认写入丢失的场景示例：</p>
<ol>
<li>写入可能会到达主节点，但虽然主节点可能能够回复客户端，但写入可能不会通过主节点和副本节点之间使用的异步复制传播到副本。如果 master 在写入未到达副本的情况下死亡，并且 master 在足够长的时间内无法访问以提升其副本之一，则写入将永远丢失。这在主节点突然完全失效的情况下通常很难观察到，因为主节点试图几乎同时回复客户端（确认写入）和副本（传播写入）。然而，它是真实世界的故障模式。</li>
<li>写入丢失的另一种理论上可能的故障模式如下：</li>
</ol>
<ul>
<li>由于分区，无法访问 master。</li>
<li>它被它的一个副本故障转移。</li>
<li>一段时间后，它可能会再次可达。</li>
<li>具有过时路由表的客户端可能会在旧主控器被集群转换为（新主控器的）副本之前写入旧主控器。</li>
</ul>
<p>第二种故障模式不太可能发生，因为主节点无法在足够的时间内与大多数其他主节点通信以进行故障转移，将不再接受写入，并且当分区固定时，仍然会在一小段时间内拒绝写入允许其他节点通知配置更改。这种故障模式还要求客户端的路由表尚未更新。</p>
<p>针对分区的少数端的写入具有更大的丢失窗口。例如，Redis 集群在只有少数 master 和至少一个或多个 clients 的分区上丢失了大量的写入，因为如果 master 在多数派。</p>
<p>具体来说，对于要故障转移的 master，它必须不能被大多数 master 访问至少<code>NODE_TIMEOUT</code>，因此如果分区在此之前修复，则不会丢失任何写入。当分区持续时间超过<code>NODE_TIMEOUT</code>时，到那时在少数方面执行的所有写入都可能丢失。然而，Redis 集群的少数端会在<code>NODE_TIMEOUT</code>没有与多数端联系的时间过去后立即开始拒绝写入，因此存在一个最大窗口，之后少数端将不再可用。因此，在那之后没有写入被接受或丢失。</p>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>Redis Cluster 在分区的少数端不可用。在分区的大多数侧，假设至少有大多数主节点和每个无法访问的主节点的副本，集群在<code>NODE_TIMEOUT</code>一段时间后再次可用加上副本被选出并故障转移其主节点所需的几秒（故障转移通常在 1 或 2 秒内执行）。</p>
<p>这意味着 Redis Cluster 旨在承受集群中少数节点的故障，但对于需要在大网络分裂情况下保持可用性的应用程序来说，它不是一个合适的解决方案。</p>
<p>在由 N 个主节点组成的集群的示例中，其中每个节点都有一个副本，只要单个节点被分区，集群的多数端将保持可用，并且<code>1-(1/(N*2-1) ) </code>在两个节点被分区时保持可用的概率分区（在第一个节点失败后，我们<code>N*2-1</code>总共剩下节点，唯一没有副本的主节点失败的概率是<code>1/(N*2-1) ) </code>。</p>
<p>例如，在一个有 5 个节点且每个节点只有一个副本的集群中，有<code>1/(5*2-1)  = 11.11%</code>可能在两个节点从多数节点中分离出来后，集群将不再可用。</p>
<p>多亏了称为<strong>副本迁移</strong>的 Redis 集群功能，通过副本迁移到孤立的主服务器（主服务器不再有副本）这一事实，集群可用性在许多现实世界场景中得到了提高。因此，在每次成功的故障事件中，集群可能会重新配置副本布局，以便更好地抵抗下一次故障。</p>
<h3 id="表现"><a href="#表现" class="headerlink" title="表现"></a>表现</h3><p>在 Redis 集群中，节点不会将命令代理到负责给定密钥的正确节点，而是将客户端重定向到为密钥空间的给定部分提供服务的正确节点。</p>
<p>最终客户端获得集群的最新表示以及哪个节点服务哪个密钥子集，因此在正常操作期间客户端直接联系正确的节点以发送给定命令。</p>
<p>由于使用异步复制，节点不会等待其他节点对写入的确认（如果未使用<a href="https://redis.io/commands/wait"><code>WAIT</code></a>  命令明确请求）。</p>
<p>此外，由于多键命令仅限于<em>近</em>键，因此除非重新分片，否则数据永远不会在节点之间移动。</p>
<p>正常操作的处理方式与单个 Redis 实例的处理方式完全相同。这意味着在具有 N 个主节点的 Redis 集群中，您可以预期与单个 Redis 实例相同的性能乘以 N，因为设计是线性扩展的。同时，查询通常在单次往返中执行，因为客户端通常与节点保持持久连接，因此延迟数据也与单个独立 Redis 节点情况相同。</p>
<p>非常高的性能和可扩展性，同时保持弱但合理的数据安全和可用性形式是 Redis 集群的主要目标。</p>
<h3 id="为什么要避免合并操作"><a href="#为什么要避免合并操作" class="headerlink" title="为什么要避免合并操作"></a>为什么要避免合并操作</h3><p>Redis 集群设计避免了多个节点中相同键值对的版本冲突，因为在 Redis 数据模型的情况下，这并不总是可取的。Redis 中的值通常非常大；看到包含数百万个元素的列表或排序集很常见。数据类型在语义上也很复杂。传输和合并这些类型的值可能是一个主要瓶颈和&#x2F;或可能需要应用程序端逻辑的重要参与、额外的内存来存储元数据等。</p>
<p>这里没有严格的技术限制。CRDT 或同步复制状态机可以模拟类似于 Redis 的复杂数据类型。但是，此类系统的实际运行时行为与 Redis 集群不同。Redis Cluster 旨在涵盖非集群 Redis 版本的确切用例。</p>
<h2 id="Redis-Cluster主要组件概览"><a href="#Redis-Cluster主要组件概览" class="headerlink" title="Redis Cluster主要组件概览"></a>Redis Cluster主要组件概览</h2><h3 id="密钥分发模型"><a href="#密钥分发模型" class="headerlink" title="密钥分发模型"></a>密钥分发模型</h3><p>集群的密钥空间被分成 16384 个槽，有效地设置了 16384 个主节点的集群大小上限（但是，建议的最大节点大小约为 1000 个节点）。</p>
<p>集群中的每个主节点处理 16384 个哈希槽的一个子集。当没有正在进行的集群重新配置（即哈希槽从一个节点移动到另一个节点）时，集群是 <strong>稳定的。</strong> 当集群稳定时，单个哈希槽将由单个节点提供服务（但是，服务节点可以有一个或多个副本，在网络分裂或故障的情况下替换它，并且可以用于扩展读取陈旧数据是可接受的操作）。</p>
<p>用于将键映射到散列槽的基本算法如下（阅读下一段以了解此规则的散列标签例外）：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">HASH_SLOT</span> = CRC16(key)  mod <span class="number">16384</span></span><br></pre></td></tr></table></figure>

<p>CRC16 指定如下：</p>
<ul>
<li>名称：XMODEM（也称为 ZMODEM 或 CRC-16&#x2F;ACORN）</li>
<li>宽度：16位</li>
<li>多边形：1021（实际上是 x^16 + x^12 + x^5 + 1）</li>
<li>初始化：0000</li>
<li>反映输入字节：False</li>
<li>反映输出 CRC：假</li>
<li>Xor 常量输出 CRC：0000</li>
<li>“123456789”的输出：31C3</li>
</ul>
<p>使用了 16 个 CRC16 输出位中的 14 个（这就是上面公式中有模 16384 运算的原因）。</p>
<p>在我们的测试中，CRC16 在将不同类型的密钥均匀分布在 16384 个槽位方面表现得非常好。</p>
<p><strong>注意</strong> ：本文档的附录 A 中提供了所使用的 CRC16 算法的参考实现。</p>
<h3 id="哈希标签"><a href="#哈希标签" class="headerlink" title="哈希标签"></a>哈希标签</h3><p>用于实现<strong>散列标签</strong>的散列槽的计算有一个例外。哈希标签是一种确保多个键分配在同一个哈希槽中的方法。这用于在 Redis 集群中实现多键操作。</p>
<p>为了实现散列标签，在某些情况下，键的散列槽的计算方式略有不同。如果密钥包含“{…}”模式，则仅对 和 之间的子字符串进行 <code>&#123;</code>哈希<code>&#125;</code>处理以获得哈希槽。但是，由于可能多次出现<code>&#123;</code>或<code>&#125;</code>算法由以下规则很好地指定：</p>
<ul>
<li>如果键包含一个<code>&#123;</code>字符。</li>
<li>AND IF<code>&#125;</code>的右边有一个字符<code>&#123;</code>。</li>
<li><code>&#123;</code>AND IF 在第一次出现的和第一次出现的之间有一个或多个字符<code>&#125;</code>。</li>
</ul>
<p>然后，不是对密钥进行哈希处理，而是仅对第一次出现的<code>&#123;</code>和随后第一次出现的之间的内容<code>&#125;</code>进行哈希处理。</p>
<p>例子：</p>
<ul>
<li>这两个键<code>&#123;user1000&#125;.following</code>和<code>&#123;user1000&#125;.followers</code>将散列到相同的散列槽，因为只有子字符串<code>user1000</code>将被散列以计算散列槽。</li>
<li>对于密钥<code>foo&#123;&#125;&#123;bar&#125;</code>，整个密钥将像往常一样被散列，因为第一次出现的<code>&#123;</code>后面是<code>&#125;</code>右边没有中间字符的。</li>
<li>对于密钥<code>foo&#123;&#123;bar&#125;&#125;zap</code>，子字符串<code>&#123;bar</code>将被散列，因为它是第一次出现的<code>&#123;</code>和<code>&#125;</code>右侧第一次出现之间的子字符串。</li>
<li>对于密钥<code>foo&#123;bar&#125;&#123;zap&#125;</code>，子字符串<code>bar</code>将被散列，因为算法在 和 的第一个有效或无效（内部没有字节）匹配时<code>&#123;</code>停止<code>&#125;</code>。</li>
<li>从该算法可以看出，如果密钥以 开头<code>&#123;&#125;</code>，则可以保证将其作为一个整体进行哈希处理。这在使用二进制数据作为键名时很有用。</li>
</ul>
<p>添加hash标签例外，以下是该<code>HASH_SLOT</code>函数在Ruby和C语言中的实现。</p>
<p>红宝石示例代码：</p>
<figure class="highlight vbnet"><table><tr><td class="code"><pre><span class="line">def HASH_SLOT(<span class="keyword">key</span>) </span><br><span class="line">    s = <span class="keyword">key</span>.index <span class="string">&quot;&#123;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> s</span><br><span class="line">        e = <span class="keyword">key</span>.index <span class="string">&quot;&#125;&quot;</span>,s+<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> e &amp;&amp; e != s+<span class="number">1</span></span><br><span class="line">            <span class="keyword">key</span> = <span class="keyword">key</span>[s+<span class="number">1</span>..e-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    crc16(<span class="keyword">key</span>)  % <span class="number">16384</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<p>C示例代码：</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">unsigned int <span class="built_in">HASH_SLOT</span>(char *key, int keylen)  &#123;</span><br><span class="line">    int s, e; <span class="comment">/* start-end indexes of &#123; and &#125; */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Search the first occurrence of &#x27;&#123;&#x27;. */</span></span><br><span class="line">    for (s = <span class="number">0</span>; s &lt; keylen; s++) </span><br><span class="line">        if (key[s] == &#x27;&#123;&#x27;)  break;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* No &#x27;&#123;&#x27; ? Hash the whole key. This is the base case. */</span></span><br><span class="line">    if (s == keylen)  return <span class="built_in">crc16</span>(key,keylen)  &amp; <span class="number">16383</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* &#x27;&#123;&#x27; found? Check if we have the corresponding &#x27;&#125;&#x27;. */</span></span><br><span class="line">    for (e = s+<span class="number">1</span>; e &lt; keylen; e++) </span><br><span class="line">        if (key[e] == &#x27;&#125;&#x27;)  break;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* No &#x27;&#125;&#x27; or nothing between &#123;&#125; ? Hash the whole key. */</span></span><br><span class="line">    if (e == keylen || e == s+<span class="number">1</span>)  return <span class="built_in">crc16</span>(key,keylen)  &amp; <span class="number">16383</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If we are here there is both a &#123; and a &#125; on its right. Hash</span></span><br><span class="line"><span class="comment">     * what is in the middle between &#123; and &#125;. */</span></span><br><span class="line">    return <span class="built_in">crc16</span>(key+s+<span class="number">1</span>,e-s-<span class="number">1</span>)  &amp; <span class="number">16383</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="集群节点属性"><a href="#集群节点属性" class="headerlink" title="集群节点属性"></a>集群节点属性</h3><p>每个节点在集群中都有一个唯一的名称。节点名称是一个 160 位随机数的十六进制表示，在节点第一次启动时获得（通常使用 &#x2F;dev&#x2F;urandom）。节点会将其 ID 保存在节点配置文件中，并将永远使用相同的 ID，或者至少只要节点配置文件没有被系统管理员删除，或者通过命令请求<em>硬重置。</em><a href="https://redis.io/commands/cluster-reset"><code>CLUSTER RESET</code></a> </p>
<p>节点 ID 用于标识整个集群中的每个节点。给定节点可以更改其 IP 地址，而无需同时更改节点 ID。集群还能够检测 IP&#x2F;端口的变化，并使用运行在集群总线上的八卦协议重新配置。</p>
<p>节点 ID 不是与每个节点关联的唯一信息，而是唯一始终全局一致的信息。每个节点还具有以下相关信息集。一些信息是关于这个特定节点的集群配置细节，并且最终在整个集群中是一致的。一些其他信息，例如上次对节点执行 ping 操作的时间，对于每个节点都是本地的。</p>
<p>每个节点都维护集群中它所知道的其他节点的以下信息：节点 ID、节点的 IP 和端口、一组标志、如果节点被标记<code>replica</code>为节点被 ping 和上次收到 pong 的时间、节点的当前  <em>配置纪元</em> （在本规范后面解释）、链路状态和最后服务的哈希槽集。</p>
<p>文档中描述了<a href="https://redis.io/commands/cluster-nodes">所有节点字段</a>  的详细说明<a href="https://redis.io/commands/cluster-nodes"><code>CLUSTER NODES</code></a>  。</p>
<p>该<a href="https://redis.io/commands/cluster-nodes"><code>CLUSTER NODES</code></a>  命令可以发送到集群中的任何节点，并根据查询节点对集群的本地视图提供集群的状态和每个节点的信息。</p>
<p>以下是<a href="https://redis.io/commands/cluster-nodes"><code>CLUSTER NODES</code></a>  发送到包含三个节点的小型集群中的主节点的命令输出示例。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">redis-cli</span> <span class="string">cluster</span> <span class="string">nodes</span></span><br><span class="line"><span class="string">d1861060fe6a534d42d8a19aeb36600e18785e04</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:6379</span> <span class="string">myself</span> <span class="bullet">-</span> <span class="number">0</span> <span class="number">1318428930</span> <span class="number">1</span> <span class="string">connected</span> <span class="number">0</span><span class="number">-1364</span></span><br><span class="line"><span class="string">3886e65cc906bfd9b1f7e7bde468726a052d1dae</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:6380</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">1318428930</span> <span class="number">1318428931</span> <span class="number">2</span> <span class="string">connected</span> <span class="number">1365</span><span class="number">-2729</span></span><br><span class="line"><span class="string">d289c575dcbc4bdd2931585fd4339089e461a27d</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:6381</span> <span class="string">master</span> <span class="bullet">-</span> <span class="number">1318428931</span> <span class="number">1318428931</span> <span class="number">3</span> <span class="string">connected</span> <span class="number">2730</span><span class="number">-4095</span></span><br></pre></td></tr></table></figure>

<p>在上面的列表中，不同的字段按顺序排列：节点 ID、地址：端口、标志、最后发送的 ping、最后接收的 pong、配置纪元、链路状态、插槽。当我们谈到 Redis Cluster 的特定部分时，将涵盖有关上述字段的详细信息。</p>
<h3 id="集群总线"><a href="#集群总线" class="headerlink" title="集群总线"></a>集群总线</h3><p>每个 Redis 集群节点都有一个额外的 TCP 端口，用于接收来自其他 Redis 集群节点的传入连接。此端口将通过向数据端口添加 10000 派生，或者可以使用 cluster-port 配置指定。</p>
<p>示例 1：</p>
<p>如果一个 Redis 节点正在监听 6379 端口上的客户端连接，并且你没有在 redis.conf 中添加 cluster-port 参数，那么 Cluster 总线端口 16379 将被打开。</p>
<p>示例 2：</p>
<p>如果 Redis 节点正在端口 6379 上侦听客户端连接，并且您在 redis.conf 中设置了 cluster-port 20000，则 Cluster 总线端口 20000 将被打开。</p>
<p>节点到节点的通信仅使用集群总线和集群总线协议进行：一种由不同类型和大小的帧组成的二进制协议。集群总线二进制协议没有公开记录，因为它不适用于外部软件设备使用此协议与 Redis 集群节点通信。但是，您可以通过阅读Redis 集群源代码中的<code>cluster.h</code>和文件来获取有关集群总线协议的更多详细信息 。<code>cluster.c</code></p>
<h3 id="集群拓扑"><a href="#集群拓扑" class="headerlink" title="集群拓扑"></a>集群拓扑</h3><p>Redis 集群是一个全网状结构，其中每个节点都使用 TCP 连接与其他每个节点相连。</p>
<p>在一个由 N 个节点组成的集群中，每个节点都有 N-1 个传出 TCP 连接和 N-1 个传入连接。</p>
<p>这些 TCP 连接始终保持活动状态，而不是按需创建。当节点期望 pong 响应集群总线中的 ping 响应时，在等待足够长的时间将节点标记为不可访问之前，它将尝试通过从头重新连接来刷新与节点的连接。</p>
<p>而 Redis Cluster 节点形成全网状，<strong>节点使用八卦协议和配置更新机制，以避免在正常情况下节点之间交换过多</strong>的消息，因此交换的消息数量不是指数级的。</p>
<h3 id="节点握手"><a href="#节点握手" class="headerlink" title="节点握手"></a>节点握手</h3><p>节点始终接受集群总线端口上的连接，甚至在收到 ping 时回复，即使 ping 节点不受信任。但是，如果发送节点不被视为集群的一部分，则所有其他数据包将被接收节点丢弃。</p>
<p>一个节点将仅通过两种方式接受另一个节点作为集群的一部分：</p>
<ul>
<li>如果一个节点向自己展示一条<code>MEET</code>消息（<a href="https://redis.io/commands/cluster-meet"><code>CLUSTER MEET</code></a>  命令）。meet 消息与消息完全一样<a href="https://redis.io/commands/ping"><code>PING</code></a>  ，但会强制接收方接受该节点作为集群的一部分。仅当系统管理员通过以下命令请求时，节点才会<code>MEET</code>向其他节点发送消息：<br>集群满足 ip 端口</li>
<li>如果已经信任的节点将八卦另一个节点，则该节点还将注册另一个节点作为集群的一部分。因此，如果 A 认识 B，而 B 认识 C，最终 B 会向 A 发送关于 C 的八卦消息。发生这种情况时，A 会将 C 注册为网络的一部分，并尝试与 C 建立联系。</li>
</ul>
<p>这意味着只要我们加入任何连接图中的节点，它们最终都会自动形成一个完全连接的图。这意味着集群能够自动发现其他节点，但前提是存在系统管理员强制建立的信任关系。</p>
<p>这种机制使集群更加健壮，但可以防止不同的 Redis 集群在 IP 地址更改或其他网络相关事件发生后意外混合。</p>
<h2 id="重定向和重新分片"><a href="#重定向和重新分片" class="headerlink" title="重定向和重新分片"></a>重定向和重新分片</h2><h3 id="移动重定向"><a href="#移动重定向" class="headerlink" title="移动重定向"></a>移动重定向</h3><p>Redis 客户端可以自由地向集群中的每个节点发送查询，包括副本节点。该节点将分析查询，如果可接受（即查询中仅提及单个键，或者提及的多个键都指向同一个哈希槽），它将查找哪个节点负责该哈希槽钥匙或钥匙所属的地方。</p>
<p>如果哈希槽由节点提供服务，则简单地处理查询，否则节点将检查其内部哈希槽到节点映射，并将用 MOVED 错误回复客户端，如下例所示：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">GET x</span><br><span class="line"><span class="deletion">-MOVED 3999 127.0.0.1:6381</span></span><br></pre></td></tr></table></figure>

<p>该错误包括密钥的哈希槽 (3999)  和可以为查询提供服务的实例的端点：端口。客户端需要重新向指定节点的端点地址和端口发出查询。端点可以是 IP 地址、主机名，也可以为空（例如<code>-MOVED 3999 :6380</code>）。空端点表示服务器节点有一个未知端点，客户端应该将下一个请求发送到与当前请求相同的端点，但使用提供的端口。</p>
<p>请注意，即使客户端在重新发出查询之前等待了很长时间，同时集群配置发生了变化，如果哈希槽 3999 现在由另一个节点提供服务，目标节点将再次回复 MOVED 错误。如果联系的节点没有更新信息，也会发生同样的情况。</p>
<p>因此，从集群节点的角度来看，我们尝试简化我们与客户端的接口，仅公开散列槽和由端点：端口对标识的 Redis 节点之间的映射。</p>
<p>客户端不需要，但应该记住哈希槽 3999 由 127.0.0.1:6381 提供服务。这样，一旦需要发出新命令，它就可以计算目标密钥的哈希槽，并有更大的机会选择正确的节点。</p>
<p>另一种方法是在收到 MOVED 重定向时使用<a href="https://redis.io/commands/cluster-shards"><code>CLUSTER SHARDS</code></a>  或已弃用的命令刷新整个客户端集群布局。<a href="https://redis.io/commands/cluster-slots"><code>CLUSTER SLOTS</code></a>  遇到重定向时，很可能会重新配置多个槽而不是一个槽，因此尽快更新客户端配置通常是最好的策略。</p>
<p>请注意，当集群稳定时（配置没有持续变化），最终所有客户端都将获得哈希槽 -&gt; 节点的映射，从而使集群高效，客户端直接寻址正确的节点而无需重定向，代理或其他单一故障点实体。</p>
<p>客户端<strong>还必须能够处理</strong>本文档后面描述的 -ASK 重定向，否则它不是一个完整的 Redis 集群客户端。</p>
<h3 id="实时重新配置"><a href="#实时重新配置" class="headerlink" title="实时重新配置"></a>实时重新配置</h3><p>Redis Cluster 支持在集群运行时添加和删除节点的能力。添加或删除节点被抽象为相同的操作：将哈希槽从一个节点移动到另一个节点。这意味着可以使用相同的基本机制来重新平衡集群、添加或删除节点等。</p>
<ul>
<li>为了向集群中添加一个新节点，将一个空节点添加到集群中，并将一些哈希槽集从现有节点移动到新节点。</li>
<li>要从集群中删除节点，分配给该节点的哈希槽将移动到其他现有节点。</li>
<li>为了重新平衡集群，一组给定的哈希槽在节点之间移动。</li>
</ul>
<p>实现的核心是移动散列槽的能力。从实际的角度来看，哈希槽只是一组键，因此 Redis 集群在重新分片期间真正做的<em>是</em>将键从一个实例移动到另一个实例。移动一个hash slot就是把所有碰巧hash的key都移到这个hash slot中。</p>
<p>为了理解这是如何工作的，我们需要展示<a href="https://redis.io/commands/cluster"><code>CLUSTER</code></a>  用于操作 Redis 集群节点中的槽转换表的子命令。</p>
<p>以下子命令可用（在这种情况下没有用的其他命令）：</p>
<ul>
<li><a href="https://redis.io/commands/cluster-addslots"><code>CLUSTER ADDSLOTS</code></a>  插槽 1 [插槽 2] … [插槽 N]</li>
<li><a href="https://redis.io/commands/cluster-delslots"><code>CLUSTER DELSLOTS</code></a>  插槽 1 [插槽 2] … [插槽 N]</li>
<li><a href="https://redis.io/commands/cluster-addslotsrange"><code>CLUSTER ADDSLOTSRANGE</code></a>  start-slot1 end-slot1 [start-slot2 end-slot2] … [start-slotN end-slotN]</li>
<li><a href="https://redis.io/commands/cluster-delslotsrange"><code>CLUSTER DELSLOTSRANGE</code></a>  start-slot1 end-slot1 [start-slot2 end-slot2] … [start-slotN end-slotN]</li>
<li><a href="https://redis.io/commands/cluster-setslot"><code>CLUSTER SETSLOT</code></a>  插槽 NODE 节点</li>
<li><a href="https://redis.io/commands/cluster-setslot"><code>CLUSTER SETSLOT</code></a>  插槽迁移节点</li>
<li><a href="https://redis.io/commands/cluster-setslot"><code>CLUSTER SETSLOT</code></a>  插槽导入节点</li>
</ul>
<p>前四个命令 、<code>ADDSLOTS</code>和<code>DELSLOTS</code>仅<code>ADDSLOTSRANGE</code>用于<code>DELSLOTSRANGE</code>将槽分配（或删除）到 Redis 节点。分配一个槽意味着告诉给定的主节点它将负责为指定的哈希槽存储和提供内容。</p>
<p>分配哈希槽后，它们将使用八卦协议在集群中传播，如稍后在 <em>配置传播</em>部分中指定的那样。</p>
<p>当从头开始创建新集群时，通常使用<code>ADDSLOTS</code>和命令为每个主节点分配所有 16384 个可用哈希槽的子集。<code>ADDSLOTSRANGE</code></p>
<p>和主要用于手动修改集群配置<code>DELSLOTS</code> 或<code>DELSLOTSRANGE</code>调试任务：实际上很少使用。</p>
<p>如果使用该形式，该<code>SETSLOT</code>子命令用于将插槽分配给特定的节点 ID <code>SETSLOT &lt;slot&gt; NODE</code>。否则插槽可以设置为两种特殊状态<code>MIGRATING</code>和<code>IMPORTING</code>。这两个特殊状态用于将哈希槽从一个节点迁移到另一个节点。</p>
<ul>
<li>当一个槽被设置为 MIGRATING 时，节点将接受所有关于这个哈希槽的查询，但前提是存在问题的键，否则查询将使用<code>-ASK</code>重定向转发到作为迁移目标的节点。</li>
<li>当一个槽被设置为 IMPORTING 时，节点将接受所有关于这个哈希槽的查询，但前提是请求之前有一个<a href="https://redis.io/commands/asking"><code>ASKING</code></a>  命令。如果<a href="https://redis.io/commands/asking"><code>ASKING</code></a> 客户端未给出命令，则查询将通过<code>-MOVED</code>重定向错误重定向到真正的哈希槽所有者，这与正常情况一样。</li>
</ul>
<p>让我们用一个哈希槽迁移的例子来说明这一点。假设我们有两个 Redis 主节点，分别称为 A 和 B。我们想将哈希槽 8 从 A 移动到 B，因此我们发出如下命令：</p>
<ul>
<li>我们发送 B：CLUSTER SETSLOT 8 IMPORTING A</li>
<li>我们发送 A：CLUSTER SETSLOT 8 MIGRATING B</li>
</ul>
<p>每次使用属于哈希槽 8 的密钥查询所有其他节点时，所有其他节点将继续将客户端指向节点“A”，因此发生的情况是：</p>
<ul>
<li>所有关于现有密钥的查询都由“A”处理。</li>
<li>所有关于 A 中不存在的键的查询都由“B”处理，因为“A”会将客户端重定向到“B”。</li>
</ul>
<p>这样我们就不再在“A”中创建新密钥。同时，<code>redis-cli</code>在重新分片和 Redis 集群配置期间使用会将哈希槽 8 中的现有键从 A 迁移到 B。这是使用以下命令执行的：</p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line"><span class="built_in">CLUSTER</span> GETKEYSINSLOT slot count</span><br></pre></td></tr></table></figure>

<p>上面的命令将返回<code>count</code>指定哈希槽中的键。对于返回的密钥，<code>redis-cli</code>向节点“A”发送一个<a href="https://redis.io/commands/migrate"><code>MIGRATE</code></a> 命令，该命令将以原子方式将指定的密钥从 A 迁移到 B（两个实例都锁定迁移密钥所需的时间（通常是非常短的时间），因此没有竞争条件) . 这是如何<a href="https://redis.io/commands/migrate"><code>MIGRATE</code></a> 工作的：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">MIGRATE target_host target_port <span class="string">&quot;&quot;</span> target_database <span class="built_in">id</span> <span class="built_in">timeout</span> KEYS key1 key2 ...</span><br></pre></td></tr></table></figure>

<p><a href="https://redis.io/commands/migrate"><code>MIGRATE</code></a> 将连接到目标实例，发送密钥的序列化版本，一旦收到 OK 代码，它自己数据集中的旧密钥将被删除。从外部客户端的角度来看，在任何给定时间，密钥都存在于 A 或 B 中。</p>
<p>在 Redis Cluster 中不需要指定除 0 以外的数据库，而是 <a href="https://redis.io/commands/migrate"><code>MIGRATE</code></a> 一个通用命令，可以用于不涉及 Redis Cluster 的其他任务。 <a href="https://redis.io/commands/migrate"><code>MIGRATE</code></a> 即使在移动复杂键（如长列表）时也被优化为尽可能快，但在 Redis 集群中，如果使用数据库的应用程序存在延迟限制，则重新配置存在大键的集群被认为不是一个明智的过程。</p>
<p>当迁移过程最终完成时，<code>SETSLOT &lt;slot&gt; NODE &lt;node-id&gt;</code>命令被发送到迁移中涉及的两个节点，以便将插槽再次设置为正常状态。相同的命令通常会发送到所有其他节点，以避免等待新配置在集群中自然传播。</p>
<h3 id="询问重定向"><a href="#询问重定向" class="headerlink" title="询问重定向"></a>询问重定向</h3><p>在上一节中，我们简要介绍了 ASK 重定向。为什么我们不能简单地使用 MOVED 重定向？因为虽然 MOVED 意味着我们认为哈希槽永久由不同的节点提供服务，并且下一个查询应该针对指定的节点进行尝试。ASK 表示只向指定节点发送下一个查询。</p>
<p>这是必需的，因为关于哈希槽 8 的下一个查询可能是关于仍在 A 中的键，所以我们总是希望客户端先尝试 A，然后在需要时尝试 B。由于这仅发生在 16384 个可用哈希槽中的一个，因此对集群的性能影响是可以接受的。</p>
<p>我们需要强制客户端行为，以确保客户端仅在尝试 A 之后尝试节点 B，如果客户端在发送查询之前发送 ASKING 命令，则节点 B 将仅接受设置为 IMPORTING 的槽的查询。</p>
<p>基本上，ASKING 命令会在客户端设置一个一次性标志，强制节点为有关 IMPORTING 槽的查询提供服务。</p>
<p>从客户端的角度来看，ASK 重定向的完整语义如下：</p>
<ul>
<li>如果收到 ASK 重定向，则只发送重定向到指定节点的查询，但继续将后续查询发送到旧节点。</li>
<li>使用 ASKING 命令启动重定向查询。</li>
<li>不要更新本地客户端表以将哈希槽 8 映射到 B。</li>
</ul>
<p>一旦哈希槽 8 迁移完成，A 将发送一条 MOVED 消息，客户端可以将哈希槽 8 永久映射到新的端点和端口对。请注意，如果有错误的客户端更早执行映射，这不是问题，因为它不会在发出查询之前发送 ASKING 命令，因此 B 将使用 MOVED 重定向错误将客户端重定向到 A。</p>
<p><a href="https://redis.io/commands/cluster-setslot"><code>CLUSTER SETSLOT</code></a>  插槽迁移在命令文档中以类似的术语解释，但措辞不同（为了文档中的冗余） 。</p>
<h3 id="客户端连接和重定向处理"><a href="#客户端连接和重定向处理" class="headerlink" title="客户端连接和重定向处理"></a>客户端连接和重定向处理</h3><p>为了提高效率，Redis 集群客户端维护当前插槽配置的映射。但是，此配置<em>不需要</em>是最新的。当联系错误的节点导致重定向时，客户端可以相应地更新其内部槽映射。</p>
<p>客户端通常需要在两种不同的情况下获取完整的插槽列表和映射的节点地址：</p>
<ul>
<li>在启动时，填充初始插槽配置</li>
<li>当客户端收到<code>MOVED</code>重定向时</li>
</ul>
<p>请注意，客户端可以<code>MOVED</code>通过仅更新其表中移动的插槽来处理重定向；然而，这通常效率不高，因为通常会同时修改多个插槽的配置。例如，如果一个副本被提升为主控，则旧主控服务的所有槽都将被重新映射）。<code>MOVED</code>通过从头开始获取槽到节点的完整映射来对重定向做出反应要简单得多。</p>
<p>客户端可以发出<a href="https://redis.io/commands/cluster-slots"><code>CLUSTER SLOTS</code></a> 命令来检索槽范围数组以及服务于指定范围的关联主节点和副本节点。</p>
<p>以下是 的输出示例<a href="https://redis.io/commands/cluster-slots"><code>CLUSTER SLOTS</code></a> ：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7000&gt; cluster slots</span><br><span class="line">1)  1)  (<span class="built_in">integer</span>)  5461</span><br><span class="line">   2)  (<span class="built_in">integer</span>)  10922</span><br><span class="line">   3)  1)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">      2)  (<span class="built_in">integer</span>)  7001</span><br><span class="line">   4)  1)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">      2)  (<span class="built_in">integer</span>)  7004</span><br><span class="line">2)  1)  (<span class="built_in">integer</span>)  0</span><br><span class="line">   2)  (<span class="built_in">integer</span>)  5460</span><br><span class="line">   3)  1)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">      2)  (<span class="built_in">integer</span>)  7000</span><br><span class="line">   4)  1)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">      2)  (<span class="built_in">integer</span>)  7003</span><br><span class="line">3)  1)  (<span class="built_in">integer</span>)  10923</span><br><span class="line">   2)  (<span class="built_in">integer</span>)  16383</span><br><span class="line">   3)  1)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">      2)  (<span class="built_in">integer</span>)  7002</span><br><span class="line">   4)  1)  <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">      2)  (<span class="built_in">integer</span>)  7005</span><br></pre></td></tr></table></figure>

<p>返回数组的每个元素的前两个子元素是范围的开始和结束槽。附加元素表示地址-端口对。第一个地址-端口对是服务于插槽的主服务器，其他地址-端口对是服务于同一插槽的副本。仅当不处于错误状态时（即，当它们的 FAIL 标志未设置时）才会列出副本。</p>
<p>上面输出中的第一个元素表示从 5461 到 10922（包括开始和结束）的插槽由 127.0.0.1:7001 提供服务，并且可以扩展与 127.0.0.1:7004 的副本联系的只读负载。</p>
<p><a href="https://redis.io/commands/cluster-slots"><code>CLUSTER SLOTS</code></a> 如果集群配置错误，则不能保证返回覆盖完整 16384 个槽的范围，因此客户端应初始化槽配置映射，用 NULL 对象填充目标节点，如果用户尝试执行有关属于的键的命令，则报告错误未分配的插槽。</p>
<p>在发现槽未分配时向调用者返回错误之前，客户端应尝试再次获取槽配置以检查集群现在是否已正确配置。</p>
<h3 id="多按键操作"><a href="#多按键操作" class="headerlink" title="多按键操作"></a>多按键操作</h3><p>使用哈希标签，客户可以自由使用多键操作。例如，以下操作是有效的：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">MSET &#123;user:<span class="number">1000</span>&#125;<span class="selector-class">.name</span> Angela &#123;user:<span class="number">1000</span>&#125;<span class="selector-class">.surname</span> White</span><br></pre></td></tr></table></figure>

<p>当键所属的哈希槽的重新分片正在进行时，多键操作可能变得不可用。</p>
<p>更具体地说，即使在重新分片期间，多键操作的目标键仍然可用，这些键都存在并且仍然散列到同一个槽（源节点或目标节点）。</p>
<p>对不存在或在重新分片期间在源节点和目标节点之间拆分的键的操作将产生<code>-TRYAGAIN</code>错误。客户端可以在一段时间后尝试操作，或者报告错误。</p>
<p>一旦指定哈希槽的迁移终止，所有多键操作就可以再次用于该哈希槽。</p>
<h3 id="使用副本节点缩放读取"><a href="#使用副本节点缩放读取" class="headerlink" title="使用副本节点缩放读取"></a>使用副本节点缩放读取</h3><p>通常，副本节点会将客户端重定向到给定命令中涉及的哈希槽的权威主节点，但是客户端可以使用副本来使用<a href="https://redis.io/commands/readonly"><code>READONLY</code></a> 命令扩展读取。</p>
<p><a href="https://redis.io/commands/readonly"><code>READONLY</code></a> 告诉 Redis 集群副本节点客户端可以读取可能过时的数据并且对运行写入查询不感兴趣。</p>
<p>当连接处于只读模式时，只有当操作涉及副本的主节点不提供服务的密钥时，集群才会向客户端发送重定向。这可能是因为：</p>
<ol>
<li>客户端发送了一个关于哈希槽的命令，这个哈希槽从未被这个副本的主人服务过。</li>
<li>集群被重新配置（例如重新分片）并且副本不再能够为给定的哈希槽提供命令。</li>
</ol>
<p>当发生这种情况时，客户端应该更新其哈希槽映射，如前几节所述。</p>
<p>可以使用<a href="https://redis.io/commands/readwrite"><code>READWRITE</code></a> 命令清除连接的只读状态。</p>
<h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><h3 id="心跳和八卦消息"><a href="#心跳和八卦消息" class="headerlink" title="心跳和八卦消息"></a>心跳和八卦消息</h3><p>Redis 集群节点不断地交换 ping 和 pong 数据包。这两种数据包具有相同的结构，都携带重要的配置信息。唯一的实际区别是消息类型字段。我们将 ping 和 pong 数据包的总和称为 <em>心跳数据包</em> 。</p>
<p>通常节点会发送 ping 数据包，这将触发接收方使用 pong 数据包进行回复。然而，这不一定是真的。节点可以只发送 pong 数据包来向其他节点发送有关其配置的信息，而不会触发回复。这很有用，例如，为了尽快广播新配置。</p>
<p>通常一个节点每秒会 ping 几个随机节点，这样无论集群中有多少个节点，每个节点发送的 ping 数据包（和接收到的 pong 数据包）的总数都是一个常数。</p>
<p>但是，每个节点都确保对所有其他未发送 ping 或未收到 pong 的时间超过一半的节点执行 ping<code>NODE_TIMEOUT</code>操作。在<code>NODE_TIMEOUT</code>过去之前，节点还尝试重新连接与另一个节点的 TCP 链接，以确保不会仅因为当前 TCP 连接存在问题而认为节点不可达。</p>
<p>如果设置为一个小数字并且节点数 (N)  非常大，则全局交换的消息数可能会<code>NODE_TIMEOUT</code>很大，因为每半个节点都会尝试 ping 没有新信息的所有其他节点<code>NODE_TIMEOUT</code>时间。</p>
<p>例如，在节点超时设置为 60 秒的 100 节点集群中，每个节点将尝试每 30 秒发送 99 个 ping，总计每秒 3.3 个 ping。乘以 100 个节点，这就是整个集群中每秒 330 次 ping。</p>
<p>有一些方法可以减少消息的数量，但是目前没有关于 Redis 集群故障检测使用的带宽问题的报告，所以现在使用明显和直接的设计。请注意，即使在上面的示例中，每秒交换的 330 个数据包平均分配给 100 个不同的节点，因此每个节点接收的流量是可以接受的。</p>
<h3 id="心跳包内容"><a href="#心跳包内容" class="headerlink" title="心跳包内容"></a>心跳包内容</h3><p>Ping 和 Pong 数据包包含一个对所有类型的数据包（例如请求故障转移投票的数据包）通用的标头，以及一个特定于 Ping 和 Pong 数据包的特殊八卦部分。</p>
<p>公共标头具有以下信息：</p>
<ul>
<li>节点 ID，一个 160 位的伪随机字符串，在第一次创建节点时分配，并在 Redis 集群节点的整个生命周期内保持不变。</li>
<li>用于挂载 Redis Cluster 使用的分布式算法的发送节点的<code>currentEpoch</code>和<code>configEpoch</code>字段（这将在下一节中详细说明）。如果该节点是副本，则它<code>configEpoch</code>是其主节点的最后一个已知节点<code>configEpoch</code>。</li>
<li>节点标志，表示该节点是否为副本、主节点等单比特节点信息。</li>
<li>发送节点服务的哈希槽的位图，或者如果节点是副本，则它的主节点服务的槽的位图。</li>
<li>发送方 TCP 基本端口，即 Redis 用于接受客户端命令的端口。</li>
<li>集群端口，即 Redis 用于节点到节点通信的端口。</li>
<li>从发送者的角度来看集群的状态（关闭或正常）。</li>
<li>发送节点的主节点 ID（如果它是副本）。</li>
</ul>
<p>ping 和 pong 数据包也包含八卦部分。此部分向接收方提供发送方节点对集群中其他节点的看法。八卦部分仅包含有关发送方已知的节点集中的几个随机节点的信息。八卦部分中提到的节点数与集群大小成正比。</p>
<p>对于添加到八卦部分的每个节点，都会报告以下字段：</p>
<ul>
<li>节点 ID。</li>
<li>节点的 IP 和端口。</li>
<li>节点标志。</li>
</ul>
<p>八卦部分允许接收节点从发送方的角度获取有关其他节点状态的信息。这对于故障检测和发现集群中的其他节点都很有用。</p>
<h3 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h3><p>Redis 集群故障检测用于识别大多数节点何时不再可以访问主节点或副本节点，然后通过将副本提升为主节点角色来做出响应。当无法进行副本提升时，集群将处于错误状态以停止接收来自客户端的查询。</p>
<p>如前所述，每个节点都有一个与其他已知节点相关联的标志列表。有两个标志用于故障检测，称为<code>PFAIL</code>和<code>FAIL</code>。<code>PFAIL</code>表示 <em>Possible failure</em> ，并且是一种未确认的故障类型。<code>FAIL</code>意味着一个节点出现故障，并且这种情况在固定时间内得到了大多数主节点的确认。</p>
<p><strong>PFAIL 标志：</strong></p>
<p><code>PFAIL</code>当一个节点在超过 time 的时间内无法访问时，该节点会用 flag 标记另一个节点<code>NODE_TIMEOUT</code>。<code>PFAIL</code>无论其类型如何，主节点和副本节点都可以将另一个节点标记为。</p>
<p>Redis 集群节点的不可访问性的概念是我们有一个 <strong>活动的 ping</strong> （我们发送的 ping，但我们还没有得到回复）等待的时间超过<code>NODE_TIMEOUT</code>。为了使这种机制起作用，<code>NODE_TIMEOUT</code>与网络往返时间相比必须很大。为了在正常操作期间增加可靠性，节点将尝试在一半时间过去后立即重新连接集群中的其他节点<code>NODE_TIMEOUT</code>而没有对 ping 的回复。这种机制确保连接保持活动状态，因此断开的连接通常不会导致节点之间出现错误的故障报告。</p>
<p><strong>失败标志：</strong></p>
<p>单独的<code>PFAIL</code>标志只是每个节点拥有的关于其他节点的本地信息，但不足以触发副本提升。对于要被视为关闭的节点，<code>PFAIL</code>需要将条件升级为<code>FAIL</code>条件。</p>
<p>正如本文档的节点心跳部分所述，每个节点都会向其他每个节点发送八卦消息，包括一些随机已知节点的状态。每个节点最终都会收到一组用于其他每个节点的节点标志。这样每个节点都有一种机制来向其他节点发送有关它们检测到的故障情况的信号。</p>
<p>当满足以下一组条件时，<code>PFAIL</code>条件将升级为<code>FAIL</code>条件：</p>
<ul>
<li>一些节点，我们称之为 A，有另一个节点 B 标记为<code>PFAIL</code>。</li>
<li>节点 A 通过八卦部分从集群中大多数主节点的角度收集了关于 B 状态的信息。</li>
<li>大多数大师会及时发出信号<code>PFAIL</code>或<code>FAIL</code>条件<code>NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT</code>。（当前实现中有效性因子设置为 2，所以这只是时间的两倍<code>NODE_TIMEOUT</code>）。</li>
</ul>
<p>如果以上所有条件都为真，节点 A 将：</p>
<ul>
<li>将节点标记为<code>FAIL</code>。</li>
<li>向所有可达节点发送<code>FAIL</code>消息（而不是心跳消息中的条件）。<code>FAIL</code></li>
</ul>
<p>该<code>FAIL</code>消息将强制每个接收节点将节点标记为处于<code>FAIL</code>状态，无论它是否已经将节点标记为处于<code>PFAIL</code>状态。</p>
<p>请注意， <em>FAIL 标志主要是一种方式</em> 。也就是说，一个节点可以从<code>PFAIL</code>到<code>FAIL</code>，但是<code>FAIL</code>只有在以下情况下才能清除标志：</p>
<ul>
<li>该节点已经可达并且是一个副本。在这种情况下，<code>FAIL</code>可以清除标志，因为副本没有故障转移。</li>
<li>该节点已经可达并且是不为任何槽提供服务的主节点。在这种情况下，<code>FAIL</code>可以清除标志，因为没有插槽的主节点并不真正参与集群，而是在等待配置以加入集群。</li>
<li>该节点已经可以访问并且是主节点，但是已经过去了很长时间（N 倍<code>NODE_TIMEOUT</code>）而没有任何可检测到的副本提升。在这种情况下，它最好重新加入集群并继续。</li>
</ul>
<p>值得注意的是，虽然<code>PFAIL</code>-&gt;<code>FAIL</code>转换使用一种协议形式，但所使用的协议很弱：</p>
<ol>
<li>节点在一段时间内收集其他节点的意见，所以即使大多数主节点需要“同意”，实际上这只是我们在不同时间从不同节点收集的状态，我们不确定，也不需要，在特定时刻，大多数大师都同意。然而，我们丢弃了旧的失败报告，因此大多数大师在一个时间窗口内发出了失败信号。</li>
<li>虽然每个检测到该<code>FAIL</code>条件的节点都会使用该消息在集群中的其他节点上强制该条件<code>FAIL</code>，但无法确保该消息将到达所有节点。例如，一个节点可能会检测到这种<code>FAIL</code>情况，并且由于分区将无法到达任何其他节点。</li>
</ol>
<p>然而，Redis 集群故障检测有一个活性要求：最终所有节点都应该就给定节点的状态达成一致。有两种情况可能源于裂脑情况。少数节点认为节点处于<code>FAIL</code>状态，或者少数节点认为节点不处于<code>FAIL</code>状态。在这两种情况下，最终集群将拥有给定节点状态的单一视图：</p>
<p><strong>情况 1</strong> ：如果大多数主节点将一个节点标记为<code>FAIL</code>，由于故障检测及其产生的 <em>连锁效应</em> ，每个其他节点最终都会将主节点标记为<code>FAIL</code>，因为在指定的时间窗口内将报告足够多的故障。</p>
<p><strong>情况 2</strong> ：当只有少数 master 将节点标记为<code>FAIL</code>时，副本提升不会发生（因为它使用更正式的算法确保每个人最终都知道提升）并且每个节点都会根据<code>FAIL</code>状态清除<code>FAIL</code>状态上面的清算规则（即经过 N 次后没有提升<code>NODE_TIMEOUT</code>）。</p>
<p><strong>该<code>FAIL</code>标志仅用作运行</strong>副本提升算法的安全部分的触发器。理论上，副本可以独立行动并在其主人不可到达时开始副本提升，如果大多数人实际上可以到达主人，则等待主人拒绝提供确认。然而，状态的增加的复杂性<code>PFAIL -&gt; FAIL</code>、弱协议和<code>FAIL</code>消息在集群的可达部分中强制在最短时间内传播状态，具有实际优势。由于这些机制，如果集群处于错误状态，通常所有节点将大约同时停止接受写入。从使用 Redis 集群的应用程序的角度来看，这是一个理想的特性。也避免了由于本地问题而无法到达其主节点的副本发起的错误选举尝试（主节点可以被大多数其他主节点访问）。</p>
<h2 id="配置处理、传播和故障转移"><a href="#配置处理、传播和故障转移" class="headerlink" title="配置处理、传播和故障转移"></a>配置处理、传播和故障转移</h2><h3 id="集群当前纪元"><a href="#集群当前纪元" class="headerlink" title="集群当前纪元"></a>集群当前纪元</h3><p>Redis Cluster 使用了一个类似于 Raft 算法“term”的概念。在 Redis Cluster 中，这个术语被称为 epoch，它用于为事件提供增量版本控制。当多个节点提供相互冲突的信息时，另一个节点可以了解哪个状态是最新的。</p>
<p>是<code>currentEpoch</code>一个 64 位无符号数。</p>
<p>在创建节点时，每个 Redis 集群节点（包括副本节点和主节点）都将 设置<code>currentEpoch</code>为 0。</p>
<p>每次从另一个节点接收到数据包时，如果发送方的纪元（集群总线消息头的一部分）大于本地节点纪元，<code>currentEpoch</code>则更新为发送方纪元。</p>
<p>由于这些语义，最终所有节点都会同意<code>currentEpoch</code>集群中最大的节点。</p>
<p>当集群的状态发生变化并且节点寻求同意以执行某些操作时，将使用此信息。</p>
<p>目前，这仅在副本提升期间发生，如下一节所述。基本上，纪元是集群的逻辑时钟，并指示给定的信息胜过纪元较小的信息。</p>
<h3 id="配置纪元"><a href="#配置纪元" class="headerlink" title="配置纪元"></a>配置纪元</h3><p>每个 master 总是<code>configEpoch</code>在 ping 和 pong 数据包中通告它，连同一个位图通告它所服务的插槽集。</p>
<p><code>configEpoch</code>创建新节点时，masters 中的 设置为零。</p>
<p><code>configEpoch</code>在副本选举期间创建一个新的。试图替换失败的主人的副本增加他们的纪元并试图从大多数主人那里获得授权。当一个副本被授权时，一个新的 unique<code>configEpoch</code> 被创建并且副本使用新的<code>configEpoch</code>.</p>
<p>正如下一节中所解释的那样，<code>configEpoch</code>当不同的节点声明不同的配置时（这种情况可能由于网络分区和节点故障而发生），这有助于解决冲突。</p>
<p>副本节点也在<code>configEpoch</code>ping 和 pong 数据包中通告该字段，但在副本的情况下，该字段代表<code>configEpoch</code>其主节点上次交换数据包时的字段。这允许其他实例检测副本何时具有需要更新的旧配置（主节点不会向具有旧配置的副本授予投票）。</p>
<p>每次<code>configEpoch</code>某个已知节点发生更改时，所有接收此信息的节点都会将其永久存储在 nodes.conf 文件中。价值也是如此<code>currentEpoch</code>。<code>fsync-ed</code>在节点继续其操作之前更新时，保证这两个变量被保存并写入磁盘。</p>
<p>在故障转移期间使用简单算法生成的<code>configEpoch</code>值保证是新的、增量的和唯一的。</p>
<h3 id="副本选举和推广"><a href="#副本选举和推广" class="headerlink" title="副本选举和推广"></a>副本选举和推广</h3><p>副本选举和升级由副本节点处理，在主节点的帮助下投票支持副本升级。<code>FAIL</code>从至少一个具有成为主节点的先决条件的副本的角度来看，当主节点处于状态时，就会发生副本选举。</p>
<p>In order for a replica to promote itself to master, it needs to start an election and win it. All the replicas for a given master can start an election if the master is in <code>FAIL</code>state, however only one replica will win the election and promote itself to master.</p>
<p>当满足以下条件时，副本开始选举：</p>
<ul>
<li>副本的主人处于<code>FAIL</code>状态。</li>
<li>主人服务于非零数量的插槽。</li>
<li>副本复制链接与主副本断开的时间不超过给定的时间，以确保提升副本的数据相当新鲜。这个时间是用户可配置的。</li>
</ul>
<p>In order to be elected, the first step for a replica is to increment its <code>currentEpoch</code>counter, and request votes from master instances.</p>
<p>副本通过<code>FAILOVER_AUTH_REQUEST</code>向集群的每个主节点广播数据包来请求投票。然后它最多等待回复到达时间的两倍<code>NODE_TIMEOUT</code>（但总是至少 2 秒）。</p>
<p>一旦一个 master 投票给了一个给定的副本，并用 a 肯定地回复<code>FAILOVER_AUTH_ACK</code>，它就不能再投票给同一 master 的另一个副本一段时间了<code>NODE_TIMEOUT * 2</code>。在此期间将无法回复同一master的其他授权请求。这不是保证安全所必需的，但对于防止多个副本在大约同一时间被选中（即使具有不同的<code>configEpoch</code>）很有用，这通常是不希望的。</p>
<p>副本会丢弃任何<code>AUTH_ACK</code>纪元小于<code>currentEpoch</code>发送投票请求时的纪元的回复。这确保它不会计算用于之前选举的选票。</p>
<p>一旦副本收到来自大多数主服务器的 ACK，它就赢得了选举。否则，如果在两次<code>NODE_TIMEOUT</code>（但始终至少 2 秒）内未达到多数，则选举中止，并在之后<code>NODE_TIMEOUT * 4</code>（且始终至少 4 秒）再次尝试新的选举。</p>
<h3 id="副本等级"><a href="#副本等级" class="headerlink" title="副本等级"></a>副本等级</h3><p>As soon as a master is in <code>FAIL</code>state, a replica waits a short period of time before trying to get elected. 该延迟计算如下：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">DELAY = <span class="number">500</span> milliseconds + <span class="built_in">random</span> delay between <span class="number">0</span> <span class="keyword">and</span> <span class="number">500</span> milliseconds +</span><br><span class="line">        REPLICA_RANK * <span class="number">1000</span> milliseconds.</span><br></pre></td></tr></table></figure>

<p>The fixed delay ensures that we wait for the <code>FAIL</code>state to propagate across the cluster, otherwise the replica may try to get elected while the masters are still unaware of the <code>FAIL</code>state, refusing to grant their vote.</p>
<p>随机延迟用于使副本不同步，因此它们不太可能同时开始选举。</p>
<p><code>REPLICA_RANK</code>是此副本关于它从主服务器处理的复制数据量的排名。副本在主服务器发生故障时交换消息以建立（尽力而为）等级：具有最新复制偏移量的副本在等级 0，第二个更新的副本在等级 1，依此类推。以这种方式，最新的副本试图在其他副本之前被选出。</p>
<p>排名顺序没有严格执行；如果更高级别的副本未能被选出，其他人将很快尝试。</p>
<p>一旦复制品赢得了选举，它将获得一种新的独特和增量<code>configEpoch</code>，该独特和增量高于任何其他现有主人。它开始在 ping 和 pong 数据包中将自己宣传为 master，为一组服务插槽提供一个<code>configEpoch</code>将胜过过去的插槽。</p>
<p>为了加速其他节点的重新配置，一个 pong 数据包被广播到集群的所有节点。当前无法访问的节点最终将在从另一个节点接收到 ping 或 pong 数据包时重新配置，或者<code>UPDATE</code>如果检测到它通过心跳数据包发布的信息已过时，则会从另一个节点接收数据包。</p>
<p>其他节点将检测到有一个新的 master 服务于旧 master 服务的相同 slot 但具有更大的<code>configEpoch</code>，并将升级它们的配置。旧主控（或故障转移主控，如果它重新加入集群）的副本不仅会升级配置，还会重新配置以从新主控复制。下一节将解释如何配置重新加入集群的节点。</p>
<h3 id="大师回复副本投票请求"><a href="#大师回复副本投票请求" class="headerlink" title="大师回复副本投票请求"></a>大师回复副本投票请求</h3><p>在上一节中，我们讨论了复制品如何试图选举产生。本节从请求为给定副本投票的主节点的角度解释发生了什么。</p>
<p>主人以副本请求的形式接收投票<code>FAILOVER_AUTH_REQUEST</code>请求。</p>
<p>要获得投票权，需要满足以下条件：</p>
<ol>
<li>master 只对给定的 epoch 进行一次投票，并且拒绝对更早的 epoch 进行投票：每个 master 都有一个 lastVoteEpoch 字段，并且只要<code>currentEpoch</code>auth 请求数据包中的不大于 lastVoteEpoch 就会拒绝再次投票。当主人对投票请求作出肯定答复时， lastVoteEpoch 会相应更新，并安全地存储在磁盘上。</li>
<li>仅当副本的主节点标记为 时，主节点才会投票给副本<code>FAIL</code>。</li>
<li><code>currentEpoch</code>a小于 master的授权请求将<code>currentEpoch</code>被忽略。因此，主回复将始终<code>currentEpoch</code>与授权请求相同。如果同一个副本再次请求投票，递增<code>currentEpoch</code>，则可以保证新投票不能接受主服务器的旧延迟回复。</li>
</ol>
<p>不使用规则 3 导致的问题示例：</p>
<p>master 为 5， lastVoteEpoch<code>currentEpoch</code>为 1（几次选举失败后可能会出现这种情况）</p>
<ul>
<li>副本<code>currentEpoch</code>为 3。</li>
<li>Replica 尝试在 epoch 4 (3+1)  中被选举，master 回复 ok <code>currentEpoch</code>5，但是回复被延迟了。</li>
<li>副本将在稍后的时间再次尝试被选举，纪元为 5 (4+1) ，延迟回复到达副本为<code>currentEpoch</code>5，并被接受为有效。</li>
</ul>
<ol start="4">
<li><code>NODE_TIMEOUT * 2</code>如果已经投票给该主控的副本，那么在该主控的副本过去之前，主控不会投票给该主控的副本。This is not strictly required as it is not possible for two replicas to win the election in the same epoch. 然而，实际上，它确保当一个副本被选中时，它有足够的时间通知其他副本，并避免另一个副本赢得新选举的可能性，从而执行不必要的第二次故障转移。</li>
<li>大师们不会以任何方式努力选择最好的复制品。如果副本的 master 处于<code>FAIL</code>状态并且 master 在当前任期内没有投票，则授予赞成票。The best replica is the most likely to start an election and win it before the other replicas, since it will usually be able to start the voting process earlier because of its <em>higher rank</em> as explained in the previous section.</li>
<li>当一个主人拒绝为给定的副本投票时，没有否定的回应，这个请求被简单地忽略了。</li>
<li>Masters 不会投票给副本发送<code>configEpoch</code>小于<code>configEpoch</code>master 表中副本声明的槽的任何 a 的副本。请记住，副本发送<code>configEpoch</code>其主服务器的位图，以及其主服务器所服务的插槽的位图。这意味着请求投票的副本必须具有其要进行故障转移的插槽的配置，该配置更新或等于授予投票的主服务器的配置。</li>
</ol>
<h3 id="分区期间配置时期有用性的实际示例"><a href="#分区期间配置时期有用性的实际示例" class="headerlink" title="分区期间配置时期有用性的实际示例"></a>分区期间配置时期有用性的实际示例</h3><p>本节说明如何使用纪元概念来使副本提升过程对分区更具抵抗力。</p>
<ul>
<li>不再可以无限期地访问 master。master 有 A、B、C 三个副本。</li>
<li>Replica A wins the election and is promoted to master.</li>
<li>网络分区使 A 对大多数集群不可用。</li>
<li>Replica B wins the election and is promoted as master.</li>
<li>A 分区使 B 对大多数集群不可用。</li>
<li>之前的分区是固定的，A又可用了。</li>
</ul>
<p>此时 B 已关闭，A 再次可用，角色为 master（实际上<code>UPDATE</code>消息会立即重新配置它，但这里我们假设所有<code>UPDATE</code>消息都丢失了）。At the same time, replica C will try to get elected in order to fail over B. This is what happens:</p>
<ol>
<li>C will try to get elected and will succeed, since for the majority of masters its master is actually down. 它将获得一个新的增量<code>configEpoch</code>。</li>
<li>A 将无法声称自己是其哈希槽的主人，因为与 A 发布的相比，其他节点已经具有与更高配置时期（B 中的那个）相关联的相同哈希槽。</li>
<li>因此，所有节点将升级其表以将哈希槽分配给 C，集群将继续其操作。</li>
</ol>
<p>正如您将在下一节中看到的那样，重新加入集群的陈旧节点通常会尽快收到有关配置更改的通知，因为只要它对任何其他节点执行 ping 操作，接收方就会检测到它有陈旧信息并发送一个<code>UPDATE</code>信息。</p>
<h3 id="哈希槽配置传播"><a href="#哈希槽配置传播" class="headerlink" title="哈希槽配置传播"></a>哈希槽配置传播</h3><p>Redis 集群的一个重要部分是用于传播有关哪个集群节点正在为一组给定的哈希槽服务的信息的机制。这对于新集群的启动以及在副本被提升以服务于其故障主节点的插槽后升级配置的能力都至关重要。</p>
<p>相同的机制允许在不确定的时间内分区的节点以合理的方式重新加入集群。</p>
<p>散列槽配置有两种传播方式：</p>
<ol>
<li>心跳消息。ping 或 pong 数据包的发送者总是添加有关它（或它的主人，如果它是副本）所服务的哈希槽集的信息。</li>
<li><code>UPDATE</code>消息。由于在每个心跳包中都有关于发送者<code>configEpoch</code>和所服务的哈希槽集的信息，如果心跳包的接收者发现发送者信息陈旧，它将发送一个包含新信息的数据包，迫使陈旧节点更新其信息。</li>
</ol>
<p>心跳或<code>UPDATE</code>消息的接收者使用某些简单的规则来更新其将散列槽映射到节点的表。当一个新的 Redis Cluster 节点被创建时，它的本地哈希槽表被简单地初始化为<code>NULL</code>条目，这样每个哈希槽就不会绑定或链接到任何节点。这看起来类似于以下内容：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span> -&gt; <span class="literal">NULL</span></span><br><span class="line"><span class="number">1</span> -&gt; <span class="literal">NULL</span></span><br><span class="line"><span class="number">2</span> -&gt; <span class="literal">NULL</span></span><br><span class="line">...</span><br><span class="line"><span class="number">16383</span> -&gt; <span class="literal">NULL</span></span><br></pre></td></tr></table></figure>

<p>节点为了更新其哈希槽表而遵循的第一条规则如下：</p>
<p><strong>规则 1</strong> ：如果哈希槽未分配（设置为<code>NULL</code>），并且已知节点声明了它，我将修改我的哈希槽表并将声明的哈希槽关联到它。</p>
<p>因此，如果我们收到来自节点 A 的心跳，声称为哈希槽 1 和 2 提供配置纪元值为 3 的服务，则该表将被修改为：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span> -&gt; NULL</span><br><span class="line"><span class="number">1</span> -&gt; <span class="selector-tag">A</span> <span class="selector-attr">[3]</span></span><br><span class="line"><span class="number">2</span> -&gt; <span class="selector-tag">A</span> <span class="selector-attr">[3]</span></span><br><span class="line">...</span><br><span class="line"><span class="number">16383</span> -&gt; NULL</span><br></pre></td></tr></table></figure>

<p>在创建新的集群时，系统管理员需要手动分配（使用<a href="https://redis.io/commands/cluster-addslots"><code>CLUSTER ADDSLOTS</code></a> 命令，通过redis-cli命令行工具，或通过任何其他方式）每个主节点服务的槽只分配给节点本身，以及信息将在集群中快速传播。</p>
<p>然而，这条规则还不够。我们知道哈希槽映射可以在两个事件期间发生变化：</p>
<ol>
<li>副本在故障转移期间替换其主副本。</li>
<li>槽从一个节点重新分片到另一个节点。</li>
</ol>
<p>现在让我们关注故障转移。当一个副本故障转移到它的主节点上时，它会获得一个配置纪元，该纪元保证大于其主节点的配置纪元（并且通常大于之前生成的任何其他配置纪元）。例如，作为 A 的副本的节点 B 可能会通过配置纪元 4 对 A 进行故障转移。它将开始发送心跳包（第一次在集群范围内进行大量广播）并且由于以下第二条规则，接收者将更新他们的哈希槽表：</p>
<p><strong>规则 2</strong> ：如果已经分配了哈希槽，并且已知节点正在使用<code>configEpoch</code>大于<code>configEpoch</code>当前与该槽相关联的主节点的 a 对其进行广告，我会将哈希槽重新绑定到新节点。</p>
<p>因此，在收到来自 B 的消息，该消息声称服务哈希槽 1 和 2 且配置纪元为 4 时，接收方将按以下方式更新其表：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span> -&gt; NULL</span><br><span class="line"><span class="number">1</span> -&gt; <span class="selector-tag">B</span> <span class="selector-attr">[4]</span></span><br><span class="line"><span class="number">2</span> -&gt; <span class="selector-tag">B</span> <span class="selector-attr">[4]</span></span><br><span class="line">...</span><br><span class="line"><span class="number">16383</span> -&gt; NULL</span><br></pre></td></tr></table></figure>

<p>Liveness property：由于第二条规则，最终集群中的所有节点都会同意一个插槽的所有者是<code>configEpoch</code>广告它的节点中最大的那个。</p>
<p>Redis Cluster 中的这种机制称为 <strong>last failover wins</strong> 。</p>
<p>在重新分片期间也会发生同样的情况。当导入哈希槽的节点完成导入操作时，其配置纪元会增加，以确保更改将在整个集群中传播。</p>
<h3 id="更新消息，仔细看看"><a href="#更新消息，仔细看看" class="headerlink" title="更新消息，仔细看看"></a>更新消息，仔细看看</h3><p>考虑到上一节，可以更轻松地了解更新消息的工作原理。节点 A 可能会在一段时间后重新加入集群。它将发送心跳数据包，声称它服务于配置时期为 3 的哈希槽 1 和 2。所有具有更新信息的接收者将看到相同的哈希槽与具有更高配置时期的节点 B 相关联。因此，他们将向<code>UPDATE</code>A 发送一条消息，其中包含插槽的新配置。由于上面的 <strong>规则 2</strong> ，A 将更新其配置。</p>
<h3 id="节点如何重新加入集群"><a href="#节点如何重新加入集群" class="headerlink" title="节点如何重新加入集群"></a>节点如何重新加入集群</h3><p>当节点重新加入集群时，使用相同的基本机制。继续上面的示例，节点 A 将收到通知，哈希槽 1 和 2 现在由 B 提供服务。假设这两个是 A 提供的唯一哈希槽，则 A 提供的哈希槽计数将下降为 0！因此 A 将 <strong>重新配置为新 master 的副本</strong> 。</p>
<p>实际遵循的规则比这复杂一点。一般情况下，A 可能会在很长时间后重新加入，同时可能会发生原先由 A 服务的哈希槽由多个节点服务，例如哈希槽 1 可能由 B 服务，而哈希槽 2 由 C 服务.</p>
<p>因此，实际的<em>Redis Cluster 节点角色切换规则</em>是： <strong>主节点将更改其配置以复制（成为副本）窃取其最后一个哈希槽的节点</strong> 。</p>
<p>在重新配置期间，最终服务的哈希槽数将下降到零，节点将相应地重新配置。请注意，在基本情况下，这仅意味着旧主服务器将是故障转移后替换它的副本的副本。然而，在一般形式下，该规则涵盖了所有可能的情况。</p>
<p>副本完全相同：它们重新配置以复制窃取其前主节点的最后一个哈希槽的节点。</p>
<h3 id="副本迁移"><a href="#副本迁移" class="headerlink" title="副本迁移"></a>副本迁移</h3><p>Redis Cluster为了提高系统的可用性，实现了一个叫做 <em>副本迁移的概念。</em> 这个想法是，在具有主副本设置的集群中，如果副本和主副本之间的映射是固定的，那么如果单个节点发生多个独立故障，可用性会随着时间的推移而受到限制。</p>
<p>例如，在每个主节点都有一个副本的集群中，只要主节点或副本发生故障，集群就可以继续运行，但如果两者同时发生故障则不能。然而，有一类故障是由硬件或软件问题引起的单个节点的独立故障，这些问题会随着时间的推移而累积。例如：</p>
<ul>
<li>Master A 有一个副本 A1。</li>
<li>大师A失败了。A1 被提升为新主人。</li>
<li>三小时后，A1 以独立方式发生故障（与 A 的故障无关）。由于节点 A 仍处于关闭状态，因此没有其他副本可用于提升。群集无法继续正常操作。</li>
</ul>
<p>如果masters和replicas之间的映射是固定的，那么让集群更能抵抗上述场景的唯一方法就是为每个master添加replicas，但是这样做代价高昂，因为它需要执行更多的Redis实例，更多的内存，以及等等。</p>
<p>另一种方法是在集群中创建不对称性，并让集群布局随时间自动改变。例如，集群可能有三个主节点 A、B、C。A 和 B 各有一个副本，A1 和 B1。然而，主 C 不同，它有两个副本：C1 和 C2。</p>
<p>副本迁移是自动重新配置副本的过程，以便<em>迁移</em>到不再覆盖的主服务器（没有工作副本）。通过副本迁移，上面提到的场景变成了以下场景：</p>
<ul>
<li>大师A失败了。A1 被提升。</li>
<li>C2 作为 A1 的副本迁移，否则不受任何副本支持。</li>
<li>三小时后，A1 也发生故障。</li>
<li>C2 被提升为新的 master 以取代 A1。</li>
<li>集群可以继续操作。</li>
</ul>
<h3 id="副本迁移算法"><a href="#副本迁移算法" class="headerlink" title="副本迁移算法"></a>副本迁移算法</h3><p>迁移算法不使用任何形式的协议，因为 Redis 集群中的副本布局不是需要与配置时代保持一致和&#x2F;或版本化的集群配置的一部分。相反，它使用一种算法来避免在不支持主服务器时大量迁移副本。该算法保证最终（一旦集群配置稳定）每个主节点都将得到至少一个副本的支持。</p>
<p>这就是算法的工作原理。首先，我们需要在这种情况下定义什么是 <em>好的副本</em><code>FAIL</code>：从给定节点的角度来看，好的副本是不处于状态的副本。</p>
<p>在检测到至少有一个主节点没有良好副本的每个副本中触发算法的执行。然而，在检测到这种情况的所有副本中，只有一个子集应该采取行动。该子集实际上通常是单个副本，除非不同的副本在给定时刻对其他节点的故障状态的看法略有不同。</p>
<p><em>acting replica</em>是 masters 中附加的 replica 数量最多的 replica，它没有处于 FAIL 状态并且具有最小的 node ID 。</p>
<p>因此，例如，如果有 10 个 master，每个 1 个副本，2 个 master，每个 5 个副本，将尝试迁移的副本是 - 在具有 5 个副本的 2 个 master 中 - 具有最低节点 ID 的副本。鉴于没有使用协议，当集群配置不稳定时，可能会出现竞争条件，即多个副本认为自己是具有较低节点 ID 的非故障副本（这在实践中不太可能发生) . 如果发生这种情况，结果是多个副本迁移到同一个主服务器，这是无害的。如果竞争以一种让出的主节点没有副本的方式发生，一旦集群再次稳定，算法将再次重新执行并将副本迁移回原始主节点。</p>
<p>最终，每个 master 都将得到至少一个 replica 的支持。但是，正常行为是单个副本从具有多个副本的主服务器迁移到孤立的主服务器。</p>
<p>该算法由一个名为 的用户可配置参数控制 <code>cluster-migration-barrier</code>：在副本可以迁移之前，主服务器必须保留的良好副本的数量。例如，如果此参数设置为 2，则只有当其 master 保留两个工作副本时，副本才能尝试迁移。</p>
<h3 id="configEpoch冲突解决算法"><a href="#configEpoch冲突解决算法" class="headerlink" title="configEpoch冲突解决算法"></a>configEpoch冲突解决算法</h3><p>当在故障转移期间通过副本提升创建新<code>configEpoch</code>值时，它们保证是唯一的。</p>
<p>然而，有两个不同的事件，其中新的 configEpoch 值以不安全的方式创建，只是增加<code>currentEpoch</code>本地节点的 local 并希望同时没有冲突。这两个事件都是系统管理员触发的：</p>
<ol>
<li><a href="https://redis.io/commands/cluster-failover"><code>CLUSTER FAILOVER</code></a> 带有选项的命令能够在大多数主节点不可用的情况下<code>TAKEOVER</code>手动将副本节点提升为主节点。例如，这在多数据中心设置中很有用。</li>
<li>出于性能原因，用于集群重新平衡的插槽迁移也会在本地节点内生成新的配置时期，而无需达成一致。</li>
</ol>
<p>具体来说，在手动重新分片过程中，当一个哈希槽从节点 A 迁移到节点 B 时，重新分片程序将强制 B 将其配置升级到集群中最大的 epoch，加 1（除非该节点是已经是具有最大配置时代的那个），而不需要其他节点的同意。通常，真实世界的重新分片涉及移动数百个哈希槽（尤其是在小型集群中）。要求在重新分片期间为每个移动的哈希槽生成新的配置时期达成协议是低效的。此外，它每次都需要在每个集群节点中进行 fsync 以存储新配置。由于它的执行方式，我们只需要在移动第一个哈希槽时创建一个新的配置纪元，这使得它在生产环境中更加高效。</p>
<p>然而，由于上述两种情况，有可能（尽管不太可能）以具有相同配置时期的多个节点结束。<code>currentEpoch</code>如果传播速度不够快，系统管理员执行的重新分片操作和同时发生的故障转移（再加上很多运气不好）可能会导致冲突。</p>
<p>此外，软件错误和文件系统损坏也可能导致多个节点具有相同的配置时期。</p>
<p>当服务于不同哈希槽的 masters 具有相同的<code>configEpoch</code>时，没有问题。更重要的是，故障转移主服务器的副本具有唯一的配置纪元。</p>
<p>也就是说，手动干预或重新分片可能会以不同方式更改集群配置。Redis Cluster main liveness 属性要求 slot 配置总是收敛的，所以在任何情况下我们都希望所有的 master 节点都有不同的<code>configEpoch</code>.</p>
<p>为了强制执行这一点，如果两个节点最终具有相同的 . ，则使用<strong>冲突解决算法</strong><code>configEpoch</code>。</p>
<ul>
<li>如果一个主节点检测到另一个主节点正在用相同的<code>configEpoch</code>.</li>
<li>AND IF 与声明相同的其他节点相比，该节点具有字典序较小的节点 ID <code>configEpoch</code>。</li>
<li>然后它将其递增<code>currentEpoch</code>1，并将其用作新的<code>configEpoch</code>.</li>
</ul>
<p>如果有任何一组节点具有相同的<code>configEpoch</code>，则除了具有最大节点 ID 的节点之外的所有节点都将向前移动，从而保证最终每个节点都会选择一个唯一的 configEpoch，而不管发生了什么。</p>
<p>这种机制还保证在创建新集群后，所有节点都以不同的方式开始<code>configEpoch</code>（即使这实际上没有被使用）因为<code>redis-cli</code>确保<a href="https://redis.io/commands/cluster-set-config-epoch"><code>CLUSTER SET-CONFIG-EPOCH</code></a> 在启动时使用。但是，如果由于某种原因导致节点配置错误，它将自动将其配置更新为不同的配置时期。</p>
<h3 id="节点重置"><a href="#节点重置" class="headerlink" title="节点重置"></a>节点重置</h3><p>可以对节点进行软件重置（无需重新启动它们），以便在不同的角色或不同的集群中重复使用。这在正常操作、测试和云环境中很有用，在云环境中可以重新配置给定节点以加入不同的节点集以扩大或创建新集群。</p>
<p>在 Redis 集群中，节点是使用<a href="https://redis.io/commands/cluster-reset"><code>CLUSTER RESET</code></a> 命令重置的。该命令有两种变体：</p>
<ul>
<li><code>CLUSTER RESET SOFT</code></li>
<li><code>CLUSTER RESET HARD</code></li>
</ul>
<p>该命令必须直接发送到要重置的节点。如果未提供复位类型，则执行软复位。</p>
<p>以下是重置执行的操作列表：</p>
<ol>
<li>软硬重置：如果节点是副本，则将其变为主节点，并丢弃其数据集。如果该节点是主节点并且包含密钥，则重置操作将中止。</li>
<li>软硬复位：释放所有槽位，复位手动故障切换状态。</li>
<li>软硬重置：删除节点表中的所有其他节点，因此该节点不再知道任何其他节点。</li>
<li>仅限硬复位：<code>currentEpoch</code>、<code>configEpoch</code>和<code>lastVoteEpoch</code>设置为 0。</li>
<li>仅硬重置：节点 ID 更改为新的随机 ID。</li>
</ol>
<p>无法重置具有非空数据集的主节点（因为通常您希望将数据重新分片到其他节点）。但是，在适当的特殊情况下（例如，当一个集群为了创建一个新集群而被完全销毁时），<a href="https://redis.io/commands/flushall"><code>FLUSHALL</code></a> 必须在继续重置之前执行。</p>
<h3 id="从集群中删除节点"><a href="#从集群中删除节点" class="headerlink" title="从集群中删除节点"></a>从集群中删除节点</h3><p>通过将所有数据重新分片到其他节点（如果它是主节点）并关闭它，实际上可以从现有集群中删除一个节点。但是，其他节点仍会记住它的节点 ID 和地址，并会尝试与其建立连接。</p>
<p>出于这个原因，当一个节点被删除时，我们还想从所有其他节点表中删除它的条目。这是通过使用 <code>CLUSTER FORGET &lt;node-id&gt;</code>命令来完成的。</p>
<p>该命令做了两件事：</p>
<ol>
<li>它从节点表中删除具有指定节点 ID 的节点。</li>
<li>它设置了 60 秒的禁令，以防止重新添加具有相同节点 ID 的节点。</li>
</ol>
<p>需要第二个操作，因为 Redis 集群使用八卦来自动发现节点，因此从节点 A 中删除节点 X 可能会导致节点 B 再次向 A 闲聊节点 X。由于 60 秒的禁令，Redis 集群管理工具有 60 秒的时间从所有节点中删除节点，防止由于自动发现而重新添加节点。</p>
<p>文档中提供了更多信息<a href="https://redis.io/commands/cluster-forget"><code>CLUSTER FORGET</code></a> 。</p>
<h2 id="发布-x2F-订阅"><a href="#发布-x2F-订阅" class="headerlink" title="发布&#x2F;订阅"></a>发布&#x2F;订阅</h2><p>在 Redis 集群中，客户端可以订阅每个节点，也可以发布到每个其他节点。集群将确保发布的消息在需要时被转发。</p>
<p>客户端可以向任何节点发送 SUBSCRIBE，也可以向任何节点发送 PUBLISH。它会简单地将每条发布的消息广播到所有其他节点。</p>
<p>Redis 7.0 及更高版本具有分片发布&#x2F;订阅功能，其中分片通道通过用于将键分配给插槽的相同算法分配给插槽。分片消息必须发送到拥有分片通道散列到的槽的节点。集群确保已发布的分片消息被转发到分片中的所有节点，因此客户端可以通过连接到负责插槽的主节点或其任何副本来订阅分片通道。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="附录-A：ANSI-C-中的-CRC16-参考实现"><a href="#附录-A：ANSI-C-中的-CRC16-参考实现" class="headerlink" title="附录 A：ANSI C 中的 CRC16 参考实现"></a>附录 A：ANSI C 中的 CRC16 参考实现</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">/<span class="emphasis">*</span></span><br><span class="line"><span class="emphasis"> *</span> Copyright 2001-2010 Georges Menie (www.menie.org) </span><br><span class="line"><span class="bullet"> *</span> Copyright 2010 Salvatore Sanfilippo (adapted to Redis coding style) </span><br><span class="line"><span class="bullet"> *</span> All rights reserved.</span><br><span class="line"><span class="bullet"> *</span> Redistribution and use in source and binary forms, with or without</span><br><span class="line"><span class="bullet"> *</span> modification, are permitted provided that the following conditions are met:</span><br><span class="line"><span class="bullet"> *</span></span><br><span class="line"> <span class="emphasis">*     *</span> Redistributions of source code must retain the above copyright</span><br><span class="line"><span class="bullet"> *</span>       notice, this list of conditions and the following disclaimer.</span><br><span class="line"><span class="bullet"> *</span>     <span class="emphasis">* Redistributions in binary form must reproduce the above copyright</span></span><br><span class="line"><span class="emphasis"> *</span>       notice, this list of conditions and the following disclaimer in the</span><br><span class="line"><span class="bullet"> *</span>       documentation and/or other materials provided with the distribution.</span><br><span class="line"><span class="bullet"> *</span>     <span class="emphasis">* Neither the name of the University of California, Berkeley nor the</span></span><br><span class="line"><span class="emphasis"> *</span>       names of its contributors may be used to endorse or promote products</span><br><span class="line"><span class="bullet"> *</span>       derived from this software without specific prior written permission.</span><br><span class="line"><span class="bullet"> *</span></span><br><span class="line"> <span class="emphasis">* THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS&#x27;&#x27; AND ANY</span></span><br><span class="line"><span class="emphasis"> *</span> EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED</span><br><span class="line"><span class="bullet"> *</span> WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE</span><br><span class="line"><span class="bullet"> *</span> DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY</span><br><span class="line"><span class="bullet"> *</span> DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES</span><br><span class="line"><span class="bullet"> *</span> (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;</span><br><span class="line"><span class="bullet"> *</span> LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)  HOWEVER CAUSED AND</span><br><span class="line"><span class="bullet"> *</span> ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT</span><br><span class="line"><span class="bullet"> *</span> (INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING IN ANY WAY OUT OF THE USE OF THIS</span><br><span class="line"><span class="bullet"> *</span> SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span><br><span class="line"> <span class="emphasis">*/</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">/*</span> CRC16 implementation according to CCITT standards.</span><br><span class="line"><span class="bullet"> *</span></span><br><span class="line"> <span class="emphasis">* Note by @antirez: this is actually the XMODEM CRC 16 algorithm, using the</span></span><br><span class="line"><span class="emphasis"> *</span> following parameters:</span><br><span class="line"><span class="bullet"> *</span></span><br><span class="line"> <span class="emphasis">* Name                       : &quot;XMODEM&quot;, also known as &quot;ZMODEM&quot;, &quot;CRC-16/ACORN&quot;</span></span><br><span class="line"><span class="emphasis"> *</span> Width                      : 16 bit</span><br><span class="line"><span class="bullet"> *</span> Poly                       : 1021 (That is actually x^16 + x^12 + x^5 + 1) </span><br><span class="line"><span class="bullet"> *</span> Initialization             : 0000</span><br><span class="line"><span class="bullet"> *</span> Reflect Input byte         : False</span><br><span class="line"><span class="bullet"> *</span> Reflect Output CRC         : False</span><br><span class="line"><span class="bullet"> *</span> Xor constant to output CRC : 0000</span><br><span class="line"><span class="bullet"> *</span> Output for &quot;123456789&quot;     : 31C3</span><br><span class="line"> <span class="emphasis">*/</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">static const uint16_t crc16tab[256]= &#123;</span></span><br><span class="line"><span class="emphasis">    0x0000,0x1021,0x2042,0x3063,0x4084,0x50a5,0x60c6,0x70e7,</span></span><br><span class="line"><span class="emphasis">    0x8108,0x9129,0xa14a,0xb16b,0xc18c,0xd1ad,0xe1ce,0xf1ef,</span></span><br><span class="line"><span class="emphasis">    0x1231,0x0210,0x3273,0x2252,0x52b5,0x4294,0x72f7,0x62d6,</span></span><br><span class="line"><span class="emphasis">    0x9339,0x8318,0xb37b,0xa35a,0xd3bd,0xc39c,0xf3ff,0xe3de,</span></span><br><span class="line"><span class="emphasis">    0x2462,0x3443,0x0420,0x1401,0x64e6,0x74c7,0x44a4,0x5485,</span></span><br><span class="line"><span class="emphasis">    0xa56a,0xb54b,0x8528,0x9509,0xe5ee,0xf5cf,0xc5ac,0xd58d,</span></span><br><span class="line"><span class="emphasis">    0x3653,0x2672,0x1611,0x0630,0x76d7,0x66f6,0x5695,0x46b4,</span></span><br><span class="line"><span class="emphasis">    0xb75b,0xa77a,0x9719,0x8738,0xf7df,0xe7fe,0xd79d,0xc7bc,</span></span><br><span class="line"><span class="emphasis">    0x48c4,0x58e5,0x6886,0x78a7,0x0840,0x1861,0x2802,0x3823,</span></span><br><span class="line"><span class="emphasis">    0xc9cc,0xd9ed,0xe98e,0xf9af,0x8948,0x9969,0xa90a,0xb92b,</span></span><br><span class="line"><span class="emphasis">    0x5af5,0x4ad4,0x7ab7,0x6a96,0x1a71,0x0a50,0x3a33,0x2a12,</span></span><br><span class="line"><span class="emphasis">    0xdbfd,0xcbdc,0xfbbf,0xeb9e,0x9b79,0x8b58,0xbb3b,0xab1a,</span></span><br><span class="line"><span class="emphasis">    0x6ca6,0x7c87,0x4ce4,0x5cc5,0x2c22,0x3c03,0x0c60,0x1c41,</span></span><br><span class="line"><span class="emphasis">    0xedae,0xfd8f,0xcdec,0xddcd,0xad2a,0xbd0b,0x8d68,0x9d49,</span></span><br><span class="line"><span class="emphasis">    0x7e97,0x6eb6,0x5ed5,0x4ef4,0x3e13,0x2e32,0x1e51,0x0e70,</span></span><br><span class="line"><span class="emphasis">    0xff9f,0xefbe,0xdfdd,0xcffc,0xbf1b,0xaf3a,0x9f59,0x8f78,</span></span><br><span class="line"><span class="emphasis">    0x9188,0x81a9,0xb1ca,0xa1eb,0xd10c,0xc12d,0xf14e,0xe16f,</span></span><br><span class="line"><span class="emphasis">    0x1080,0x00a1,0x30c2,0x20e3,0x5004,0x4025,0x7046,0x6067,</span></span><br><span class="line"><span class="emphasis">    0x83b9,0x9398,0xa3fb,0xb3da,0xc33d,0xd31c,0xe37f,0xf35e,</span></span><br><span class="line"><span class="emphasis">    0x02b1,0x1290,0x22f3,0x32d2,0x4235,0x5214,0x6277,0x7256,</span></span><br><span class="line"><span class="emphasis">    0xb5ea,0xa5cb,0x95a8,0x8589,0xf56e,0xe54f,0xd52c,0xc50d,</span></span><br><span class="line"><span class="emphasis">    0x34e2,0x24c3,0x14a0,0x0481,0x7466,0x6447,0x5424,0x4405,</span></span><br><span class="line"><span class="emphasis">    0xa7db,0xb7fa,0x8799,0x97b8,0xe75f,0xf77e,0xc71d,0xd73c,</span></span><br><span class="line"><span class="emphasis">    0x26d3,0x36f2,0x0691,0x16b0,0x6657,0x7676,0x4615,0x5634,</span></span><br><span class="line"><span class="emphasis">    0xd94c,0xc96d,0xf90e,0xe92f,0x99c8,0x89e9,0xb98a,0xa9ab,</span></span><br><span class="line"><span class="emphasis">    0x5844,0x4865,0x7806,0x6827,0x18c0,0x08e1,0x3882,0x28a3,</span></span><br><span class="line"><span class="emphasis">    0xcb7d,0xdb5c,0xeb3f,0xfb1e,0x8bf9,0x9bd8,0xabbb,0xbb9a,</span></span><br><span class="line"><span class="emphasis">    0x4a75,0x5a54,0x6a37,0x7a16,0x0af1,0x1ad0,0x2ab3,0x3a92,</span></span><br><span class="line"><span class="emphasis">    0xfd2e,0xed0f,0xdd6c,0xcd4d,0xbdaa,0xad8b,0x9de8,0x8dc9,</span></span><br><span class="line"><span class="emphasis">    0x7c26,0x6c07,0x5c64,0x4c45,0x3ca2,0x2c83,0x1ce0,0x0cc1,</span></span><br><span class="line"><span class="emphasis">    0xef1f,0xff3e,0xcf5d,0xdf7c,0xaf9b,0xbfba,0x8fd9,0x9ff8,</span></span><br><span class="line"><span class="emphasis">    0x6e17,0x7e36,0x4e55,0x5e74,0x2e93,0x3eb2,0x0ed1,0x1ef0</span></span><br><span class="line"><span class="emphasis">&#125;;</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">uint16_t crc16(const char *</span>buf, int len)  &#123;</span><br><span class="line"><span class="code">    int counter;</span></span><br><span class="line"><span class="code">    uint16_t crc = 0;</span></span><br><span class="line"><span class="code">    for (counter = 0; counter &lt; len; counter++) </span></span><br><span class="line"><span class="code">            crc = (crc&lt;&lt;8)  ^ crc16tab[((crc&gt;&gt;8)  ^ *buf++) &amp;0x00FF];</span></span><br><span class="line"><span class="code">    return crc;</span></span><br><span class="line"><span class="code">&#125;</span></span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote>
<p><a href="https://redis.io/docs/reference/cluster-spec/">https://redis.io/docs/reference/cluster-spec/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>Go语言学习-快速入门</title>
    <url>/2021/11/27/go/basic-grammar/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>最近觉得Go语言很有前途，语法灵活，容器化部署方便，资源消耗小。<br>而且还有强力的并发能力：Goroutines<br>所以决定从今天开始，学习Go语言。</p>
<p>这一次我们将学习到：</p>
<ul>
<li>Golang基本概念</li>
<li>基本数据类型</li>
<li>基本语法</li>
<li>复杂类型</li>
<li>方法与协程</li>
</ul>
<p>我们现在开始吧！</p>
<span id="more"></span>

<h2 id="Golang基本概念"><a href="#Golang基本概念" class="headerlink" title="Golang基本概念"></a>Golang基本概念</h2><p>Go， 他是一款Google开发的语言。<br>他是静态的<br>他是编译形语言<br>他拥有垃圾回收器<br>他有强大的并发机制</p>
<p>在容器越来越流行的今天，Go语言拥有着非常大的潜力。</p>
<h2 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h2><p>我们使用<code>var</code>来声明一个变量，用<code>const</code>来声明一个常量。<br>当然还有一个简便的写法，使用<code>:</code></p>
<h3 id="int类型"><a href="#int类型" class="headerlink" title="int类型"></a>int类型</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">		i1       = <span class="number">1</span></span><br><span class="line">		i2       = <span class="number">1000</span></span><br><span class="line">		i3 <span class="type">int8</span>  = <span class="number">127</span></span><br><span class="line">		i4 <span class="type">int16</span> = <span class="number">128</span></span><br><span class="line">		i5 <span class="type">uint</span>  = <span class="number">257</span></span><br><span class="line">		i6 <span class="type">int</span>   = <span class="number">0</span>b101</span><br><span class="line">		i7       = <span class="number">0</span>o77</span><br><span class="line">		i8       = <span class="number">0xAF</span></span><br><span class="line">	)</span><br><span class="line">	fmt.Println(i1, i2, i3, i4, i5, i6, i7, i8)</span><br></pre></td></tr></table></figure>
<p>上面的代码，展示了不同类型的int类型。大家酌情使用。</p>
<h3 id="float类型"><a href="#float类型" class="headerlink" title="float类型"></a>float类型</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	f1         = <span class="number">0.1</span></span><br><span class="line">	f2 <span class="type">float64</span> = <span class="number">0.0001</span></span><br><span class="line">)</span><br><span class="line">fmt.Println(f1, f2)</span><br></pre></td></tr></table></figure>
<p>float类型有两种，对应Java中的Float和Double。</p>
<h3 id="byte类型"><a href="#byte类型" class="headerlink" title="byte类型"></a>byte类型</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	c1 <span class="type">byte</span></span><br><span class="line">	c2 = <span class="string">&#x27;c&#x27;</span></span><br><span class="line">	c3 = <span class="string">&#x27;鹏&#x27;</span></span><br><span class="line">)</span><br><span class="line">fmt.Printf(<span class="string">&quot;\&quot;%v, %T; %v, %T; %v, %T \n&quot;</span>, c1, c1, c2, c2, c3, c3)</span><br><span class="line"></span><br><span class="line">c4 := <span class="string">&#x27;a&#x27;</span></span><br><span class="line">c5 := <span class="string">&#x27;A&#x27;</span></span><br><span class="line">c6 := <span class="string">&#x27;x&#x27;</span> + c5 - c4</span><br><span class="line">fmt.Println(c6, <span class="type">string</span>(c6))</span><br></pre></td></tr></table></figure>
<p>为了节约内存，go使用了byte来做string的底层，所以中文可能会被截断。<br>Java在9之后，String的底层也从char变成了byte。</p>
<h3 id="boolean"><a href="#boolean" class="headerlink" title="boolean"></a>boolean</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> b1 <span class="type">bool</span> = <span class="literal">true</span></span><br><span class="line"><span class="keyword">var</span> b2 = <span class="literal">false</span></span><br><span class="line">b3 := b1 &amp;&amp; b2</span><br><span class="line">fmt.Println(b1, b2, b3)</span><br></pre></td></tr></table></figure>

<h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">s1 := <span class="string">&quot;hello&quot;</span></span><br><span class="line">s2 := <span class="string">&quot;世界&quot;</span></span><br><span class="line">fmt.Println(s1 + s2)</span><br><span class="line">fmt.Println(<span class="built_in">len</span>(s1), <span class="built_in">len</span>(s2))</span><br></pre></td></tr></table></figure>

<h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><h3 id="变量与常量"><a href="#变量与常量" class="headerlink" title="变量与常量"></a>变量与常量</h3><h4 id="变量声明的几种方式"><a href="#变量声明的几种方式" class="headerlink" title="变量声明的几种方式"></a>变量声明的几种方式</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> v1 <span class="type">int</span></span><br><span class="line">v1 = <span class="number">1</span></span><br><span class="line"><span class="keyword">var</span> v2 <span class="type">int</span> = <span class="number">2</span></span><br><span class="line"><span class="keyword">var</span> v3 = <span class="number">3</span></span><br><span class="line">v4 := <span class="number">4</span></span><br><span class="line">fmt.Println(v1, v2, v3, v4)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	v5 = <span class="number">5</span></span><br><span class="line">	v6 = <span class="number">6</span></span><br><span class="line">)</span><br><span class="line">fmt.Println(v5, v6)</span><br><span class="line">fmt.Println(globalVariable)</span><br></pre></td></tr></table></figure>
<p>变量不会定义成特定的类型，他会进行类型推断。<br>还有比较有特色的声明方式是使用<code>:=</code></p>
<h4 id="常量声明"><a href="#常量声明" class="headerlink" title="常量声明"></a>常量声明</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> c1 = <span class="number">1</span> <span class="comment">// 1</span></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">	c2 = <span class="number">2</span>    <span class="comment">//2</span></span><br><span class="line">	c3 = <span class="literal">iota</span> <span class="comment">//1 当前行数（从0开始）</span></span><br><span class="line">	c4 = <span class="literal">iota</span> <span class="comment">//2</span></span><br><span class="line">	c5        <span class="comment">//3 默认值为上一行</span></span><br><span class="line">	c6        <span class="comment">//4</span></span><br><span class="line">	c7 = <span class="number">7</span>    <span class="comment">//7</span></span><br><span class="line">	c8        <span class="comment">//7 默认值为上一行</span></span><br><span class="line">	c9        <span class="comment">//7</span></span><br><span class="line">)</span><br><span class="line">fmt.Println(c1, c2, c3, c4, c5, c6, c7, c8, c9)</span><br><span class="line">fmt.Println(globalConstant)</span><br></pre></td></tr></table></figure>
<p>常量充当的是Java中final关键字的功能，还有枚举的功能。</p>
<h3 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h3><p>我们通过<code>if else</code>， <code>for loop</code> 等来控制程序的执行流程。</p>
<h4 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> s = rand.Int31n(<span class="number">100</span>)</span><br><span class="line">fmt.Println(s)</span><br><span class="line"><span class="keyword">if</span> s &gt; <span class="number">60</span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;pass&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;fall&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> s <span class="type">int32</span> = rand.Int31n(<span class="number">100</span>)</span><br><span class="line">fmt.Println(s)</span><br><span class="line"><span class="keyword">switch</span> &#123;</span><br><span class="line"><span class="keyword">case</span> s &lt; <span class="number">10</span>:</span><br><span class="line">	fmt.Println(<span class="string">&quot;太差了&quot;</span>)</span><br><span class="line"><span class="keyword">case</span> s &lt; <span class="number">60</span>:</span><br><span class="line">	fmt.Println(<span class="string">&quot;不及格&quot;</span>)</span><br><span class="line"><span class="keyword">case</span> s &lt; <span class="number">80</span>:</span><br><span class="line">	<span class="keyword">fallthrough</span></span><br><span class="line"><span class="keyword">case</span> s &lt; <span class="number">100</span>:</span><br><span class="line">	fmt.Println(<span class="string">&quot;good&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两种条件的方式，更多的是使用if。</p>
<h4 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">i := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> i &gt;= <span class="number">10</span> &#123;</span><br><span class="line">		<span class="keyword">break</span></span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Print(i)</span><br><span class="line">	i++</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println()</span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i &lt; <span class="number">10</span> &#123;</span><br><span class="line">	fmt.Print(i)</span><br><span class="line">	i++</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">	fmt.Print(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不想Java有三种循环方式<code>while</code>、<code>do while</code>、<code>for</code>，<br>Go只有<code>for</code>这一种方式，当时功能依旧强大，有类似python的<code>range</code>关键字。<br>当然，依旧有<code>break</code>和<code>continue</code>的支持</p>
<h3 id="init函数"><a href="#init函数" class="headerlink" title="init函数"></a>init函数</h3><p>init()函数会在当前go文件加载前加载，<br>他的加载顺序是：<br>被依赖包的全局变量 -&gt; 被依赖包的init函数 -&gt; 当前包的全局变量 -&gt; 当前包的init函数 -&gt; 当前包的函数</p>
<p>这个方法可以在程序一开始的时候，创建一些数据连接什么的。</p>
<p>使用方法如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;this main init function&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="异常与错误"><a href="#异常与错误" class="headerlink" title="异常与错误"></a>异常与错误</h3><p>每一种程序都会有一场，在go语言种，使用panic机制来表示异常。<br>恐慌，很形象。</p>
<p>比如抛出一个异常可以这样：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="built_in">panic</span>(Error)</span><br></pre></td></tr></table></figure>

<p>我们可以生成一个error，来让panic抛出。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> lovelyError = errors.New(<span class="string">&quot;this is a lovely error&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> cuteError = fmt.Errorf(<span class="string">&quot;this is a cute error&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>有了异常和抛出异常，当然会有捕获异常，<br>在go里面是使用<code>defer</code>（延迟）和 <code>recover</code>（恢复）来做的。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">errorOperation</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">var</span> e = <span class="built_in">recover</span>()</span><br><span class="line">		fmt.Println(<span class="string">&quot;recover:&quot;</span>, e)</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">var</span> lovelyError = errors.New(<span class="string">&quot;this is a lovely error&quot;</span>)</span><br><span class="line">	<span class="keyword">var</span> cuteError = fmt.Errorf(<span class="string">&quot;this is a cute error&quot;</span>)</span><br><span class="line">	fmt.Println(lovelyError, <span class="string">&quot;;&quot;</span>, cuteError)</span><br><span class="line"></span><br><span class="line">	<span class="built_in">panic</span>(cuteError)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="函数与接口"><a href="#函数与接口" class="headerlink" title="函数与接口"></a>函数与接口</h3><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><p>go的函数声明类似Java的方法声明，但是又有所增强。</p>
<p>简单的函数声明</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">add</span><span class="params">(a <span class="type">int</span>, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> a + b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>返回两个变量</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sumAndDiff</span><span class="params">(a <span class="type">int</span>, b <span class="type">int</span>)</span></span> (<span class="type">int</span>, <span class="type">int</span>) &#123;</span><br><span class="line">	sum := a + b</span><br><span class="line">	diff := a - b</span><br><span class="line">	<span class="keyword">return</span> sum, diff</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>匿名函数</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">anonymousFunc</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> f = <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		fmt.Println(<span class="string">&quot;I am anonymous function&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	f()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>闭包</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">incr</span><span class="params">()</span></span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> x <span class="type">int</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">int</span> &#123;</span><br><span class="line">        x++</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h4><blockquote>
<p>如果它看起来像鸭子、游泳像鸭子、叫声像鸭子，那么它可能就是只鸭子。</p>
</blockquote>
<p>go的接口和接口的实现，参考的是这种思想。</p>
<p>我们先声明一个接口：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Message <span class="keyword">interface</span> &#123;</span><br><span class="line">	getType() <span class="type">string</span></span><br><span class="line">	send()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，这个接口，定义了两个函数。</p>
<p>再来声明一个struct来实现这个接口</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// TextMsg obj</span></span><br><span class="line"><span class="keyword">type</span> TextMsg <span class="keyword">struct</span> &#123;</span><br><span class="line">	text <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tm *TextMsg)</span></span> getType() <span class="type">string</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tm *TextMsg)</span></span> send() &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;sendText -&gt; &quot;</span>, tm.text, <span class="string">&quot;; type is &quot;</span>, tm.getType())</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>大家可以看到， TextMsg并没有直接声明 implement Message接口<br>但是 TextMsg 绑定了Message接口的两个函数，当然，还可以绑定自己的函数。</p>
<p>这样的话，程序就会认为，TextMsg就是Message的实现结构体。</p>
<h2 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h2><h3 id="array"><a href="#array" class="headerlink" title="array"></a>array</h3><p>和Java中的数组一样，需要提前定义好数组的容量。<br>直接分配内存，效率高。</p>
<p>使用方式如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> array [<span class="number">3</span>]<span class="type">int</span> = [<span class="number">3</span>]<span class="type">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">fmt.Println(array[<span class="number">1</span>], <span class="built_in">len</span>(array))</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> array1 = [...]<span class="type">int</span>&#123;<span class="number">4</span>,</span><br><span class="line">	<span class="number">5</span>,</span><br><span class="line">	<span class="number">6</span>&#125;</span><br><span class="line">fmt.Println(array1[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, v := <span class="keyword">range</span> array1 &#123;</span><br><span class="line">	fmt.Println(i, <span class="string">&quot;的值是&quot;</span>, v)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>二维数组：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> points = [<span class="number">3</span>][<span class="number">2</span>]<span class="type">int</span>&#123;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;, &#123;<span class="number">2</span>, <span class="number">2</span>&#125;, &#123;<span class="number">3</span>, <span class="number">3</span>&#125;&#125;</span><br><span class="line"><span class="keyword">for</span> _, point := <span class="keyword">range</span> points &#123;</span><br><span class="line">	fmt.Println(point)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="slice"><a href="#slice" class="headerlink" title="slice"></a>slice</h3><p>切片是Go中使用的最多的列表，类似Java中的ArrayList。</p>
<p>很多种方法可以创建一个切片。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">createSlice</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// from array</span></span><br><span class="line">	array := [<span class="number">5</span>]<span class="type">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">	<span class="keyword">var</span> s1 = array[<span class="number">0</span> : <span class="built_in">len</span>(array)<span class="number">-1</span>]</span><br><span class="line">	fmt.Println(s1)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// from slice</span></span><br><span class="line">	<span class="keyword">var</span> s2 = s1[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">	fmt.Println(s2)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// make</span></span><br><span class="line">	s3 := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">0</span>)</span><br><span class="line">	fmt.Println(s3)</span><br><span class="line">	s3 = <span class="built_in">append</span>(s3, <span class="number">3</span>)</span><br><span class="line">	fmt.Println(s3)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// sugar</span></span><br><span class="line">	s4 := []<span class="type">int</span>&#123;<span class="number">4</span>&#125;</span><br><span class="line">	fmt.Println(s4)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>他是一种动态数组，支持自动扩容，底层当然是array。<br>可以参考Java中ArrayList的实现和扩容方式。<br>他有着长度和容量两个数值。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">lenAndCap</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> slice = <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">8</span>, <span class="number">10</span>)</span><br><span class="line">	fmt.Println(slice, <span class="built_in">len</span>(slice), <span class="built_in">cap</span>(slice))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然还支持着拼接和copy</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">appendSlice</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> s1 = []<span class="type">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">	fmt.Println(s1, <span class="built_in">len</span>(s1), <span class="built_in">cap</span>(s1))</span><br><span class="line">	s1 = <span class="built_in">append</span>(s1, <span class="number">4</span>)</span><br><span class="line">	fmt.Println(s1, <span class="built_in">len</span>(s1), <span class="built_in">cap</span>(s1))</span><br><span class="line">	s1 = <span class="built_in">append</span>(s1, []<span class="type">int</span>&#123;<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>&#125;...)</span><br><span class="line">	fmt.Println(s1, <span class="built_in">len</span>(s1), <span class="built_in">cap</span>(s1))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">copySlice</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> s1 = []<span class="type">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">	<span class="keyword">var</span> s2 = []<span class="type">int</span>&#123;<span class="number">6</span>, <span class="number">7</span>&#125;</span><br><span class="line">	fmt.Println(s1, s2)</span><br><span class="line">	<span class="built_in">copy</span>(s1, s2)</span><br><span class="line">	fmt.Println(s1, s2)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在go中没有栈和队列的数据结构，一般都是用slice来模拟的。</p>
<h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><p>go中的map类似与Java中的HashMap，基本操作如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">createMap</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> m1 = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>)</span><br><span class="line">	m1[<span class="string">&quot;morning&quot;</span>] = <span class="string">&quot;eat breakfast&quot;</span></span><br><span class="line">	m1[<span class="string">&quot;noon&quot;</span>] = <span class="string">&quot;have lunch&quot;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> m2 = <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>&#123;</span><br><span class="line">		<span class="string">&quot;evening&quot;</span>: <span class="string">&quot;get dinner&quot;</span>,</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	fmt.Println(m1, m2)</span><br><span class="line"></span><br><span class="line">	fmt.Println(m1[<span class="string">&quot;noom&quot;</span>], m2[<span class="string">&quot;evening&quot;</span>])</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">findDeleteRange</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> m1 = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>)</span><br><span class="line">	m1[<span class="string">&quot;morning&quot;</span>] = <span class="string">&quot;eat breakfast&quot;</span></span><br><span class="line">	m1[<span class="string">&quot;noon&quot;</span>] = <span class="string">&quot;have lunch&quot;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> v, ok = m1[<span class="string">&quot;noon&quot;</span>]</span><br><span class="line">	fmt.Println(v, ok)</span><br><span class="line"></span><br><span class="line">	<span class="built_in">delete</span>(m1, <span class="string">&quot;noon&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> key, value := <span class="keyword">range</span> m1 &#123;</span><br><span class="line">		fmt.Println(key, value)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="方法与协程"><a href="#方法与协程" class="headerlink" title="方法与协程"></a>方法与协程</h2><h3 id="goroutine"><a href="#goroutine" class="headerlink" title="goroutine"></a>goroutine</h3><p>Go语言的核心之一，最最重要的特点，就是goroutine。<br>就是Go语言原生帮我实现的协程，又成用户线程。<br>可以非常快速和方便的实现异步操作。</p>
<p>使用方法非常简单：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> function()</span><br></pre></td></tr></table></figure>
<p>这样就会表示，新开一个协程来调用<code>function()</code>函数。</p>
<p>在Java中需要这样写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; function()).start();</span><br></pre></td></tr></table></figure>
<p>当然还可以使用协程池来开启一个新线程。</p>
<p>但是不管那种方式，不管是在使用方便的程度，还是程序的运行效率。<br>Go 的 goroutine都更加优异。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> doWork1()</span><br><span class="line">	<span class="keyword">go</span> doWork2()</span><br><span class="line">	fmt.Println(<span class="string">&quot;END&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork2</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-2&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork1</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-1&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/2Ml3uc.png"></p>
<p>类似这个图，<code>END</code>,<code>WORK-1</code>,<code>WORK-2</code>的顺序是没办法保证的。</p>
<p>但是在实际的操作中，我们可能看不到<code>WORK-1</code>,<code>WORK-2</code>，<br>因为在协程执行完之前，整个程序的进程就结束了。</p>
<p>为了解决这个这个问题，我们需要<code>wait group</code>来同步结果。</p>
<h3 id="wait-group"><a href="#wait-group" class="headerlink" title="wait group"></a>wait group</h3><p>我们使用WG来保证所有协程都能够结束</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">2</span>)</span><br><span class="line">	<span class="keyword">go</span> doWork1(&amp;wg)</span><br><span class="line">	<span class="keyword">go</span> doWork2(&amp;wg)</span><br><span class="line">	wg.Wait()</span><br><span class="line">	fmt.Println(<span class="string">&quot;END&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork2</span><span class="params">(wg *sync.WaitGroup)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-2&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork1</span><span class="params">(wg *sync.WaitGroup)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-1&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用<code>WaitGroup</code>，可以保证，在<code>END</code>之前，保证<code>WORK-1</code>,<code>WORK-2</code>执行完毕。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/OxRa4Q.png"></p>
<h3 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h3><p>channel类似一个管道，可以又缓存，可以往里面输入东西，可以从里面取出东西。<br>在Java中，有个很类似的东西，BlockingQueue。<br>两者都具备阻塞队列的功能。</p>
<p>但是他们核心不同点是，Go里面的channel使用的<a href="http://www.usingcsp.com/cspbook.pdf">CSP</a>模型。<br>channel的使用也更简洁，还支持select语法，和定向channel。</p>
<p>使用方法如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">2</span>)</span><br><span class="line">	<span class="keyword">var</span> c = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">string</span>)</span><br><span class="line">	<span class="keyword">go</span> doWork1(&amp;wg, &amp;c)</span><br><span class="line">	<span class="keyword">go</span> doWork2(&amp;wg, &amp;c)</span><br><span class="line">	wg.Wait()</span><br><span class="line">	fmt.Println(<span class="string">&quot;END&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork2</span><span class="params">(wg *sync.WaitGroup, c *<span class="keyword">chan</span> <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	m := &lt;-*c</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-2&quot;</span>)</span><br><span class="line">	fmt.Println(m)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork1</span><span class="params">(wg *sync.WaitGroup, c *<span class="keyword">chan</span> <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-1&quot;</span>)</span><br><span class="line">	*c &lt;- <span class="string">&quot;test message&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WORK-1</span><br><span class="line">WORK-2</span><br><span class="line">test message</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p>我们可以使用channel来把信息跨协程传输，<br>我们还可以保证<code>WORK-1</code>在<code>WORK-2</code>之前被打印。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/0peR0n.png"></p>
<h3 id="context"><a href="#context" class="headerlink" title="context"></a>context</h3><p>上下文，我们可以通过它，来控制协程的活动，比如中断一个协程。<br>我们来看段代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// wait group</span></span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// channel</span></span><br><span class="line">	<span class="keyword">var</span> c = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">string</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// context</span></span><br><span class="line">	ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line"></span><br><span class="line">	<span class="keyword">go</span> doWork1(&amp;wg, &amp;c, ctx)</span><br><span class="line">	<span class="keyword">go</span> doWork2(&amp;wg, &amp;c, ctx)</span><br><span class="line"></span><br><span class="line">	time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">	<span class="comment">// 中断</span></span><br><span class="line">	cancel()</span><br><span class="line"></span><br><span class="line">	wg.Wait()</span><br><span class="line">	fmt.Println(<span class="string">&quot;END&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork2</span><span class="params">(wg *sync.WaitGroup, c *<span class="keyword">chan</span> <span class="type">string</span>, ctx context.Context)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	m := &lt;-*c</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-2&quot;</span>)</span><br><span class="line">	fmt.Println(m)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doWork1</span><span class="params">(wg *sync.WaitGroup, c *<span class="keyword">chan</span> <span class="type">string</span>, ctx context.Context)</span></span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> wg.Done()</span><br><span class="line">	fmt.Println(<span class="string">&quot;WORK-1&quot;</span>)</span><br><span class="line">	*c &lt;- <span class="string">&quot;test message&quot;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">100</span>; i++ &#123;</span><br><span class="line">		time.Sleep(time.Second)</span><br><span class="line">		fmt.Println(<span class="string">&quot;WORK-1&quot;</span>, i)</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">			fmt.Println(<span class="string">&quot;WORK-1 DONE&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在work1里面 我们有段逻辑，是打印 0～99，但是如果主线程通知我们中断，我们就会中断当前操作。</p>
<p>我们就会打印出这样的结果。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WORK-1</span><br><span class="line">WORK-2</span><br><span class="line">test message</span><br><span class="line">WORK-1 0</span><br><span class="line">WORK-1 1</span><br><span class="line">WORK-1 2</span><br><span class="line">WORK-1 3</span><br><span class="line">WORK-1 4</span><br><span class="line">WORK-1 DONE</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p>我们的示意图，就会变成这样：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/rWNJKX.png"></p>
<p>我们除了<code>func WithCancel(parent Context) (ctx Context, cancel CancelFunc)</code>之外，<br>还有</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithDeadline</span><span class="params">(parent Context, deadline time.Time)</span></span> (Context, CancelFunc)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span></span> (Context, CancelFunc)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key <span class="keyword">interface</span>&#123;&#125;, val <span class="keyword">interface</span>&#123;&#125;)</span></span> (Context)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>大家如果感兴趣，可以自己尝试一下。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这次，我们快速入门了Go，这是一种非常新的语言。<br>我相信它会在不久的未来会大展宏图。在市场上有自己的一席之地。</p>
<p>希望这片文章对大家有所帮助～</p>
<p>Bye！</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://go.dev/">https://go.dev/</a></li>
<li><a href="https://github.com/CPyeah/hello-go/tree/master/grammar">https://github.com/CPyeah/hello-go/tree/master/grammar</a></li>
</ul>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>basic-grammar</tag>
      </tags>
  </entry>
  <entry>
    <title>ESL - Clean the house and relax</title>
    <url>/2021/07/18/english/clean-room/</url>
    <content><![CDATA[<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>使用下面的关键词，写一篇小短文。</p>
<blockquote>
<ul>
<li>energetic</li>
<li>dust&#x2F;dusting</li>
<li>lamp</li>
<li>furniture</li>
<li>wipe</li>
<li>rug&#x2F;carpet</li>
<li>filthy</li>
<li>vacuum</li>
<li>sucking</li>
<li>mop&#x2F;mopping</li>
<li>broom</li>
<li>scrub&#x2F;scrubbing</li>
<li>tub</li>
<li>closet</li>
<li>newscast</li>
<li>cable television</li>
<li>flip through&#x2F;thumb through</li>
<li>commercial</li>
<li>reality show</li>
<li>contest</li>
<li>There is nothing like …</li>
</ul>
</blockquote>
<span id="more"></span>

<p>Today is Sunday, so I am very energetic.<br>So I decide to clean up my house.<br>First, I dust the tables, lamps and anther furniture.<br>Then I wipe the kitchen table.<br>I saw the carpet is filthy.<br>I take out the vacuum to vacuum it.<br>It’s very convenient.<br>I clean floor in room by vacuum better than broom.<br>Next is the bathroom.<br>I mop the bathroom floor, and I scrub the sink.<br>So far, I finished all of this cleaning.<br>I’m very satisfy for it.</p>
<p>After lunch.<br>I go to watch my favorite reality show that the rap of china.<br>It’s a contest in 50 rappers.<br>I like rap song in it.</p>
<p>There is nothing like watch TV show after hardworking.</p>
]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>english</tag>
        <tag>ESL</tag>
        <tag>write</tag>
        <tag>clean_room</tag>
      </tags>
  </entry>
  <entry>
    <title>Java操作ElasticSearch</title>
    <url>/2021/06/11/java/Java%E6%93%8D%E4%BD%9CElasticSearch/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>今天我们将使用Java来操作ElasticSearch。<br>我们将：</p>
<ul>
<li>使用Docker搭建ES集群环境</li>
<li>使用SpringBoot搭建Java环境</li>
<li>在Java模型中定义ES的索引</li>
<li>使用两种方式来操作ES（JPA和ElasticSearchTemplate）</li>
</ul>
<span id="more"></span>

<h2 id="搭建集群环境"><a href="#搭建集群环境" class="headerlink" title="搭建集群环境"></a>搭建集群环境</h2><p>今天我们继续使用docker来搭建环境。<br><code>docker-compose.yaml</code>奉上。<br>想必大家都很清楚docker compose的用法了，这里就不再赘述。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2.2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">es01:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">es01</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node.name=es01</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.name=es-docker-cluster</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">discovery.seed_hosts=es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.initial_master_nodes=es01,es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;ES_JAVA_OPTS=-Xms128m -Xmx128m&quot;</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/chengpeng/docker_volume/elasticsearch/data01:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">9200</span><span class="string">:9200</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">es02:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">es02</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node.name=es02</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.name=es-docker-cluster</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">discovery.seed_hosts=es01,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.initial_master_nodes=es01,es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;ES_JAVA_OPTS=-Xms128m -Xmx128m&quot;</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/chengpeng/docker_volume/elasticsearch/data02:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line">  <span class="attr">es03:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">docker.elastic.co/elasticsearch/elasticsearch:7.13.2</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">es03</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">node.name=es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.name=es-docker-cluster</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">discovery.seed_hosts=es01,es02</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">cluster.initial_master_nodes=es01,es02,es03</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">bootstrap.memory_lock=true</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;ES_JAVA_OPTS=-Xms128m -Xmx128m&quot;</span></span><br><span class="line">    <span class="attr">ulimits:</span></span><br><span class="line">      <span class="attr">memlock:</span></span><br><span class="line">        <span class="attr">soft:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">hard:</span> <span class="number">-1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/chengpeng/docker_volume/elasticsearch/data03:/usr/share/elasticsearch/data</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">elastic</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">data01:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">data02:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="attr">data03:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">elastic:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure>

<p>因为这里是集群，除了<code>volumes</code>需要注意之外，还需要注意<code>network</code>需要配置一下。<br>启动完成之后，浏览器访问:<br><a href="http://localhost:9200/">http://localhost:9200</a><br>如果展示：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/image.png"><br>表示ES集群启动成功。</p>
<h2 id="搭建Java环境"><a href="#搭建Java环境" class="headerlink" title="搭建Java环境"></a>搭建Java环境</h2><p>我们创建一个SpringBoot项目。<br>在<code>pom.xml</code>中引入elasticsearch的starter，即可。<br>不过要注意的是，因为ElasticSearch版本迭代很快，我们的版本要对应的上。<br>我们先查看一下ElasticSearch的版本： 7.13.2<br>再看一下<a href="https://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/">Spring文档</a>，找到对应的SpringData的版本。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/J73lBg.png"><br>在pom中我们添加上引用：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-elasticsearch<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>刷新下maven。 再继续在<code>application.properties</code>中配置:</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring.data.elasticsearch.cluster-name</span>=<span class="string">es-docker-cluster</span></span><br><span class="line"><span class="attr">spring.data.elasticsearch.cluster-nodes</span>=<span class="string">localhost:9200</span></span><br></pre></td></tr></table></figure>

<p>即完成环境搭建。</p>
<h2 id="在Java模型中定义ES的索引"><a href="#在Java模型中定义ES的索引" class="headerlink" title="在Java模型中定义ES的索引"></a>在Java模型中定义ES的索引</h2><p>好，接下来来到我们的重头戏，设计ES的索引。<br>在ES中，索引对应类似MySQL中的表，而Mapping，相当于MySQL中的表结构。<br>在一切开始之前，设计一个足够好的表结构尤为重要。可以直接影响到数据库的性能。</p>
<p>直接上结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Document(indexName = &quot;product&quot;)</span></span><br><span class="line"><span class="meta">@Setting(shards = 3, replicas = 2)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Product</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Id</span></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Text, index = false)</span></span><br><span class="line">	<span class="keyword">private</span> String id;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Keyword, ignoreAbove = 128)</span></span><br><span class="line">	<span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Text, analyzer = &quot;ik_smart&quot;, searchAnalyzer = &quot;ik_smart&quot;)</span></span><br><span class="line">	<span class="keyword">private</span> String description;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Keyword)</span></span><br><span class="line">	<span class="keyword">private</span> String brandName;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Long)</span></span><br><span class="line">	<span class="keyword">private</span> Long stock;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Double)</span></span><br><span class="line">	<span class="keyword">private</span> BigDecimal price;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Date, format = &#123;&#125;, pattern = &#123;&quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd&quot;,</span></span><br><span class="line"><span class="meta">			&quot;epoch_millis&quot;&#125;)</span></span><br><span class="line">	<span class="keyword">private</span> LocalDateTime updateTime;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Field(type = FieldType.Nested)</span></span><br><span class="line">	<span class="keyword">private</span> List&lt;Sku&gt; skuList;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>我们首先定义了一个商品的Java模型<code>Product</code>，有各种Java类型（String、Long、BigDecimal、LocalDateTime、List）。<br>在类的上面添加<code>Document</code>注解，表示被Spring所管理。<br><code>org.springframework.data.elasticsearch.annotations.Document</code>中还有一些其他的属性。大家可以参考官方文档。</p>
<h3 id="定义Setting"><a href="#定义Setting" class="headerlink" title="定义Setting"></a>定义Setting</h3><p>定义好模型之后，我们再确定好索引的配置，<code>Setting</code>。<br>这里面主要配置，这个索引在ES中的分片数，和副本数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Setting(shards = 3, replicas = 2)</span></span><br></pre></td></tr></table></figure>

<p>当然，除了分片数和副本数，还有其他的配置，大家参考官方文档。</p>
<h3 id="定义Mapping"><a href="#定义Mapping" class="headerlink" title="定义Mapping"></a>定义Mapping</h3><p>接下来，就到了定义最重要的Mapping。</p>
<h4 id="确定数据结构"><a href="#确定数据结构" class="headerlink" title="确定数据结构"></a>确定数据结构</h4><p>首先我们要知道，ES有着自己的数据结构，而且种类还很多。如图：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/JtmYzS.png"><br>我们需要在每一个Java的数据结构中，对应上ES的数据结构。<br>比如<code>@Field(type = FieldType.Text)</code>表示它在ES中，是一个文本型的数据。<br>而文本型，是要被分词，生成倒排索引的。<br>这里提几点选择策略：</p>
<ul>
<li>文本类型分两种，需要分词，选text，不需要分词，选keyword</li>
<li>如果你未来不确定你到底有多少数据，将类型设置为long是比较合适的</li>
<li>keyword检索比较短的字符会更快，如果字符很大，那么会增加存储和检索成本，可以使用<code>ignoreAbove</code>属性</li>
</ul>
<h4 id="确定是否需要被索引"><a href="#确定是否需要被索引" class="headerlink" title="确定是否需要被索引"></a>确定是否需要被索引</h4><p>默认情况下，索引的字段都是需要被索引的，但是为了节省空间，我们可以把一些字段设置成不建索引。<br>比如ID一类的参数，不想被索引：<code>@Field(type = FieldType.Text, index = false)</code></p>
<h4 id="检索的方式"><a href="#检索的方式" class="headerlink" title="检索的方式"></a>检索的方式</h4><p>我们可以通过分词器，来定义我们的分词方式，比如<br><code>@Field(type = FieldType.Text, analyzer = &quot;ik_smart&quot;, searchAnalyzer = &quot;ik_smart&quot;)</code><br>这样，我们就可以使用中文的倒排索引啦。。。</p>
<h4 id="特殊的类型"><a href="#特殊的类型" class="headerlink" title="特殊的类型"></a>特殊的类型</h4><p>如果我们需要使用时间类型，在Java中，我们使用<code>LocalDateTime</code>,对应ES中是<code>Date</code>类型。<br>但是需要注意的是，我们需要定义格式化的方式，不然大概率时分秒要丢失。<br><code>@Field(type = FieldType.Date, format = &#123;&#125;, pattern = &#123;&quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd&quot;, &quot;epoch_millis&quot;&#125;)</code></p>
<p>嵌套类型，使用<code>Nested</code><br><code>@Field(type = FieldType.Nested)</code></p>
<h2 id="使用两种方式来操作ES"><a href="#使用两种方式来操作ES" class="headerlink" title="使用两种方式来操作ES"></a>使用两种方式来操作ES</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/MHdECp.png"></p>
<h3 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h3><p>首先我们来看看如何来管理ES的索引</p>
<h4 id="JPA"><a href="#JPA" class="headerlink" title="JPA"></a>JPA</h4><p>如果使用JPA，我们只需保持默认配置，JPA就会替我们按照我们定义的Map来创建索引。<br>不需要我们操心。</p>
<p>我们可以使用<a href="http://localhost:9200/product/_mapping">http://localhost:9200/product/_mapping</a>来查看对应索引信息。</p>
<h4 id="ElasticsearchRestTemplate"><a href="#ElasticsearchRestTemplate" class="headerlink" title="ElasticsearchRestTemplate"></a>ElasticsearchRestTemplate</h4><p>template对应的Api如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">index</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 拿到对应索引的操作引用</span></span><br><span class="line">    <span class="type">IndexOperations</span> <span class="variable">indexOperations</span> <span class="operator">=</span> elasticsearchRestTemplate.indexOps(Product.class);</span><br><span class="line">    <span class="comment">// 查看索引是否存在</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">exists</span> <span class="operator">=</span> indexOperations.exists();</span><br><span class="line">    <span class="keyword">if</span> (exists) &#123;</span><br><span class="line">        <span class="comment">// 删除索引（删除操作要慎重）</span></span><br><span class="line">        indexOperations.delete();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 创建索引</span></span><br><span class="line"><span class="comment">//		indexOperations.create(); //这个没有配置mapping</span></span><br><span class="line">    indexOperations.createWithMapping();</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 查看索引的Setting</span></span><br><span class="line">    <span class="type">Settings</span> <span class="variable">settings</span> <span class="operator">=</span> indexOperations.getSettings();</span><br><span class="line">    <span class="comment">// 查看索引的Mapping</span></span><br><span class="line">    Map&lt;String, Object&gt; mapping = indexOperations.getMapping();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="增删改查操作"><a href="#增删改查操作" class="headerlink" title="增删改查操作"></a>增删改查操作</h3><h4 id="JPA-1"><a href="#JPA-1" class="headerlink" title="JPA"></a>JPA</h4><p>使用JPA非常方便，只需要定义好<code>Repository</code>，就可以方便快捷的操作Document了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ProductRepository</span> <span class="keyword">extends</span> <span class="title class_">ElasticsearchRepository</span>&lt;Product, String&gt; &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后我们就可以这样使用：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CURDTest</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Autowired</span></span><br><span class="line">	<span class="keyword">private</span> ProductRepository repository;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">create</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product</span> <span class="operator">=</span> repository.save(Product.get());</span><br><span class="line">		Assertions.assertNotNull(product);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createMore</span><span class="params">()</span> &#123;</span><br><span class="line">		List&lt;Product&gt; products = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">		<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">			products.add(Product.get());</span><br><span class="line">		&#125;</span><br><span class="line">		repository.saveAll(products);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">listAll</span><span class="params">()</span> &#123;</span><br><span class="line">		Iterable&lt;Product&gt; all = repository.findAll();</span><br><span class="line">		all.forEach(System.out::println);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">page</span><span class="params">()</span> &#123;</span><br><span class="line">		Page&lt;Product&gt; page = repository.findAll(Pageable.ofSize(<span class="number">4</span>).withPage(<span class="number">0</span>));</span><br><span class="line">		System.out.println(page);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getById</span><span class="params">()</span> &#123;</span><br><span class="line">		Page&lt;Product&gt; page = repository.findAll(Pageable.ofSize(<span class="number">1</span>).withPage(<span class="number">0</span>));</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product</span> <span class="operator">=</span> page.getContent().get(<span class="number">0</span>);</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product1</span> <span class="operator">=</span> repository.findById(product.getId()).orElse(<span class="literal">null</span>);</span><br><span class="line">		Assertions.assertNotNull(product1);</span><br><span class="line">		System.out.println(product1);</span><br><span class="line">		Assertions.assertEquals(product.getId(), product1.getId());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">()</span> &#123;</span><br><span class="line">		Page&lt;Product&gt; page = repository.findAll(Pageable.ofSize(<span class="number">1</span>).withPage(<span class="number">0</span>));</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product</span> <span class="operator">=</span> page.getContent().get(<span class="number">0</span>);</span><br><span class="line">		<span class="type">Product</span> <span class="variable">newProduct</span> <span class="operator">=</span> Product.get();</span><br><span class="line">		newProduct.setId(product.getId());</span><br><span class="line">		<span class="type">Product</span> <span class="variable">save</span> <span class="operator">=</span> repository.save(newProduct);</span><br><span class="line">		Assertions.assertEquals(product.getId(), save.getId());</span><br><span class="line">		Assertions.assertNotEquals(product.getName(), save.getName());</span><br><span class="line">		System.out.println(product);</span><br><span class="line">		System.out.println(save);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">delete</span><span class="params">()</span> &#123;</span><br><span class="line">		Page&lt;Product&gt; page = repository.findAll(Pageable.ofSize(<span class="number">1</span>).withPage(<span class="number">0</span>));</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product</span> <span class="operator">=</span> page.getContent().get(<span class="number">0</span>);</span><br><span class="line">		repository.delete(product);</span><br><span class="line"></span><br><span class="line">		<span class="type">Product</span> <span class="variable">product1</span> <span class="operator">=</span> repository.findById(product.getId()).orElse(<span class="literal">null</span>);</span><br><span class="line">		Assertions.assertNull(product1);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>JPA的封装可以让我们无差别的操作任何数据库。 yyds</p>
<h4 id="ElasticsearchRestTemplate-1"><a href="#ElasticsearchRestTemplate-1" class="headerlink" title="ElasticsearchRestTemplate"></a>ElasticsearchRestTemplate</h4><p>使用ElasticsearchRestTemplate操作文档相对麻烦一些：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CURDTest2</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Autowired</span></span><br><span class="line">	<span class="keyword">private</span> ElasticsearchRestTemplate elasticsearchRestTemplate;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">create</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product</span> <span class="operator">=</span> elasticsearchRestTemplate.save(Product.get());</span><br><span class="line">		Assertions.assertNotNull(product);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createMore</span><span class="params">()</span> &#123;</span><br><span class="line">		List&lt;Product&gt; products = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">		<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">			products.add(Product.get());</span><br><span class="line">		&#125;</span><br><span class="line">		elasticsearchRestTemplate.save(products);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">listAll</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">Query</span> <span class="variable">query</span> <span class="operator">=</span> elasticsearchRestTemplate.matchAllQuery();</span><br><span class="line">		SearchHits&lt;Product&gt; search = elasticsearchRestTemplate.search(query, Product.class);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getById</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">Product</span> <span class="variable">product</span> <span class="operator">=</span> elasticsearchRestTemplate.get(<span class="string">&quot;ID&quot;</span>, Product.class);</span><br><span class="line">		Assertions.assertNotNull(product);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">Product</span> <span class="variable">oldProduct</span> <span class="operator">=</span> elasticsearchRestTemplate.get(<span class="string">&quot;ID&quot;</span>, Product.class);</span><br><span class="line">		Assertions.assertNotNull(oldProduct);</span><br><span class="line"></span><br><span class="line">		<span class="type">Product</span> <span class="variable">newProduct</span> <span class="operator">=</span> Product.get();</span><br><span class="line">		<span class="type">Document</span> <span class="variable">document</span> <span class="operator">=</span> newProduct.toDocument();</span><br><span class="line">		<span class="type">UpdateQuery</span> <span class="variable">updateQuery</span> <span class="operator">=</span> UpdateQuery.builder(<span class="string">&quot;ID&quot;</span>).withDocument(document).build();</span><br><span class="line">		<span class="type">UpdateResponse</span> <span class="variable">product</span> <span class="operator">=</span> elasticsearchRestTemplate</span><br><span class="line">				.update(updateQuery, IndexCoordinates.of(<span class="string">&quot;product&quot;</span>));</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">delete</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> elasticsearchRestTemplate.delete(<span class="string">&quot;ID&quot;</span>, Product.class);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><h4 id="JPA-2"><a href="#JPA-2" class="headerlink" title="JPA"></a>JPA</h4><p>JPA的搜索很简单，就把当成一个普通的数据库搜索就行。<br>我们只需要在repository中定义</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Repository</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ProductRepository</span> <span class="keyword">extends</span> <span class="title class_">ElasticsearchRepository</span>&lt;Product, String&gt; &#123;</span><br><span class="line"></span><br><span class="line">	List&lt;Product&gt; <span class="title function_">findAllByNameContaining</span><span class="params">(String name)</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我没就可以在所有名称中包含莫个字段了。<br>在调用这个方法的时候，可以在控制台看到，本质上是JPA帮我我们发了一个<code>_search</code>的POST请求。<br>其他更复杂的方法，可以参考JPA的文档。</p>
<h4 id="ElasticsearchRestTemplate-2"><a href="#ElasticsearchRestTemplate-2" class="headerlink" title="ElasticsearchRestTemplate"></a>ElasticsearchRestTemplate</h4><p>使用ElasticsearchRestTemplate操作search，也很不错。<br>我们可以这样写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">searchTest</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 查询所有</span></span><br><span class="line">    <span class="type">Query</span> <span class="variable">searchQuery</span> <span class="operator">=</span> Query.findAll();</span><br><span class="line">    <span class="type">IndexCoordinates</span> <span class="variable">indexCoordinates</span> <span class="operator">=</span> IndexCoordinates.of(<span class="string">&quot;product&quot;</span>);</span><br><span class="line">    SearchHits&lt;Product&gt; result = elasticsearchRestTemplate</span><br><span class="line">            .search(searchQuery, Product.class, indexCoordinates);</span><br><span class="line">    System.out.println(result);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 按名称 搜索</span></span><br><span class="line">    <span class="type">MatchQueryBuilder</span> <span class="variable">matchQueryBuilder</span> <span class="operator">=</span> QueryBuilders.matchQuery(<span class="string">&quot;spuName&quot;</span>, <span class="string">&quot;473&quot;</span>);</span><br><span class="line">    searchQuery = <span class="keyword">new</span> <span class="title class_">NativeSearchQueryBuilder</span>()</span><br><span class="line">            .withQuery(matchQueryBuilder)</span><br><span class="line">            .build();</span><br><span class="line">    result = elasticsearchRestTemplate</span><br><span class="line">            .search(searchQuery, Product.class, indexCoordinates);</span><br><span class="line">    System.out.println(result);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 按价格搜索</span></span><br><span class="line">    <span class="type">Criteria</span> <span class="variable">criteria</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Criteria</span>(<span class="string">&quot;price&quot;</span>)</span><br><span class="line">            .greaterThan(<span class="number">500.0</span>)</span><br><span class="line">            .lessThan(<span class="number">800.0</span>);</span><br><span class="line"></span><br><span class="line">    searchQuery = <span class="keyword">new</span> <span class="title class_">CriteriaQuery</span>(criteria);</span><br><span class="line"></span><br><span class="line">    result = elasticsearchRestTemplate</span><br><span class="line">            .search(searchQuery, Product.class, indexCoordinates);</span><br><span class="line">    System.out.println(result);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样写有一个好处，就是在返回结果数据的同时，还会返回命中率，这个有时候也是会用到的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，我们已经学会了如何把ES操作引入到我们到Java项目中，<br>还知道了如何设计并建立一个索引，<br>还有使用两种方法来操作ES。<br>希望大家都能够在工作当中用上哦！！</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>java</tag>
        <tag>springboot</tag>
        <tag>jpa</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>SystemDesign:开放平台</title>
    <url>/2021/10/18/system_design/open_platform/</url>
    <content><![CDATA[<blockquote>
<ul>
<li>客户端注册管理</li>
<li>客户端权限验证</li>
<li>客户端调用内部接口</li>
<li>消息接收</li>
</ul>
</blockquote>
<span id="more"></span>

<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>MVP</p>
<ul>
<li>用户注册app使用权限</li>
<li>后台管理系统</li>
<li>用户调用接口</li>
<li>消息回调</li>
<li>用户Oauth2权限验证</li>
<li>接口文档展示</li>
</ul>
<p>目标：</p>
<ul>
<li>系统高可用</li>
<li>消息不丢失</li>
<li>数据持久化</li>
</ul>
<p>加分项：</p>
<ul>
<li>Error Trace</li>
<li>统计分析</li>
<li>mock invoke in document</li>
<li>沙箱</li>
</ul>
<h2 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h2><ul>
<li>用户：10万 不需要partition</li>
<li>RPS：5k &#x2F;user&#x2F;day &#x3D; 5K</li>
<li>Message 1K&#x2F;user&#x2F;day &#x3D; 1K</li>
</ul>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><ul>
<li>apply appKey&#x2F;appSecret<br>console server</li>
<li>getToken<ul>
<li>OAuth2 server</li>
</ul>
</li>
<li>invoke interface<ul>
<li>api server</li>
</ul>
</li>
<li>message server</li>
<li>doc server</li>
</ul>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/openplatformsystem.png"></p>
<h3 id="后台管理服务（console-server）"><a href="#后台管理服务（console-server）" class="headerlink" title="后台管理服务（console server）"></a>后台管理服务（console server）</h3><p>内部管理员操作</p>
<ul>
<li>用户管理</li>
<li>appId、appSecret管理</li>
<li>token管理</li>
<li>内部系统用户与client绑定管理<h3 id="权限认证服务（OAuth2-server）"><a href="#权限认证服务（OAuth2-server）" class="headerlink" title="权限认证服务（OAuth2 server）"></a>权限认证服务（OAuth2 server）</h3></li>
<li>客户端获取token</li>
<li>token校验<h3 id="接口服务（API-server）"><a href="#接口服务（API-server）" class="headerlink" title="接口服务（API server）"></a>接口服务（API server）</h3></li>
<li>类似一个网关</li>
<li>客户端参照文档，调用接口（同步）</li>
<li>校验token，验证签名</li>
<li>调用内部系统的接口</li>
<li>消息订阅</li>
<li>请求返回信息给分析服务（异步）<h3 id="分析服务（analysis-server）"><a href="#分析服务（analysis-server）" class="headerlink" title="分析服务（analysis server）"></a>分析服务（analysis server）</h3></li>
<li>接受所有的请求、消息</li>
<li>记录分析、生成仪表板</li>
<li>大数据<h3 id="消息服务（message-server）"><a href="#消息服务（message-server）" class="headerlink" title="消息服务（message server）"></a>消息服务（message server）</h3></li>
<li>监听内部系统消息</li>
<li>消息记录（状态：Queue｜Sent｜Fail）</li>
<li>客户端消息订阅查看</li>
<li>异步发送已订阅的消息（Rabbit Queue）</li>
<li>消息给分析服务（异步）</li>
</ul>
<h2 id="数据库选择"><a href="#数据库选择" class="headerlink" title="数据库选择"></a>数据库选择</h2><h3 id="后台管理服务"><a href="#后台管理服务" class="headerlink" title="后台管理服务"></a>后台管理服务</h3><p>变化少 - 关系型数据库MySQL</p>
<h3 id="认证服务"><a href="#认证服务" class="headerlink" title="认证服务"></a>认证服务</h3><p>调用频繁，过期，读多写少 - redis</p>
<h3 id="消息服务"><a href="#消息服务" class="headerlink" title="消息服务"></a>消息服务</h3><p>消息metaData保存，消息状态，事务 - MySQL<br>异步发送消息，消息队列 - Rabbit&#x2F;Kafka</p>
<h3 id="统计分析服务"><a href="#统计分析服务" class="headerlink" title="统计分析服务"></a>统计分析服务</h3><p>数据量大，实时分析 - Mongo&#x2F;KafKa&#x2F;Flink</p>
<h2 id="API-设计"><a href="#API-设计" class="headerlink" title="API 设计"></a>API 设计</h2><h3 id="管理员"><a href="#管理员" class="headerlink" title="管理员"></a>管理员</h3><p>createUser(innerId)  appId,appSecret<br>dashboard()<br>CRUD(userInfo)<br>triggerGenerateDocWebSite()</p>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>token &#x3D; generateToken(appId, appKey)<br>token &#x3D; refreshToken(token, appId, appKey)<br>result &#x3D; invokeInterface(data, appId, token, sign)</p>
<p>listenMessage(netty&#x2F;socket)</p>
<h3 id="内部接口"><a href="#内部接口" class="headerlink" title="内部接口"></a>内部接口</h3><h4 id="API-server"><a href="#API-server" class="headerlink" title="API server"></a>API server</h4><p>innerId &#x3D; verityTokenAndSign(appId, token, sign)<br>invokeInnerInterface(data, innerId)<br>sendRequestToAnalysis(requestInfo, metaData)</p>
<h4 id="Message-server"><a href="#Message-server" class="headerlink" title="Message server"></a>Message server</h4><p>listenInnerSystemMessage</p>
<p>filterAndSaveAndQueueMessage(message)</p>
<p>sendMessageAndChangeState(message)</p>
<p>sendMessageToAnalysis(messageInfo, metaData)</p>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>Client:</p>
<ul>
<li>id</li>
<li>innerId</li>
<li>appKey</li>
<li>appSecret</li>
<li>token</li>
<li>token overtime</li>
<li>client info</li>
<li>subscribe topic list</li>
</ul>
<p>Message:</p>
<ul>
<li>id</li>
<li>type</li>
<li>status(Queue｜Sent｜Fail)</li>
<li>create_time</li>
<li>finish_time</li>
</ul>
<p>Analysis Model</p>
<ul>
<li>id</li>
<li>appId (partition key)</li>
<li>clientInfo</li>
<li>type (request&#x2F;message)</li>
<li>interfaceName</li>
<li>messageTopic</li>
<li>cost</li>
<li>requestResult(success&#x2F;fail)</li>
<li>requestBody(json)</li>
<li>createTime</li>
<li>invokeTime</li>
</ul>
]]></content>
      <categories>
        <category>system_design</category>
      </categories>
      <tags>
        <tag>system_design</tag>
        <tag>open_platform</tag>
      </tags>
  </entry>
  <entry>
    <title>Java操作Redis</title>
    <url>/2021/03/25/java/Java%E6%93%8D%E4%BD%9CRedis/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Redis是目前最流行的缓存数据库，完全基于内存操作，速度非常快。<br>它是我们互联网公司高性能，高并发的基石。<br>它的功能包括但不限于：提供中央缓存功能，分布式锁，还有特殊数据结构的特殊应用。<br>本篇文章都会一一说到。</p>
<p>接下来我们会：</p>
<ul>
<li>使用Docker搭建redis环境</li>
<li>搭建springboot服务</li>
<li>使用redisson来操作redis</li>
<li>熟悉redis的五大基本数据类型</li>
<li>熟悉使用redis的高级数据结构及其应用</li>
</ul>
<span id="more"></span>

<h2 id="使用Docker搭建redis环境"><a href="#使用Docker搭建redis环境" class="headerlink" title="使用Docker搭建redis环境"></a>使用Docker搭建redis环境</h2><p>使用Docker搭建环境非常方便。 在本地安装好Docker后，使用<code>docker compose</code>可以方便快捷但搭好环境。</p>
<p>只需要创建<code>docker-compose.yaml</code>文件，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.9&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">cache:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">redis:latest</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;6379:6379&#x27;</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">redis-server</span> <span class="string">--save</span> <span class="number">20</span> <span class="number">1</span> <span class="string">--loglevel</span> <span class="string">warning</span> <span class="string">--requirepass</span> <span class="string">eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">~/docker_volume/redis:/data</span></span><br></pre></td></tr></table></figure>

<p>注意： command里面的password和volumes映射，按照自己需要配置</p>
<p>再使用命令行，cd到yaml的目录下，运行<code>docker-compose up</code>命令。</p>
<p>非常简单。</p>
<p>等启动好了之后，可以用redis工具连接，看下效果。</p>
<h2 id="搭建springboot服务"><a href="#搭建springboot服务" class="headerlink" title="搭建springboot服务"></a>搭建springboot服务</h2><p>IDEA启动等一个Springboot的项目。我这里使用的是gradle。maven当让也可以。</p>
<p>我的引用如下：</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">dependencies</span> &#123;</span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter&#x27;</span></span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-web&#x27;</span></span><br><span class="line">    implementation <span class="string">&#x27;org.redisson:redisson-spring-boot-starter:3.15.6&#x27;</span></span><br><span class="line">    implementation <span class="keyword">group</span>: <span class="string">&#x27;de.ruedigermoeller&#x27;</span>, name: <span class="string">&#x27;fst&#x27;</span>, version: <span class="string">&#x27;2.57&#x27;</span></span><br><span class="line">    compileOnly <span class="string">&#x27;org.projectlombok:lombok&#x27;</span></span><br><span class="line">    annotationProcessor <span class="string">&#x27;org.projectlombok:lombok&#x27;</span></span><br><span class="line">    testImplementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-test&#x27;</span></span><br><span class="line">    testImplementation <span class="string">&#x27;io.projectreactor:reactor-test&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我这里使用的官方推荐的redis客户端<code>Redisson</code>,相关的依赖是<code>org.redisson:redisson-spring-boot-starter:3.15.6</code>和<code>de.ruedigermoeller&#39;, name: &#39;fst&#39;, version: &#39;2.57</code>。这样我们就可以在我们的代码中使用<code>RedissonClient</code>了。</p>
<blockquote>
<p>干净又卫生</p>
</blockquote>
<h2 id="使用redisson来操作redis"><a href="#使用redisson来操作redis" class="headerlink" title="使用redisson来操作redis"></a>使用redisson来操作redis</h2><h3 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h3><p>因为redis是键值对，大家可以把redis当成一个大的<code>HashMap</code>，所以知道它的所有的key很有必要。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">keysTest</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="type">RKeys</span> <span class="variable">keys</span> <span class="operator">=</span> redissonClient.getKeys();</span><br><span class="line">	System.out.println(keys.count());<span class="comment">// org.redisson.client.protocol.RedisCommands.DBSIZE 命令</span></span><br><span class="line">	Iterable&lt;String&gt; keysByPattern = keys</span><br><span class="line">			.getKeysByPattern(<span class="string">&quot;*&quot;</span>); <span class="comment">// org.redisson.client.protocol.RedisCommands.SCAN</span></span><br><span class="line">	keys.getKeysStream()</span><br><span class="line">			.forEach(System.out::println);<span class="comment">// org.redisson.client.protocol.RedisCommands.SCAN</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Redisson中使用<code>RKeys</code>类来对redis中的keys做封装。</p>
<p>我们可以</p>
<ul>
<li>拿到所有key的数量</li>
<li>把所有的key列出来</li>
<li>按照正则匹配key</li>
</ul>
<p>注意，在redisson中，使用的不是redis提供的<code>keys</code>命令，而是<code>scan</code>命令。原因是因为，redis是单线程服务，如果key的量特别大，一次keys操作会消耗很长时间，整体拖慢服务性能。</p>
<h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p><code>String</code>是redis的最基础的数据结构。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//String</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testString</span><span class="params">()</span> &#123;</span><br><span class="line">	RBucket&lt;String&gt; hello = redissonClient.getBucket(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">	System.out.println(hello.get());<span class="comment">// org.redisson.client.protocol.RedisCommands.GET</span></span><br><span class="line">	hello.set(<span class="string">&quot;world ! &quot;</span>, <span class="number">5</span>,</span><br><span class="line">			TimeUnit.MINUTES);<span class="comment">// org.redisson.client.protocol.RedisCommands.PSETEX</span></span><br><span class="line">	System.out.println(hello.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>redis中所有的key都是String类型，而一些对象的存储，都是把对象序列化成为字符串进行存储。</p>
<p>string作为redis中的最基础的数据类型，redis做了极致的优化，这个我们后面再说。</p>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list是redis中列表的数据结构。说实话，在工作中使用的比较少。可以用来做一个简单的消息队列。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// List</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testList</span><span class="params">()</span> &#123;</span><br><span class="line">	RedissonList&lt;Person&gt; list = (RedissonList) redissonClient.getList(<span class="string">&quot;list&quot;</span>);</span><br><span class="line">	<span class="type">Person</span> <span class="variable">tom</span> <span class="operator">=</span> Person.tom();</span><br><span class="line">	list.add(tom);<span class="comment">// RPUSH</span></span><br><span class="line">	list.addBefore(tom, <span class="keyword">new</span> <span class="title class_">Person</span>());</span><br><span class="line">	list.readAll(); <span class="comment">// LRANGE</span></span><br><span class="line">	list.fastSet(<span class="number">1</span>, <span class="keyword">new</span> <span class="title class_">Person</span>());</span><br><span class="line">	System.out.println(list.size());</span><br><span class="line">	list.forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以把redis中的list，在Java中，当成LinkedList操作（插入、删除快；查找慢）。 使用简单方便。</p>
<p>list的底层是一个叫快速列表的数据结构（quick list）。</p>
<p>如果所示，它是由ziplist组成，ziplist是压缩列表，是紧凑的，再用link给串起来。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/image.png"></p>
<h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p>hash，map，dict，说的都是一个东西，在Java中，我们叫做<code>HashMap</code>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Map</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMap</span><span class="params">()</span> &#123;</span><br><span class="line">	RedissonMap&lt;String, Object&gt; myMap = (RedissonMap) redissonClient.getMap(<span class="string">&quot;myMap&quot;</span>);</span><br><span class="line">	myMap.put(<span class="string">&quot;Tom&quot;</span>, Person.tom());</span><br><span class="line">	RedissonMap&lt;String, Object&gt; map = (RedissonMap) redissonClient.getMap(<span class="string">&quot;myMap&quot;</span>);</span><br><span class="line">	System.out.println(map.get(<span class="string">&quot;Tom&quot;</span>)); <span class="comment">// HGET</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用和Java无二。 当我们使用Map缓存数据时候，我们可以部分的获取一些字段，不用把整个对象都拿出来。</p>
<p>注意：一整个Map能设置过期删除。Map中单独的key-value是设置不了过期删除的。</p>
<p>和Java中<code>HashMap</code>不同的是，扩容rehash的过程中，redis当中是渐进式的，可能同时出现两个map。</p>
<h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>redis中的set和Java中的HashSet类型。使用方法也类似。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Set</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSet</span><span class="params">()</span> &#123;</span><br><span class="line">	RSet&lt;Object&gt; set = redissonClient.getSet(<span class="string">&quot;set&quot;</span>);</span><br><span class="line">	set.add(<span class="number">1</span>);</span><br><span class="line">	set.add(<span class="number">2</span>);</span><br><span class="line">	set = redissonClient.getSet(<span class="string">&quot;set&quot;</span>);</span><br><span class="line">	<span class="keyword">for</span> (Object o : set) &#123;</span><br><span class="line">		System.out.println(o);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>工作中使用的也不错，可以计算一些UV。</p>
<h3 id="zset"><a href="#zset" class="headerlink" title="zset"></a>zset</h3><p>sort set，排序集合，redis特色结构。</p>
<p>在set的基础上，给每个value加上了分数，在zset中的值都是按照分数排好序的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ZSet</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testZSet</span><span class="params">()</span> &#123;</span><br><span class="line">	RSortedSet&lt;Object&gt; zset = redissonClient.getSortedSet(<span class="string">&quot;zset&quot;</span>);</span><br><span class="line">	zset.add(<span class="number">1</span>);</span><br><span class="line">	zset.add(<span class="number">2</span>);</span><br><span class="line">	zset.forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">	RScoredSortedSet&lt;Object&gt; szset = redissonClient.getScoredSortedSet(<span class="string">&quot;szset&quot;</span>);</span><br><span class="line">	szset.add(<span class="number">11.1</span>, <span class="number">1</span>);<span class="comment">// ZADD</span></span><br><span class="line">	szset.add(<span class="number">1.1</span>, <span class="number">2</span>);</span><br><span class="line">	szset.forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>zset底层使用的跳跃表（skip list），具体后面再说。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/1653463112036-image.png"></p>
<p>主要的作用是可以做一些排行榜，像微博热搜。</p>
<hr>
<p>这篇文章我们讲到了如果搭建一个redis环境，并使用<code>redisson</code>对redis做一些基本操作。</p>
<p>在下一篇文章中，我们将讲到redis中的一些高级数据结构。</p>
<ul>
<li>位图</li>
<li>布隆过滤器</li>
<li>队列</li>
<li>分布式锁</li>
<li>限流器</li>
<li>HyperLogLog</li>
<li>Geo</li>
</ul>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>redis</tag>
        <tag>redisson</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解Java虚拟机</title>
    <url>/2022/03/05/java/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这边文章我们深入了解一下Java虚拟机。<br>我会了解到：</p>
<ul>
<li>虚拟机的种类大概有哪些？</li>
<li>JVM的内存管理模型是什么样子的？</li>
<li>Java对象的创建过程是什么样子的？</li>
<li>Java对象的内存布局是什么样子的？</li>
<li>如何判断对象是垃圾？</li>
<li>Java中引用的类型有哪些？</li>
<li>垃圾收集算法有哪些？</li>
<li>HopSpot的垃圾收器是怎么实现的？</li>
<li>经典的垃圾收集器有哪些？</li>
<li>低延迟的垃圾收集器有哪些？</li>
<li>如何选择垃圾收集器？</li>
<li>JVM提供了哪些监控工具？</li>
<li>市面上有哪些可视化的工具？</li>
<li>JVM是怎么调优的？</li>
<li>Class文件结构是什么样子的？</li>
<li>常见的字节码指令有哪些？</li>
<li>Java编译的流程是什么样子的？</li>
<li>后端编译的过程是什么样子的？</li>
<li>Java内存模型是什么样子的？</li>
<li>volatile关键字有什么用？</li>
<li>Java的多线程是怎么实现的？</li>
<li>Java中有哪些锁优化？</li>
</ul>
<p>希望对你有所帮助～</p>
<span id="more"></span>

<h2 id="虚拟机的种类大概有哪些？"><a href="#虚拟机的种类大概有哪些？" class="headerlink" title="虚拟机的种类大概有哪些？"></a>虚拟机的种类大概有哪些？</h2><h3 id="HotSpot"><a href="#HotSpot" class="headerlink" title="HotSpot"></a>HotSpot</h3><p>首当其冲的就是使用最广泛的 <code>HotSpot</code> 虚拟机，它最重要的功能就是和它的名字一样，有<code>热点探测</code>的功能。<br>它的原理是通过方法计数器，找到多次调用的方法，和多次循环的方法，然后以方法为单位，进行二次编译成机器码，物理硬件可以直接执行。<br>还有就是它的准确式的内存管理。以前的虚拟机，都是通过句柄来操作对象的，而HotSpot可以直接识别栈上的地址是不是一个对象的引用。</p>
<h3 id="Sun-Classic"><a href="#Sun-Classic" class="headerlink" title="Sun Classic"></a>Sun Classic</h3><p>还有<code>Sun Classic</code>是Java的第一款虚拟机，能编译一起，到处运行。这是Java一开始的口号。 但是有很多缺点。<br>性能慢，不支持即时编译，需要进行外挂。</p>
<h3 id="Mobile-x2F-Embedded-VM"><a href="#Mobile-x2F-Embedded-VM" class="headerlink" title="Mobile&#x2F;Embedded VM"></a>Mobile&#x2F;Embedded VM</h3><p>还有一种就是运行在一些嵌入式设备，老年机上的Java虚拟机。它的特点就是需要的硬件资源少。</p>
<p>还有一些其他公司的虚拟机，各有各的特点。。。</p>
<h2 id="实战1：自己编译JDK"><a href="#实战1：自己编译JDK" class="headerlink" title="实战1：自己编译JDK"></a>实战1：自己编译JDK</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">/Users/chengpeng/Library/Java/JavaVirtualMachines/liberica-1.8.0_322/bin/java -version</span><br><span class="line"></span><br><span class="line">brew install autoconf</span><br><span class="line">brew install freetype ccache</span><br><span class="line"></span><br><span class="line">bash configure --enable-debug --with-jvm-variants=server</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="JVM的内存管理模型是什么样子的？"><a href="#JVM的内存管理模型是什么样子的？" class="headerlink" title="JVM的内存管理模型是什么样子的？"></a>JVM的内存管理模型是什么样子的？</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16455236088988.jpg"></p>
<p>在java虚拟机中，最重要的两个分区就是堆和栈</p>
<h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p>堆空间就是我们一般放对象的地方，在栈里面放的都是基本数据类型和对象的引用。<br>堆也是会被垃圾收集的一块内存空间。可以在物理上不连续，但是在逻辑上连续。<br>通过JVM的版本不同（G1为分界），对堆的分区也有不同。</p>
<h3 id="栈（虚拟机栈）"><a href="#栈（虚拟机栈）" class="headerlink" title="栈（虚拟机栈）"></a>栈（虚拟机栈）</h3><p>栈是属于线程的，每一个线程在开始的时候，都会同步创建一个栈空间，每一次方法调用的时候，都会创建一个栈帧，放到这个栈里面，方法调用结束的时候，栈帧就会出栈。栈帧是和方法向对应的，里面有：</p>
<ul>
<li>局部变量表，放一些方法里面的局部变量</li>
<li>操作数栈，在做运算的时候需要的一种数据结构</li>
<li>动态链接</li>
<li>方法出口</li>
<li>等等</li>
</ul>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p>和操作数栈类似，只不过本地方法栈是给一个native方法服务的。</p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>程序计数器是<code>线程隔离</code>的，每一个线程都有一个程序计数器。我们的程序本质上是一个一个的字节码指令，像<code>LOP</code>什么的，我们的程序（线程）就是一条指令一条指令的往下执行，程序计数器就是记录的<code>当前程序执行的位置</code>，就是当前命令的<code>行号</code>。<br>因为在多线程 线程切换的时候，会记录下当前执行命令的行号，再当线程回来继续执行的时候。就会按照程序计数器中的行号继续往下执行。</p>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>方法区和堆一样，也是所有线程共用的。在逻辑上，它是数据堆空间的一部分，但是实际上是不同的实现。里面主要放一些：</p>
<ul>
<li>类的信息</li>
<li>静态变量的信息</li>
<li>常量</li>
<li>即时编译后的一些缓存的代码</li>
</ul>
<p>以JDK8为分界，以前有个永久代，来完成现在方法区的工作，几乎不做垃圾收集（除非一些类的卸载）。因为和堆共用空间，可能会导致内存溢出。<br>所以现在通过元空间来实现方法区。使用本地内存来实现，不会占用堆空间的大小。</p>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p>它是属于方法区的一部分。主要保存一些类在编译期的常量，还有运行时动态生成的一些常量。</p>
<h3 id="其他内存"><a href="#其他内存" class="headerlink" title="其他内存"></a>其他内存</h3><p>堆外内存，不被GC，可以通过NIO直接分配堆外内存，通过堆里面的一个引用来操作堆外内存。在一些场景中可以提高效率。</p>
<h2 id="Java对象的创建过程是什么样子的？"><a href="#Java对象的创建过程是什么样子的？" class="headerlink" title="Java对象的创建过程是什么样子的？"></a>Java对象的创建过程是什么样子的？</h2><ul>
<li>通过字节码中的NEW命令来创建对象</li>
<li>看类的字面量在常量池中有没有类的引用</li>
<li>判断这个类有没有被加载，如果没有的话，执行类加载</li>
<li>通过类，来判断对象多需要内存的大小</li>
<li>在堆空间中（eden）占用内存空间，有两种方式<ul>
<li>指针碰撞（Serial、ParNew等带压缩整理，需要对齐的堆空间，把判断空闲的指针向后移动特定距离）</li>
<li>空闲列表（CMS中，维护了一个表，来判断哪些内存是空闲的）</li>
</ul>
</li>
<li>占内存的并发问题<ul>
<li>CAS（如果发现冲突，重试）</li>
<li>本地线程分配缓冲（TLAB，-XX：+&#x2F;-UseTLAB配置开启。    每一个线程提前分配一定的堆内存大小，每个线程在自己的缓存中创建对象，如果自己的内存满了，分配新缓存时，使用同步锁）</li>
</ul>
</li>
<li>对象初始化为0（在对象体中，实例数据）</li>
<li>设置对象（对象头）。比如：来自于那个类，对象的Hash，偏向锁，存活年龄等。</li>
<li>再执行构造函数，完成程序员对对象的初始化。</li>
</ul>
<h2 id="Java对象的内存布局是什么样子的？"><a href="#Java对象的内存布局是什么样子的？" class="headerlink" title="Java对象的内存布局是什么样子的？"></a>Java对象的内存布局是什么样子的？</h2><ul>
<li>对象头<ul>
<li>MarkWord：Hash，年龄，锁信息，偏向线程ID等</li>
<li>类型指针、（数组长度）</li>
</ul>
</li>
<li>实例数据<ul>
<li>对象属性字段</li>
<li>对象和方法的引用</li>
</ul>
</li>
<li>数据填充<ul>
<li>占位，8的整数倍</li>
</ul>
</li>
<li>对象访问的两种方式<ul>
<li>句柄</li>
<li>直接指针引用</li>
</ul>
</li>
</ul>
<h2 id="实战2：OutOfMemoryError异常"><a href="#实战2：OutOfMemoryError异常" class="headerlink" title="实战2：OutOfMemoryError异常"></a>实战2：OutOfMemoryError异常</h2><ul>
<li>堆内存溢出</li>
<li>栈空间溢出（深度、内存大小）</li>
<li>方法区溢出（永久代、元空间）</li>
<li>直接内存溢出</li>
</ul>
<hr>
<h2 id="如何判断对象是垃圾？"><a href="#如何判断对象是垃圾？" class="headerlink" title="如何判断对象是垃圾？"></a>如何判断对象是垃圾？</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p>开辟一块空间来维护对象被引用的个数，如果为0，就表示该对象没有被引用。<br>优点：简单，判定效率高<br>缺点：没法解决循环引用的问题</p>
<h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h3><p>从GC Root为根节点，往下开始遍历、引用，搜索到的对象都是被引用的对象，其他的就是没有被引用的对象，需要被清理。<br>GCRoot包括：</p>
<ul>
<li>栈空间（包括虚拟机栈、本地方法栈）</li>
<li>方法区（静态变量，常量）</li>
<li>JVM内部引用（Class对象，常驻异常，空指针，内存溢出的异常，类加载器）</li>
<li>被synchronized锁住的对象</li>
<li>等等</li>
</ul>
<p>会有两次标记的过程<br>没有被GCRoot调用链的对象，先回被标记一次，再做一次筛选，看需不需要执行finalize()方法。如果需要执行，会放到队列里面执行。<br>执行finalize()方法有时间限制，不会永久的等待。但是在finalize()方法中，可以把当前对象重新给引用上，以逃离被清除的命运。<br>队列中执行完了之后，会进行第二次标记，其中对象有可能被重新引用上了（把this赋值给了别的对象）<br>第二次还是被标记上是垃圾的对象，就真的会被执行清除。</p>
<h3 id="对方法区的回收"><a href="#对方法区的回收" class="headerlink" title="对方法区的回收"></a>对方法区的回收</h3><ul>
<li>字符串常量的回收</li>
<li>类的卸载、回收（字节码创建的类）</li>
</ul>
<h2 id="Java中引用的类型有哪些？"><a href="#Java中引用的类型有哪些？" class="headerlink" title="Java中引用的类型有哪些？"></a>Java中引用的类型有哪些？</h2><h3 id="强引用-Strongly-Reference"><a href="#强引用-Strongly-Reference" class="headerlink" title="强引用 (Strongly Reference)"></a>强引用 (Strongly Reference)</h3><p>一般口中的引用，对象被强引用，就不会被回收</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">o</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br></pre></td></tr></table></figure>

<h3 id="软引用-（Soft-Reference）"><a href="#软引用-（Soft-Reference）" class="headerlink" title="软引用 （Soft Reference）"></a>软引用 （Soft Reference）</h3><p>还有用，但是非必需的对象。一般GC不会清理，但是内存溢出前会清理。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SoftReference&lt;Object&gt; softReference = <span class="keyword">new</span> <span class="title class_">SoftReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>());</span><br></pre></td></tr></table></figure>

<h3 id="弱引用（Weak-Reference）"><a href="#弱引用（Weak-Reference）" class="headerlink" title="弱引用（Weak Reference）"></a>弱引用（Weak Reference）</h3><p>被弱引用关联的对象只 能生存到下一次垃圾收集发生为止.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">WeakReference&lt;Object&gt; weakReference = <span class="keyword">new</span> <span class="title class_">WeakReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>());</span><br></pre></td></tr></table></figure>

<h3 id="虚引用（Phantom-Reference）"><a href="#虚引用（Phantom-Reference）" class="headerlink" title="虚引用（Phantom Reference）"></a>虚引用（Phantom Reference）</h3><p>不能被访问，没啥用，唯一的用处，就是对象在被回收的时候，得到一个系统通知。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PhantomReference&lt;Object&gt; phantomReference = <span class="keyword">new</span> <span class="title class_">PhantomReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>(), <span class="keyword">new</span> <span class="title class_">ReferenceQueue</span>&lt;&gt;());</span><br></pre></td></tr></table></figure>

<h2 id="垃圾收集算法有哪些？介绍一下。"><a href="#垃圾收集算法有哪些？介绍一下。" class="headerlink" title="垃圾收集算法有哪些？介绍一下。"></a>垃圾收集算法有哪些？介绍一下。</h2><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><p>基础GC算法，先标记，后清除。</p>
<p>问题：</p>
<ul>
<li>对象多，垃圾对象多的时候，效率不稳定，需要一个个的清除</li>
<li>会产生内存碎片</li>
</ul>
<h3 id="标记-复制算法"><a href="#标记-复制算法" class="headerlink" title="标记-复制算法"></a>标记-复制算法</h3><p>把内存分为大小相等的两块，每次只使用一块。每次做完标记之后，把存活的对象（新生代中存活的对象往往都是少数），全部移动到另外一块空白的内存上去，再把之前的这块内存全部清除。</p>
<p>好处：</p>
<ul>
<li>一次性的清除一块区域，效率高</li>
<li>每次复制的时候做整理，没有内存碎片</li>
<li>实现简单</li>
<li>缺点：</li>
<li>内存空间利用率低，每次只能用到一半的内存。</li>
</ul>
<h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><p>先标记，在进行整理，把存活的对象都整理到一边，再把边界之外的对象一次性全部清理掉。</p>
<p>优点：</p>
<ul>
<li>没有内存碎片</li>
<li>执行清理掉效率比较高</li>
<li>缺点：</li>
<li>移动对象的时候需要更长时间的Stop the world</li>
</ul>
<h2 id="HopSpot的垃圾收器是怎么实现的？"><a href="#HopSpot的垃圾收器是怎么实现的？" class="headerlink" title="HopSpot的垃圾收器是怎么实现的？"></a>HopSpot的垃圾收器是怎么实现的？</h2><ol>
<li>通过<code>OopMap</code>，在栈、方法区找到引用类型的GCRoot枚举</li>
<li>线程在<code>安全点</code>时，才会可能发生GC。比如一些方法调用、循环跳转、异常跳转等</li>
<li>如何在需要GC时，让所有线程都停在安全点上。<ol>
<li><code>主动式中断</code>，设置标志位，让线程轮训，自行中断</li>
<li><code>抢先式中断</code>，先全部强制中断，再把没有到安全点点线程，让它运行到安全点。</li>
</ol>
</li>
<li>对于挂起或者sleep中的线程，它可能永远不会走到安全点上，所以对于这样的线程，把它设为<code>安全区域</code>，随时可以做GC。</li>
<li>处理跨代的收集-&gt;<code>记忆集</code>和它的实现 <code>卡表</code><ol>
<li>卡表是记忆集的一种实现</li>
<li>卡表维护的其他年龄代的一块Page</li>
<li>如果有其他代的对象引用了当前代，对应卡表的元素变脏</li>
<li>在GC中，会把变脏的其他代内存对象当成GCRoot来扫描</li>
<li>在每次赋值操作是，会有个<code>写屏障</code>的过程，对赋值操作的AOP，会同时维护卡表元素</li>
</ol>
</li>
<li>可达性分析，如何标记对象。 三色标记法<ul>
<li>白色：未被扫描过，如果扫描结束了还是白色，说明这个对象就是垃圾</li>
<li>黑色：不是垃圾，被扫描过，而且它所有引用的对象也被扫描过</li>
<li>灰色：不是垃圾，但是它又被没有扫过的引用</li>
<li>等到没有灰色的时候，表示一次扫描结束。这时候，清除所有白色的垃圾</li>
<li>并发扫描的时候，对象消失的问题（本来应该被标记的对象，没有被标记上。<ul>
<li>黑色对象获取了白色对象的引用</li>
<li>灰色对象失去了所有对白色对象的引用</li>
<li>增量更新 and 原始快照</li>
<li>当扫描时，做赋值操作的时候，记录下来，在扫描结束的时候，再扫一次</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16458666178983.jpg"></p>
<h2 id="经典的垃圾收集器有哪些？"><a href="#经典的垃圾收集器有哪些？" class="headerlink" title="经典的垃圾收集器有哪些？"></a>经典的垃圾收集器有哪些？</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16467271742313.jpg"></p>
<h3 id="Serial收集器（年轻代）"><a href="#Serial收集器（年轻代）" class="headerlink" title="Serial收集器（年轻代）"></a>Serial收集器（年轻代）</h3><p>它需要把所有的用户线程全部停下来（Stop the world），然后专心的做垃圾清理。<br>缺点很明显，就是长时间的STW，影响用户体验，现在已经很少用了。<br>但是它也有优点，就是简单，单线程，使用的额外内存很少很少。有些场景可能回适用。</p>
<h3 id="ParNew收集器（年轻代）"><a href="#ParNew收集器（年轻代）" class="headerlink" title="ParNew收集器（年轻代）"></a>ParNew收集器（年轻代）</h3><p>他几乎和Serial一样，就是加入了多线程的功能，可以多个线程同时进行GC，但是这样就会增加了线程间切换的开销。<br>但是它有个优势，就是它可以和CMS搭配使用。在java9之前，这都是官方默认配置。</p>
<h3 id="Parallel-Scavenge收集器（年轻代）"><a href="#Parallel-Scavenge收集器（年轻代）" class="headerlink" title="Parallel Scavenge收集器（年轻代）"></a>Parallel Scavenge收集器（年轻代）</h3><p>他和ParNew收集器类似，但他有两个重要的特性：</p>
<ol>
<li>第一点就是它可以控制每次GC时STW的时间，和吞吐量的比率，但是如果配置的过小，它GC的就会更加频繁。</li>
<li>第二点就是，它有个自适应开关，打开了之后，我们就不用配置年轻代的大小了，它会根据监控数据，自动适应。<h3 id="Serial-Old收集器（老年代）"><a href="#Serial-Old收集器（老年代）" class="headerlink" title="Serial Old收集器（老年代）"></a>Serial Old收集器（老年代）</h3>老年代，单线程，串型收集器， 标记-整理。<br>主要是为了和Parallel Scavenge收集器搭配使用。  还有个用途，就是做CMS的后备收集器。<h3 id="Parallel-Old收集器（老年代）"><a href="#Parallel-Old收集器（老年代）" class="headerlink" title="Parallel Old收集器（老年代）"></a>Parallel Old收集器（老年代）</h3>Parallel Scavenge收集器的老年代版本， 标记-整理，注重吞吐量和单次GC时间。和Parallel Scavenge搭配使用。<h3 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h3>java9之前最经典的收集器，STW的时间非常短。它的特点就是可以GC线程和用户线程的并发。<br>它在一次GC的过程中共有四个阶段：</li>
<li>找到所有的GCRoot（STW）</li>
<li>并发标记</li>
<li>二次标记（STW）</li>
<li>并发清除<br>优点：它只需要很短的时间STW来做一些标记工作，标记-清理算法，快。<br>缺点：需要额外的内存，来存放在并发期间的新对象。内存不足会抛异常。会执行Serial Old收集。    需要间隔的执行内存整理，防止内存碎片。<h3 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h3>它是在java9之后主要的收集器，在以后也会慢慢的替换掉CMS。它的内存模型有一个比较大的改变，它是把整个的JVM内存分成一个一个的region来管理。每个region可以有不同的角色，比如edian、surivior、老年代和大对象区域。<br>然后每次回收都会选择性的清理一部分的region，根据配置，来选择清理效率最高的一些region。<br>它的GC过程主要分成四步：</li>
<li>初始标记（STW）<br>这一步主要是找GCRoot，耗时会比较短，因为会跨区域收集，所以每个region里面都会维护一个记忆集，是用来找到持有该region引用的内存区域。</li>
<li>并发标记<br>这一步是和用户线程并发执行了，耗时会比较长。<br>会维护两个区域，一个是在此过程中，新new出对象存放的区域，这次GC不会被清理。  还有一个就是在此过程中，指针有变换的对象，通过写屏障，就是对赋值操作的切面。会在下一步最终标记里面，再检查一次。</li>
<li>最终标记（STW）<br>这一步就是对在并发标记过程中，指针有变化的对象，再做一次确定操作，这一步也是需要STW的，保证不会把不是垃圾的对象收集掉。</li>
<li>筛选清除（STW）<br>这一步的时候，就能确定region里面的垃圾了，也可以计算出清理region所需要的时间，大概，然后对清理的成本和价值做个排序，根据配置的清理时间，确定要清理哪一些region。 再做复制-清除操作，因为涉及到了复制对象，所以需要用户线程是STW的。</li>
</ol>
<p>相比CMS，它需要更多内存空间来维护一些东西，比如region的管理，每个region都会有一份的卡表（跨区域指针），而CMS只需要在年轻代维护一份卡表就行了。  它的主要优势是它把整个JVM内存化整为零，不会一次性清理全部的区域，而是根据配置，可控的清理一部分region。  还有一点就是，每次清理实际上是标记-复制法，所以不会有内存碎片，而CMS是标记-清除法，会有内存碎片的问题。   目前在大内存的服务器上，G1的性能会更好。</p>
<h2 id="低延迟的垃圾收集器有哪些？"><a href="#低延迟的垃圾收集器有哪些？" class="headerlink" title="低延迟的垃圾收集器有哪些？"></a>低延迟的垃圾收集器有哪些？</h2><h3 id="Shenandoah收集器"><a href="#Shenandoah收集器" class="headerlink" title="Shenandoah收集器"></a>Shenandoah收集器</h3><p>它不是Oracle官方出的GC，是redhat搞的，所以不受官方的支持，只能在openJDK上使用。<br>它的内存分布和G1差不多，都是使用region把内存分成一个一个的小块，再进行收集。<br>它的收集过程</p>
<ol>
<li>GCRoot标记</li>
<li>并发标记</li>
<li>最终标记</li>
<li>并发清理（清理全部是垃圾的region）</li>
<li>并发回收（把region中存活的对象，移到新的region中）</li>
<li>初始引用更新（这里把老对象的地址，和对应新对象的地址找出来，并做成一个Map映射， 短暂的STW）</li>
<li>并发引用更新（按物理顺序扫描，按照映射修改引用地址）</li>
<li>最终引用更新（更改GCTRoot的引用，短暂STW）</li>
<li>最终并发清理（这时候老的region应该都是垃圾对象了，再并发清理掉）</li>
</ol>
<p>它的特点就是停顿时间很短，基本上大的操作都是并发执行的，但是就是因为是并发，会有很多线程竞争的场景，所以总体吞吐量不大。整体性能一般。</p>
<h3 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a>ZGC</h3><p>它是目前最先进的一款收集器，参考的是Azul公司的PGC和C4收集器。 它最大的特点，就是在对象在region间复制的过程中，不需要STW，而且复制过去了之后，立马生效，不同再等到全堆扫描更新引用。<br>它主要的技术是：</p>
<ul>
<li>染色指针（就是在指针上面打Flag，而不用存在对象头，或者单独维护）</li>
<li>读屏障（在对象内存寻址的时候，可以重定向）</li>
<li>内存多种映射（这是为了解决不同底层硬件，操作系统对染色指针的不支持）<br>它的主要GC过程：</li>
</ul>
<ol>
<li>标记（初始、并发、最终）</li>
<li>并发准备重分配（扫描所有的region，找到这次需要清理的region）</li>
<li>并发重分配（就是把region里面不是垃圾的对象做复制转移，并在当前region里面，维护一个转发表，这个时候，就可以把老的对象给删了）     如果这个时候有新的寻址过来，通过读屏障，会在转发表里面，找到对象的新地址，并更新引用。</li>
<li>并发重映射（就是扫描所有的对象，把引用全部更新成新的地址，在转发表里面找），因为这一步不需要立刻执行，所有它把这一步合并到下一次GC的标记操作中了。</li>
</ol>
<h2 id="如何选择垃圾收集器？"><a href="#如何选择垃圾收集器？" class="headerlink" title="如何选择垃圾收集器？"></a>如何选择垃圾收集器？</h2><p>场景：</p>
<ol>
<li>桌面程序，占用内存</li>
<li>服务，注重停顿时间</li>
<li>计算密集性服务，吞吐量</li>
<li>老版本的JDK</li>
<li>有充足预算，直接上Azul公司的C4</li>
</ol>
<h2 id="实战3：内存分配与回收策略"><a href="#实战3：内存分配与回收策略" class="headerlink" title="实战3：内存分配与回收策略"></a>实战3：内存分配与回收策略</h2><hr>
<h2 id="JVM提供了哪些监控工具？"><a href="#JVM提供了哪些监控工具？" class="headerlink" title="JVM提供了哪些监控工具？"></a>JVM提供了哪些监控工具？</h2><ul>
<li>jps [-lv]  查看所有jvm进程</li>
<li>jstat [-option] pid  查看jvm状态</li>
<li>jinfo [-option] pid 查看jvm配置信息</li>
<li>jmap  查看内存信息<ul>
<li><code>jmap -dump:format=b,file=eclipse.bin 3500</code></li>
</ul>
</li>
<li>jstack pid  查看堆栈信息</li>
</ul>
<h2 id="市面上有哪些可视化的工具？"><a href="#市面上有哪些可视化的工具？" class="headerlink" title="市面上有哪些可视化的工具？"></a>市面上有哪些可视化的工具？</h2><ul>
<li>JConsole</li>
<li>VisualVM</li>
<li>·Eclipse的Memory Analyzer Tool[5]（MAT）</li>
</ul>
<h2 id="JVM是怎么调优的？举例说明一下。"><a href="#JVM是怎么调优的？举例说明一下。" class="headerlink" title="JVM是怎么调优的？举例说明一下。"></a>JVM是怎么调优的？举例说明一下。</h2><h4 id="大内存大对象的优化"><a href="#大内存大对象的优化" class="headerlink" title="大内存大对象的优化"></a>大内存大对象的优化</h4><p>方案：</p>
<ol>
<li>用Shenandoah、ZGC等可控延迟的GC</li>
<li>使用Full GC 时，控制频率</li>
<li>拆分虚拟机，一个大内存的JVM变成多个小内存的JVM</li>
</ol>
<h4 id="缓存溢出"><a href="#缓存溢出" class="headerlink" title="缓存溢出"></a>缓存溢出</h4><p>因为某些原因，导致缓存一直没有被消除</p>
<h4 id="堆外内存溢出"><a href="#堆外内存溢出" class="headerlink" title="堆外内存溢出"></a>堆外内存溢出</h4><p>使用NIO操作文件，可直接只用堆外内存。 需要注意堆外内存大小。</p>
<h4 id="调用shell脚本导致内存溢出"><a href="#调用shell脚本导致内存溢出" class="headerlink" title="调用shell脚本导致内存溢出"></a>调用shell脚本导致内存溢出</h4><p>通过Java的Runtime.getRuntime().exec()，这个非常消耗资源，频繁调用，会导致内存溢出。</p>
<h4 id="socket链接长时间等待"><a href="#socket链接长时间等待" class="headerlink" title="socket链接长时间等待"></a>socket链接长时间等待</h4><p>链接服务慢，导致本机长时间等待，socket链接堆积，导致内存溢出。<br>可更换链接方式。</p>
<h4 id="数据分析，大批量数据存活"><a href="#数据分析，大批量数据存活" class="headerlink" title="数据分析，大批量数据存活"></a>数据分析，大批量数据存活</h4><p>大匹量对象在Eden中存活，在Surivor中来回复制，导致停顿时间长。</p>
<h4 id="某线程到达安全点时间长"><a href="#某线程到达安全点时间长" class="headerlink" title="某线程到达安全点时间长"></a>某线程到达安全点时间长</h4><p>某线程使用int使用循环，是不会进入安全点的。导致该线程需要长时间到达安全点，其他线程只能等待。<br>方案：找到长时间运转的线程，把int-&gt;long</p>
<h2 id="Class文件结构是什么样子的？"><a href="#Class文件结构是什么样子的？" class="headerlink" title="Class文件结构是什么样子的？"></a>Class文件结构是什么样子的？</h2><ol>
<li>Magic Number</li>
<li>版本号</li>
<li>常量池（字面量+引用符号）</li>
<li>类描述符、父类、接口列表</li>
<li>字段集合</li>
<li>方法集合</li>
<li>属性集合（类的源文件、方法体）</li>
</ol>
<h2 id="你知道的字节码指令有哪些？"><a href="#你知道的字节码指令有哪些？" class="headerlink" title="你知道的字节码指令有哪些？"></a>你知道的字节码指令有哪些？</h2><h4 id="加载、存储指令"><a href="#加载、存储指令" class="headerlink" title="加载、存储指令"></a>加载、存储指令</h4><ul>
<li>load：从局部变量表 加载 到操作数栈（入栈）</li>
<li>store：从操作数栈 存储数据到局部变量表（出栈）</li>
<li>const：加载一个常量到操作数栈（入栈）<h4 id="运算指令"><a href="#运算指令" class="headerlink" title="运算指令"></a>运算指令</h4></li>
<li>加：add</li>
<li>减：sub</li>
<li>乘：mul</li>
<li>除：div</li>
<li>取余：rem</li>
<li>取反：neg</li>
<li>位移：shl、shr</li>
<li>按位与、或：and、or</li>
<li>按位异或：xor</li>
<li>局部变量自增：inc</li>
<li>比较：cmpg、cmpl<h4 id="对象创建与访问指令"><a href="#对象创建与访问指令" class="headerlink" title="对象创建与访问指令"></a>对象创建与访问指令</h4></li>
<li>创建对象：new</li>
<li>创建数组：newarray</li>
<li>访问对象属性：getfield、putfield、getstatic、putstatic</li>
<li>数组操作：aload、astore<h4 id="操作数栈管理指令"><a href="#操作数栈管理指令" class="headerlink" title="操作数栈管理指令"></a>操作数栈管理指令</h4></li>
<li>出栈：pop、pop2</li>
<li>复制栈顶的值：dup、dup2</li>
<li>栈顶两个元素交换位置：swap<h4 id="控制转移指令"><a href="#控制转移指令" class="headerlink" title="控制转移指令"></a>控制转移指令</h4></li>
<li>if</li>
<li>switch</li>
<li>goto<h4 id="方法调用和返回指令"><a href="#方法调用和返回指令" class="headerlink" title="方法调用和返回指令"></a>方法调用和返回指令</h4></li>
<li><strong>invokevirtual</strong></li>
<li>invokeinterface</li>
<li>invokespecial</li>
<li><strong>invokedynamic</strong><h4 id="异常指令"><a href="#异常指令" class="headerlink" title="异常指令"></a>异常指令</h4></li>
<li>athrow<h4 id="同步指令（synchronized）"><a href="#同步指令（synchronized）" class="headerlink" title="同步指令（synchronized）"></a>同步指令（synchronized）</h4></li>
<li>monitor enter</li>
<li>monitor exit</li>
</ul>
<h2 id="Java的类加载过程是什么样子的？"><a href="#Java的类加载过程是什么样子的？" class="headerlink" title="Java的类加载过程是什么样子的？"></a>Java的类加载过程是什么样子的？</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16478477164166.jpg"></p>
<ol>
<li>加载（加载字节码）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 通过全限定类名找到改类的二进制流（字节码）</span><br><span class="line">2. 将字节码流转化成方法区的存储结构</span><br><span class="line">3. 在内存中生成一个Class对象，来作为这个类的访问入口</span><br></pre></td></tr></table></figure></li>
<li>验证（验证字节码格式）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">对字节码的格式、语义做校验，要是不符合规范的，抛出VerifyException。</span><br></pre></td></tr></table></figure></li>
<li>准备（基础数据类型的准备）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">为一些静态变量赋值，static修饰的变量，赋成 0 。</span><br><span class="line">但是使用final修饰的常量，直接赋成定义的值。</span><br></pre></td></tr></table></figure></li>
<li>解析（引用类型的解析，找到对应的类，并做一些校验）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">将符号引用转换成直接引用。</span><br><span class="line">就是将字符串、字面量转换成其他类真正的引用。</span><br><span class="line">如果其他的类还没有加载，就先加载其他的类。</span><br></pre></td></tr></table></figure></li>
<li>初始化（走一些静态语句脚本）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">JVM会汇总一个clinit方法，里面会包含所有变量的赋值操作，和静态代码块的内容。</span><br><span class="line">然后会对它们按顺序执行。</span><br><span class="line">如果它的父类有clinit方法，会先执行父类的。</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="有几种类加载器？双亲委派是什么？"><a href="#有几种类加载器？双亲委派是什么？" class="headerlink" title="有几种类加载器？双亲委派是什么？"></a>有几种类加载器？双亲委派是什么？</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16478551695468.jpg"></p>
<ul>
<li>启动类加载器（bootstrap）<ul>
<li>加载java核心代码（lib目录下），比如rt.jar tools.jar</li>
<li>C语言编写，我们没法使用</li>
</ul>
</li>
<li>扩展类加载器（extension）<ul>
<li>加载java扩展代码，ext目录下</li>
<li>Java编写，可以获取到使用</li>
</ul>
</li>
<li>应用程序类加载器（application）<ul>
<li>加载我们自己编写的代码</li>
<li>一般Class默认的类加载器</li>
</ul>
</li>
<li>自定义类加载器<ul>
<li>实现 <code>ClassLoader</code>接口</li>
</ul>
</li>
</ul>
<h4 id="双亲委派"><a href="#双亲委派" class="headerlink" title="双亲委派"></a>双亲委派</h4><p>当我们得到一个全限定类名，并尝试加载它的时候，会先让当前Classloader的父加载器去加载，如果该类不在父加载器的加载范围，再使用当前加载器加载。<br>这样的目的是保证一些核心类的安全。一些基础的类，比如Object，只能使用bootstrap加载器加载。<br>以为在Java中，判断一个类的唯一性，是通过 类加载器+全限定类名 来判断的，如果使用两个类加载器加载Object，会导致程序错乱。</p>
<h4 id="打破双亲委派"><a href="#打破双亲委派" class="headerlink" title="打破双亲委派"></a>打破双亲委派</h4><ol>
<li>java1.2以前</li>
<li>热部署、osgi</li>
</ol>
<h4 id="在java9之后的双亲委派"><a href="#在java9之后的双亲委派" class="headerlink" title="在java9之后的双亲委派"></a>在java9之后的双亲委派</h4><p>在java9之后，引入了模块系统，每个模块是隔离的，所以在ApplicationClassLoader和PlatfromClassLoader中，在向上委派之前，会现在其他的module中找一下这个类的归属，如果属于别的module，就让别的module的classloader加载。</p>
<h2 id="Java运行时候的栈帧是什么样子的？"><a href="#Java运行时候的栈帧是什么样子的？" class="headerlink" title="Java运行时候的栈帧是什么样子的？"></a>Java运行时候的栈帧是什么样子的？</h2><ul>
<li>局部变量表（变量保存）<ul>
<li>它主要存储在当前作用域中的一些局部变量，存储单元是变量槽，0号变量槽是this，其他的变量（方法参数，定义的变量）从1开始往后。</li>
<li>变量槽可以复用，但是不会主动擦除数据。</li>
</ul>
</li>
<li>操作数栈（函数、方法的参数传递）<ul>
<li>栈结构，用来做运算和方法调用</li>
</ul>
</li>
<li>动态链接（找调用方法的入口）<ul>
<li>在多态的情况下，只有在运行时才能知道，到底是调用的哪个类的方法，所以要保存一个动态链接。</li>
</ul>
</li>
<li>方法返回地址（当前方法的出口）</li>
</ul>
<h2 id="Java运行时，方法调用的过程是什么样子的？"><a href="#Java运行时，方法调用的过程是什么样子的？" class="headerlink" title="Java运行时，方法调用的过程是什么样子的？"></a>Java运行时，方法调用的过程是什么样子的？</h2><p>方法调用主要分为两种，静态的和动态的。</p>
<ul>
<li>invoke字节码命令</li>
<li>静态分配<ul>
<li>在编译期间就能够去定需要调用的是哪个方法</li>
<li>在一些static方法调用，无继承的（finial修饰）方法调用</li>
</ul>
</li>
<li>动态分配<ul>
<li>在运行期间才能够确定，到底调用的是哪个方法</li>
<li>典型的就是多态，在运行的时候，才能确定调用的是哪个子类对象</li>
</ul>
</li>
<li>在方法区中，虚拟机会对每个类维护一个虚方法表，来记录它调用地址的入口，如果是继承的方法且没有重写，就会指向父类的对应方法入口。</li>
<li>接口同理（接口方法表）</li>
<li>没有别final修饰的方法，都是虚方法</li>
</ul>
<h2 id="Java的动态语言类型支持是什么样子的？"><a href="#Java的动态语言类型支持是什么样子的？" class="headerlink" title="Java的动态语言类型支持是什么样子的？"></a>Java的动态语言类型支持是什么样子的？</h2><p>通过<code>invokedynamic</code>字节码命令实现。<br>在别的动态类型语言里面，类似JavaScript、Grvooy，通过<code>var</code>来定义对象，这个时候就不能确定引用的类型，所以在实际运行时方法调用的时候，需要找到真正执行方法，就有一个lookup的过程。</p>
<h2 id="实战4：掌控方法分派规则"><a href="#实战4：掌控方法分派规则" class="headerlink" title="实战4：掌控方法分派规则"></a>实战4：掌控方法分派规则</h2><h2 id="字节码解释执行的过程是什么样子的？"><a href="#字节码解释执行的过程是什么样子的？" class="headerlink" title="字节码解释执行的过程是什么样子的？"></a>字节码解释执行的过程是什么样子的？</h2><p>我们编写的Java源代码，本质上就是一堆字符串，计算机肯定不认识，所以我们把这段字符串交给JVM编译，编译的结果有两种：<br>一种是字节码，JVM认识，物理机不认识，只能通过JVM解释执行。<br>还有一种就是CPU的指令集，汇编，本质上就是0101，物理机能直接执行。</p>
<p>在JVM的解释执行字节码的过程中，是通过操作数栈进行指令执行的，它是基于内存的，所以速度理论上会慢一点，但是它不会依赖物理机器，可移植。 而物理机执行的话，是基于寄存器的，速度会很快，但是不同架构的CPU的寄存器和指令集都是不同的，就没有可移植性。</p>
<h2 id="你了解的字节码生成技术是什么样子的？"><a href="#你了解的字节码生成技术是什么样子的？" class="headerlink" title="你了解的字节码生成技术是什么样子的？"></a>你了解的字节码生成技术是什么样子的？</h2><h2 id="实战5：自己动手实现远程执行功能"><a href="#实战5：自己动手实现远程执行功能" class="headerlink" title="实战5：自己动手实现远程执行功能"></a>实战5：自己动手实现远程执行功能</h2><h2 id="Java编译的流程是什么样子的？"><a href="#Java编译的流程是什么样子的？" class="headerlink" title="Java编译的流程是什么样子的？"></a>Java编译的流程是什么样子的？</h2><p>Java的编译主要依靠javac工具来执行的，他的任务就是把java源代码，编译成 .class的字节码。<br>主要通过<code>JavaCompiler</code>类来实现的。<br>有4个过程：</p>
<ul>
<li>准备过程<ul>
<li>准备插入式注解处理器（<code>initProcessAnnotations</code>）</li>
</ul>
</li>
<li>语法解析 and 填充符号表 -&gt; 生成抽象语法树<ul>
<li>语法、词法解析。（<code>parseFiles</code>）<ul>
<li>有点像ES中的分词，生成抽象语法树（AST）。</li>
<li>后续的操作都基于这个抽象语法树了。</li>
<li>有插件可以查看。</li>
</ul>
</li>
<li>填充符号表。 产生符号地址和符号信息内容（<code>enterTrees</code>）</li>
</ul>
</li>
<li>注解处理器的处理过程。 （<code>processAnnotations</code>）<ul>
<li>通过注解，在编译期间对抽象语法树做出处理。 著名的案例就是Lombok。</li>
</ul>
</li>
<li>分析语法树 and 字节码生成（<code>compile2()</code>）<ul>
<li>标注检查分析（静态）（<code>attribute()</code>）</li>
<li>控制流检查分析（动态）（<code>flow()</code>）</li>
<li>解语法糖（<code>desugar()</code>）</li>
<li>字节码生成（<code>generate()</code>）</li>
</ul>
</li>
</ul>
<h2 id="实战6：插入式注解处理器"><a href="#实战6：插入式注解处理器" class="headerlink" title="实战6：插入式注解处理器"></a>实战6：插入式注解处理器</h2><h2 id="后端编译的过程是什么样子的？"><a href="#后端编译的过程是什么样子的？" class="headerlink" title="后端编译的过程是什么样子的？"></a>后端编译的过程是什么样子的？</h2><p>后端编译就是java的字节码编译成机器码的过程。在机器上直接跑机器码，速度和性能就会更快。<br>后端编译就是即时编译，是HotSpot虚拟机有的一个主要的功能，其他虚拟机有的也有。<br>它主要的作用，就是在运行期间，对代码的热度，进行统计分析，针对的是方法级别和循环体级别，然后把热点的字节码编译成机器码，让计算机原生之行。</p>
<p>热点统计方式主要有两种：<br>1、采样。  定时在所有栈的顶部采集栈帧，统计方法调用的次数。<br>2、方法计数器。 每个方法、代码块，维护一个调用计数器。到达一定的阈值，就会成为热点代码，会被即时编译期异步的编译成为原生的机器码。</p>
<p>在HotSpot虚拟机中，主要有三种即时编译器，C1、C2和Java10才出来的Graal。 其中Graal的作用是C2的升级版。</p>
<p>在JVM中，使用的是分层编译的方式。<br>第0层，就是纯解释执行<br>第1层，是使用C1编译器，简单快速的编译，并不做统计。<br>第2层，使用C1编译器编译，并做有限的性能监控。<br>第3层，使用C1编译器，并开启全部都性能监控<br>第4层，使用C2编译器，做激进的性能优化<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16487127229876.jpg"></p>
<h2 id="编译的优化方法有哪些？"><a href="#编译的优化方法有哪些？" class="headerlink" title="编译的优化方法有哪些？"></a>编译的优化方法有哪些？</h2><ul>
<li>方法内联（多态方法内联缓存）</li>
<li>逃逸分析（看这个对象有没有超过方法的范围（栈帧），有没有超过线程的范围（方法栈））<ul>
<li>栈上分配（把对象直接在栈上创建，不在堆内存创建）</li>
<li>标量替换（不new出对象，用几个局部变量来代替）</li>
<li>同步消除（如果有锁，而这个对象并没有超出线程的范围，就把锁的过程给优化掉）</li>
</ul>
</li>
<li>无效代码消除</li>
<li>公共子表达式消除（在一个表达式中，如果有重复计算的地方，给他做合并消除，即只需要计算一次）</li>
<li>代数化简（数学操作）</li>
<li>数组边界检查、隐式异常处理、自动装箱消除</li>
</ul>
<h4 id="客户端编译器-C1"><a href="#客户端编译器-C1" class="headerlink" title="客户端编译器  C1"></a>客户端编译器  C1</h4><p>在整体的编译过程一共有几个阶段。</p>
<p>第一个就是从 <code>字节码</code>  编译成  <code>HIR</code>（高级的中间表示编码，与硬件指令集无关）<br>这个时候，会做一些优化。如：<code>方法内联</code>、<code>常数传播</code></p>
<p>第二阶段就是 对  <code>HIR</code>编码做优化<br>会做一些 <code>范围检查消除</code>、<code>空值检查消除</code>等优化</p>
<p>第三阶段就是 把 <code>HIR</code>  编译成  <code>LIR</code>（低等级的中间表示，与硬件指令集有关）</p>
<p>最后一阶段，就是在<code>LIR</code>上做<code>线性算法扫描</code>，<code>分配寄存器</code>，做<code>窥孔</code>（Peephole）优化， 最后生成<code>机器码</code>。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16487136001857.jpg"></p>
<h4 id="服务端编译器-C2"><a href="#服务端编译器-C2" class="headerlink" title="服务端编译器  C2"></a>服务端编译器  C2</h4><p>服务端编译器的优化会更加的激进。</p>
<p>无用代码消除（Dead Code Elimination）、<br>循环展开 （Loop Unrolling）、<br>循环表达式外提（Loop Expression Hoisting）、<br>消除公共子表达式（Common Subexpression Elimination）、<br>常量传播（Constant Propagation）、<br>基本块重排序（Basic Block Reordering）等</p>
<p>范围检查消除（Range Check Elimination）、<br>空值检查消除（Null Check Elimination）</p>
<p>如守护内联（Guarded Inlining）、<br>分支频率预测 （Branch Frequency Prediction）</p>
<h2 id="提前编译-和-即时编译-各有什么优缺点？"><a href="#提前编译-和-即时编译-各有什么优缺点？" class="headerlink" title="提前编译 和 即时编译 各有什么优缺点？"></a>提前编译 和 即时编译 各有什么优缺点？</h2><p>提前编译的优点：</p>
<ol>
<li>独立的资源，在程序运行之前编译，可以享受大量的资源。</li>
<li>一开始运行时的程序的速度就会非常快，不会有预热的过程。<br>及时编译的优点：</li>
<li>实时监控，编译需要编译的代码，并且按层级编译，最高效的使用资源。</li>
<li>可以执行激进的编译优化策略，也是根据性能监控。</li>
<li>动态链接时优化，在运行时，可以确定动态链接库，可以做一些优化，比如方法内联。</li>
</ol>
<h2 id="实战6：深入理解Graal编译器"><a href="#实战6：深入理解Graal编译器" class="headerlink" title="实战6：深入理解Graal编译器"></a>实战6：深入理解Graal编译器</h2><p>字节码 -&gt; 理想图 -&gt; 优化 -&gt; 机器码</p>
<h2 id="Java内存模型是什么样子的？"><a href="#Java内存模型是什么样子的？" class="headerlink" title="Java内存模型是什么样子的？"></a>Java内存模型是什么样子的？</h2><p>首先要从计算机的发展说起，摩尔定律慢慢的失效，硬件发展到了一个瓶颈，而在这种情况下，并行化的发展越来越被看重。 所以就CPU的核心数就越来越多。<br>而有一个客观问题的存在，CPU的速度实在太快了，跟内存的IO不是一个数量级的，我们为了能更加的压榨CPU的性能，就在CPU的每个核心中设立了高速缓存，一般是三层。<br>而这样就会出现一个问题，在多个核心同时对主内存中的数据做操作的时候，会先把内存中的数据缓存一份到自己的高速缓存中，再进行操作。这样就会有了一个数据不一致的并发的问题。  解决这个问题的方法，就是设定一个缓存一致性协议。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16493208068770.jpg"></p>
<p>而JAVA在这样的基础上，对CPU、高速缓存、主内存这样的硬件结构的基础上，做了一个抽象。就成了JMM（JAVA内存模型）<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/16493208196376.jpg"></p>
<h2 id="volatile关键字有什么用？"><a href="#volatile关键字有什么用？" class="headerlink" title="volatile关键字有什么用？"></a>volatile关键字有什么用？</h2><ol>
<li>保证变量的可见性<ul>
<li>线程1和线程2，同时操作主内存里面的一个数据。</li>
<li>两个线程都会把数据缓存到自己的工作内存中（高速缓存或寄存器）</li>
<li>如果线程1操作了这个数据，会立刻把更新过后的数据同步到主内存之中</li>
<li>线程2在操作这个数据之前，会先从主内存中拉取最新的数据，再进行操作。</li>
</ul>
</li>
<li>阻止指令重排序<ul>
<li>CPU在执行程序的时候，不一定会按照我们代码编写的顺序执行</li>
<li>CPU为了优化，在编译成汇编语言的时候，会对程序进行各种优化</li>
<li>在赋值操作的时候，顺序的变化可能会导致意想不到的问题</li>
<li>volatile会防止指令的重排序，会添加一个<code>lock add</code>的指令，内存屏障</li>
<li>指令重排的意义在于，CPU把不同的指令，同时分配给不同的电路单元，以提高性能</li>
</ul>
</li>
</ol>
<h2 id="Java的多线程是怎么实现的？"><a href="#Java的多线程是怎么实现的？" class="headerlink" title="Java的多线程是怎么实现的？"></a>Java的多线程是怎么实现的？</h2><p>在主流的操作系统中，线程一般有三种实现方式：</p>
<ol>
<li>内核线程，操作系统自己实现</li>
<li>用户线程，应用程序实现</li>
<li>混合模式，内核线程+用户线程  在一个核心线程上，再扩展N个用户线程</li>
</ol>
<p>JAVA中，主流的JVM都是使用的内核线程，具体的调度由操作系统控制。<br>在GO中，主要使用的是用户线程</p>
<p>核心线程的重要的性能消耗是操作系统在内核态与用户态之间的转换，但是它的优点就是实现起来方便，调操作系统的接口就行了， 上下文的保持工作也是由操作系统实现。<br>而用户线程的有点就是实现起来非常复杂，线程的调度，线程上下文的保持都需要代码实现。而它的优点就是运行效率更高一些。<br>在新版本的JAVA中，也引入的用户线程的实现，fiber，纤程&#x2F;协程。 JAVA可以同时支持核心线程和用户线程</p>
<h2 id="Java中线程安全是怎么保证的？"><a href="#Java中线程安全是怎么保证的？" class="headerlink" title="Java中线程安全是怎么保证的？"></a>Java中线程安全是怎么保证的？</h2><ol>
<li>synchronized关键字</li>
<li>concurrent包， ReentrantLock</li>
<li>分布式锁  redis&#x2F;zk</li>
</ol>
<h2 id="Java中有哪些锁优化？"><a href="#Java中有哪些锁优化？" class="headerlink" title="Java中有哪些锁优化？"></a>Java中有哪些锁优化？</h2><ul>
<li>自旋锁 CAS 忙循环，不会进入线程阻塞  JVM监控子系统还会推算忙循环的次数</li>
<li>锁消除  如果JVM发现没有共享内存变量，即不需要锁，就会把锁给去了</li>
<li>锁粗化  如果检测到一连串的锁，比如StringBuffer连续append，会粗化成一个锁</li>
<li>轻量级锁   由对象头的MarkWord中的标志位 标记。<ul>
<li>如果对象的标志位为<code>01</code>，表示未上锁，线程会通过CSA把标志位改成<code>00</code>，并持有这个锁对象</li>
<li>如果这时候有另外的线程来抢占这个锁，会把锁升级成重量级锁，标志位<code>10</code></li>
</ul>
</li>
<li>偏向锁  在无锁状态下的优化<ul>
<li>在一个线程占用了一个锁对象，又释放了，这时候这个对象是无锁的状态，还会把偏向模式设成1，并记录这个线程的ID</li>
<li>如果这个线程再次获取锁，且在无并发竞争的情况下，不需要上锁了</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>十大排序算法</title>
    <url>/2021/07/06/algorithm/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>今天开启我们的算法系列，争取说简单➕通俗易懂。<br>我们从经典的排序算法开始。学习十大排序算法。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/zoOH3H.png"></p>
<p>排序算法可以分为两大类：基于比较的排序 and 不基于比较的排序。<br>基于比较的排序，是通过元素间的两两比较，来判断大小，继而排序。<br>不基于比较的排序，就是通过各种其他的方法，来让元素排序。</p>
<p>在表格中，上面的7种都是基于比较的排序算法。下3种是不基于比较的排序。</p>
<p>接下来我们一个一个的来仔细看。</p>
<span id="more"></span>

<h2 id="1、冒泡排序（Bubble-Sort）"><a href="#1、冒泡排序（Bubble-Sort）" class="headerlink" title="1、冒泡排序（Bubble Sort）"></a>1、冒泡排序（Bubble Sort）</h2><p>首先，我们来说说最简单的冒泡排序。</p>
<p>大家可以想象一下，在小学的时候，第一节体育课，老师给我们按照身高排成一列。</p>
<p>就是相邻的两个同学比较一下身高，让后把高的放右边，矮的站左边。</p>
<p>冒泡排序就是这样，从左往右遍历，相邻的两个元素进行比较，大的放右边，小的放左边。</p>
<p>这样一次遍历之后，最右边的元素肯定是最大的。</p>
<p>再进行n次遍历，就可以把整个队列排好序了。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015223238449-2146169197.gif"></p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 冒泡排序</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 两次循环，相邻的两个元素比较，小的往前</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * O(n2)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BubbleSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="comment">// 注意边界， 不用到最后一个</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; nums.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line">				<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; nums.length - i - <span class="number">1</span>; j++) &#123;</span><br><span class="line">					<span class="keyword">if</span> (nums[j] &gt; nums[j + <span class="number">1</span>]) &#123;</span><br><span class="line">						SortUtil.swap(nums, j, j + <span class="number">1</span>);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2、选择排序（Selection-Sort）"><a href="#2、选择排序（Selection-Sort）" class="headerlink" title="2、选择排序（Selection Sort）"></a>2、选择排序（Selection Sort）</h2><p>选择排序思路也很简单，我们把队列分成两个部分。</p>
<p>一部分是乱序的，就是我们一开始的样子。</p>
<p>一部分是有序的。</p>
<p>我们先在乱序的队列里面找到一个最小的元素，放到有序的队列里面。</p>
<p>再在乱序的队列里面找一个最小的元素，依次放到有序队列里面。</p>
<p>直到乱序的队列里面一个元素都没有了。</p>
<p>这样，有序的队列就是我们最终的结果。</p>
<p>为了节省空间，我们可以在一个数组里面，存下这两个队列。<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015223238449-2146169197.gif"></p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 选择排序， 每次循环找出最小值，往前面换</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SelectionSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="type">int</span> minIndex;</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; nums.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line">				minIndex = i;</span><br><span class="line">				<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i; j &lt; nums.length; j++) &#123;</span><br><span class="line">					<span class="keyword">if</span> (nums[j] &lt; nums[minIndex]) &#123;</span><br><span class="line">						minIndex = j;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				SortUtil.swap(nums, i, minIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3、插入排序（Insertion-Sort）"><a href="#3、插入排序（Insertion-Sort）" class="headerlink" title="3、插入排序（Insertion Sort）"></a>3、插入排序（Insertion Sort）</h2><p>插入排序也很好理解。</p>
<p>相信大家都打过扑克牌，每次我们一开始摸牌都时候，都是一次插入排序都过程。</p>
<p>同样有两个队列，一个乱序，一个有序。</p>
<p>每次我们从乱序都队列里面拿出一张牌，再插入到有序队列里面合适到地方。</p>
<p>这就是插入排序。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015225645277-1151100000-2.gif"></p>
<p>请看代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 插入排序， 找到一个元素，向前扫描，前面但往后移动，在合适但地方插入</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InsertionSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="keyword">if</span> (nums.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">				<span class="keyword">return</span> nums;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 1   3   2</span></span><br><span class="line">			<span class="comment">//     j   i</span></span><br><span class="line">			<span class="comment">// 1   2   3</span></span><br><span class="line">			<span class="comment">// j       i</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">				<span class="type">int</span> <span class="variable">indexValue</span> <span class="operator">=</span> nums[i];</span><br><span class="line">				<span class="comment">// 往左扫描</span></span><br><span class="line">				<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i - <span class="number">1</span>; j &gt;= <span class="number">0</span>; j--) &#123;</span><br><span class="line">					<span class="comment">// 如果indexValue比较小，j往右移动</span></span><br><span class="line">					<span class="comment">// 同时把 i的值填充进去</span></span><br><span class="line">					<span class="keyword">if</span> (indexValue &lt; nums[j]) &#123;</span><br><span class="line">						nums[j + <span class="number">1</span>] = nums[j];</span><br><span class="line">						nums[j] = indexValue;</span><br><span class="line">					&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">						<span class="comment">// 已经找到比当前小的了， 跳出此轮循环</span></span><br><span class="line">						<span class="keyword">break</span>;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="4、希尔排序（Shell-Sort）"><a href="#4、希尔排序（Shell-Sort）" class="headerlink" title="4、希尔排序（Shell Sort）"></a>4、希尔排序（Shell Sort）</h2><p>希尔排序，顾名思义，它是一个名叫希尔的人发明的，第一个个时间复杂的图片O(n2)排序。</p>
<p>它是插入排序的一个变种，但是它的实现相对复杂。</p>
<p>为了帮助大家理解，我们先看一下<strong>插入排序</strong>的动图。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015225645277-1151100000-2.gif"></p>
<p>大家有没有发现，每一次插入的过程，基本上都要移动好几个元素。大小相似的元素往往相隔的比较远。</p>
<p>为了优化这个过程，希尔选择了先把整个队列按照间隔分组，分别进行插入排序。</p>
<p>然后间隔原来越小，当间隔为1的时候，就是一次正常的插入排序。</p>
<p>这样在前期的准备中，大小相似的元素，相邻的都比较近了，可以提高最终排序的效率。</p>
<p>动图如下：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20180331170017421-364506073.gif"></p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 希尔排序：</span></span><br><span class="line"><span class="comment"> * 1 按照间隔分组（初始间隔一般是数组长度的一半）</span></span><br><span class="line"><span class="comment"> * 2 排序每个组（插入排序法）</span></span><br><span class="line"><span class="comment"> * 3 间隔减小，重新分组（新的间隔一般为原间隔的一般，最后为1）</span></span><br><span class="line"><span class="comment"> * 4 再排序每个组</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ShellSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="type">int</span> <span class="variable">interval</span> <span class="operator">=</span> nums.length / <span class="number">2</span>;</span><br><span class="line">			<span class="keyword">while</span> (interval &gt; <span class="number">0</span>) &#123;</span><br><span class="line">				insertSortByInterval(nums, interval);</span><br><span class="line">				interval = interval / <span class="number">2</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">insertSortByInterval</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> interval)</span> &#123;</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; interval; i++) &#123;</span><br><span class="line">				<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i + interval; j &lt; nums.length; j += interval) &#123;</span><br><span class="line">					insertSortByInterval(nums, j, interval);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">//  0  x  x  2  x  x  3  x  x  1  x  x</span></span><br><span class="line">		<span class="comment">//                    i        s</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">insertSortByInterval</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> startIndex, <span class="type">int</span> interval)</span> &#123;</span><br><span class="line">			<span class="type">int</span> <span class="variable">value</span> <span class="operator">=</span> nums[startIndex];</span><br><span class="line">			<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> startIndex - interval;</span><br><span class="line">			<span class="keyword">while</span> (i &gt;= <span class="number">0</span> &amp;&amp; nums[i] &gt; value) &#123;</span><br><span class="line">				nums[i + interval] = nums[i];</span><br><span class="line">				nums[i] = value;</span><br><span class="line">				i -= interval;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="5、归并排序（Merge-Sort）"><a href="#5、归并排序（Merge-Sort）" class="headerlink" title="5、归并排序（Merge Sort）"></a>5、归并排序（Merge Sort）</h2><p>如果你是程序员的化，归并排序也很好理解。</p>
<p>它主要采用分治的思想，使用递归。 化繁为简。</p>
<p>直接上代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 归并排序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MergeSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="keyword">return</span> mergeSort(nums);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 递归方法</span></span><br><span class="line">		<span class="keyword">private</span> <span class="type">int</span>[] mergeSort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="comment">// 递归出口</span></span><br><span class="line">			<span class="keyword">if</span> (nums.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">				<span class="keyword">return</span> nums;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 分成两个数组</span></span><br><span class="line">			<span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> nums.length / <span class="number">2</span>;</span><br><span class="line">			<span class="type">int</span>[] left = Arrays.copyOfRange(nums, <span class="number">0</span>, m);</span><br><span class="line">			<span class="type">int</span>[] right = Arrays.copyOfRange(nums, m, nums.length);</span><br><span class="line">			<span class="comment">// 对这两个数组做排序</span></span><br><span class="line">			left = mergeSort(left);</span><br><span class="line">			right = mergeSort(right);</span><br><span class="line">			<span class="comment">// 合并这两个排序好的数组</span></span><br><span class="line">			<span class="keyword">return</span> mergeSort(left, right);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 对两个排序好的数组做合并</span></span><br><span class="line">		<span class="keyword">private</span> <span class="type">int</span>[] mergeSort(<span class="type">int</span>[] left, <span class="type">int</span>[] right) &#123;</span><br><span class="line">			<span class="type">int</span> <span class="variable">length</span> <span class="operator">=</span> left.length + right.length;</span><br><span class="line">			<span class="type">int</span>[] merged = <span class="keyword">new</span> <span class="title class_">int</span>[length];</span><br><span class="line">			<span class="type">int</span> <span class="variable">leftIndex</span> <span class="operator">=</span> <span class="number">0</span>, rightIndex = <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">				<span class="keyword">if</span> (leftIndex &lt; left.length &amp;&amp; rightIndex &lt; right.length) &#123;</span><br><span class="line">					<span class="type">int</span> <span class="variable">leftValue</span> <span class="operator">=</span> left[leftIndex];</span><br><span class="line">					<span class="type">int</span> <span class="variable">rightValue</span> <span class="operator">=</span> right[rightIndex];</span><br><span class="line">					<span class="keyword">if</span> (leftValue &lt; rightValue) &#123;</span><br><span class="line">						merged[i] = leftValue;</span><br><span class="line">						leftIndex++;</span><br><span class="line">					&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">						merged[i] = rightValue;</span><br><span class="line">						rightIndex++;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125; <span class="keyword">else</span> <span class="keyword">if</span> (leftIndex &gt;= left.length) &#123;</span><br><span class="line">					merged[i] = right[rightIndex];</span><br><span class="line">					rightIndex++;</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					merged[i] = left[leftIndex];</span><br><span class="line">					leftIndex++;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> merged;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>动图如下：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015230557043-37375010.gif"></p>
<h2 id="6、快速排序（Quick-Sort）"><a href="#6、快速排序（Quick-Sort）" class="headerlink" title="6、快速排序（Quick Sort）"></a>6、快速排序（Quick Sort）</h2><p>重点！ 重点～ 重点。。。<br>快速排序非常重要‼️</p>
<p>它的思想是：设立一个基准，把小于基准的移动到左边，把大于基准的移动到右边。</p>
<p>在把左边小于基准的子队列，再设立一个基准，再移动，右边同理。</p>
<p>使用递归，直至子队列的长度小于2。</p>
<p>先来个带辅助空间的快速排序的实现，很简单，大家体会下。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用List，带辅助空间</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">		List&lt;Integer&gt; list = quickSort(</span><br><span class="line">				Arrays.stream(nums).boxed().collect(Collectors.toList()));</span><br><span class="line">		<span class="keyword">return</span> list.stream().mapToInt(i -&gt; i).toArray();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 快速排序递归方法</span></span><br><span class="line">	<span class="keyword">private</span> List&lt;Integer&gt; <span class="title function_">quickSort</span><span class="params">(List&lt;Integer&gt; list)</span> &#123;</span><br><span class="line">		<span class="comment">// 递归出口</span></span><br><span class="line">		<span class="keyword">if</span> (list.size() &lt; <span class="number">2</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> list;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 随便找一个基准，这里取的是第一个元素</span></span><br><span class="line">		<span class="type">Integer</span> <span class="variable">pivot</span> <span class="operator">=</span> list.get(<span class="number">0</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 辅助空间</span></span><br><span class="line">		List&lt;Integer&gt; low = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">		List&lt;Integer&gt; high = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">		List&lt;Integer&gt; equal = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 结果集合</span></span><br><span class="line">		List&lt;Integer&gt; sorted = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 大于基准的集合；小于基准的集合；等于基准的集合</span></span><br><span class="line">		<span class="keyword">for</span> (Integer item : list) &#123;</span><br><span class="line">			<span class="keyword">if</span> (item.equals(pivot)) &#123;</span><br><span class="line">				equal.add(item);</span><br><span class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span> (item &lt; pivot) &#123;</span><br><span class="line">				low.add(item);</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				high.add(item);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 递归</span></span><br><span class="line">		low = quickSort(low);</span><br><span class="line">		high = quickSort(high);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 合并</span></span><br><span class="line">		sorted.addAll(low);</span><br><span class="line">		sorted.addAll(equal);</span><br><span class="line">		sorted.addAll(high);</span><br><span class="line">		<span class="keyword">return</span> sorted;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>不带辅助空间的算法实现起来比较复杂，但是思想一致。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// in-place</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution2</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">		sort(nums, <span class="number">0</span>, nums.length - <span class="number">1</span>);</span><br><span class="line">		<span class="keyword">return</span> nums;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (left &gt;= right) &#123;</span><br><span class="line">			<span class="keyword">return</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="type">int</span> <span class="variable">pivotIndex</span> <span class="operator">=</span> pivotDivision(nums, left, right);</span><br><span class="line"></span><br><span class="line">		sort(nums, left, pivotIndex - <span class="number">1</span>);</span><br><span class="line">		sort(nums, pivotIndex + <span class="number">1</span>, right);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 按照基准  左右划分</span></span><br><span class="line">	<span class="comment">// 3  2  6  5  4</span></span><br><span class="line">	<span class="comment">// 3  2  4  6  5</span></span><br><span class="line">	<span class="keyword">private</span> <span class="type">int</span> <span class="title function_">pivotDivision</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">		<span class="comment">// 默认给最右边的值 为基准</span></span><br><span class="line">		<span class="type">int</span> <span class="variable">pivot</span> <span class="operator">=</span> nums[right];</span><br><span class="line">		<span class="comment">// 初始化，基准Index</span></span><br><span class="line">		<span class="type">int</span> <span class="variable">pivotIndex</span> <span class="operator">=</span> left;</span><br><span class="line">		<span class="comment">// 把子数组遍历一遍</span></span><br><span class="line">		<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> left; i &lt; right; i++) &#123;</span><br><span class="line">			<span class="comment">// 如果比 基准小  替换到前面  基准Index++</span></span><br><span class="line">			<span class="keyword">if</span> (nums[i] &lt;= pivot) &#123;</span><br><span class="line">				SortUtil.swap(nums, i, pivotIndex);</span><br><span class="line">				pivotIndex++;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 最后再把 基准放到中间来</span></span><br><span class="line">		SortUtil.swap(nums, right, pivotIndex);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> pivotIndex;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>最后我们看下动图：<br>黄色的元素是基准<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015230936371-1413523412.gif"></p>
<h2 id="7、堆排序（Heap-Sort）"><a href="#7、堆排序（Heap-Sort）" class="headerlink" title="7、堆排序（Heap Sort）"></a>7、堆排序（Heap Sort）</h2><p>堆排序，就比较不好想了，它的思路是把数组转换成二叉树。对，没错。</p>
<p>把数组当成一个二叉树。</p>
<p>然后对二叉树进行递归比较，把较大对元素放到根节点。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HeapSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 1. 把数组抽象成二叉树</span></span><br><span class="line"><span class="comment">	 * &lt;p&gt;</span></span><br><span class="line"><span class="comment">	 * 2. 每个子树做堆化操作，比较根元素和子元素，交换位置，保持根元素最大</span></span><br><span class="line"><span class="comment">	 * &lt;p&gt;</span></span><br><span class="line"><span class="comment">	 * 3. 循环，保持整棵树的根元素最大</span></span><br><span class="line"><span class="comment">	 * &lt;p&gt;</span></span><br><span class="line"><span class="comment">	 * 4. 把根元素放到最后</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 7  6  5  2  3  4  1</span></span><br><span class="line">		<span class="comment">//          7</span></span><br><span class="line">		<span class="comment">//         /  \</span></span><br><span class="line">		<span class="comment">//        5    2</span></span><br><span class="line">		<span class="comment">//       / \  /</span></span><br><span class="line">		<span class="comment">//      3  4  1</span></span><br><span class="line">		<span class="comment">//  左边叶子节点的位置 = 根节点的位置 * 2 + 1</span></span><br><span class="line">		<span class="comment">//  右边叶子节点的位置 = 根节点的位置 * 2 + 2</span></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> nums.length - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">				<span class="comment">// 堆化</span></span><br><span class="line">				heapify(nums, i);</span><br><span class="line">				<span class="comment">// 此时root已经最大，把root移动到后面</span></span><br><span class="line">				SortUtil.swap(nums, <span class="number">0</span>, i);</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 从后往前比较每一个节点</span></span><br><span class="line">		<span class="comment">// 类似一个冒泡的过程，把最大的值给冒上来</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">heapify</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> i)</span> &#123;</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i; j &gt;= <span class="number">0</span>; j--) &#123;</span><br><span class="line">				checkRootValueBeMax(nums, j, i);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 保证根节点 元素最大  左边节点，第二大   右边节点最小</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">checkRootValueBeMax</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> rootIndex, <span class="type">int</span> limit)</span> &#123;</span><br><span class="line">			<span class="type">int</span> <span class="variable">leftIndex</span> <span class="operator">=</span> rootIndex * <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">			<span class="type">int</span> <span class="variable">rightIndex</span> <span class="operator">=</span> rootIndex * <span class="number">2</span> + <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (leftIndex &lt; limit &amp;&amp; nums[leftIndex] &gt; nums[rootIndex]) &#123;</span><br><span class="line">				SortUtil.swap(nums, leftIndex, rootIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> (rightIndex &lt; limit &amp;&amp; nums[rightIndex] &gt; nums[rootIndex]) &#123;</span><br><span class="line">				SortUtil.swap(nums, rightIndex, rootIndex);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> (leftIndex &lt; nums.length &amp;&amp;</span><br><span class="line">					rightIndex &lt; nums.length &amp;&amp;</span><br><span class="line">					nums[leftIndex] &gt; nums[rightIndex]) &#123;</span><br><span class="line">				SortUtil.swap(nums, leftIndex, rightIndex);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>动图如下：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015231308699-356134237.gif"></p>
<h2 id="8、计数排序（Counting-Sort）"><a href="#8、计数排序（Counting-Sort）" class="headerlink" title="8、计数排序（Counting Sort）"></a>8、计数排序（Counting Sort）</h2><p>从这种排序算法开始，后面3种算法，就都是不依靠比较的排序算法了。</p>
<p>计数排序就是其中之一。</p>
<p>计数排序的核心，就是定义一个计数数组，记录每个数出现的次数。</p>
<p>如果有一个待排序的数组如：[ 5, 3, 3, 2, 6, 7, 8, 9, 0, 4 ]，最大值为10。</p>
<p>那么我们的计数数组填充完毕后的样子就是：[ 1, 0, 1, 2, 1, 1, 1, 1, 1, 1 ]</p>
<p>最后再通过计数数组，生成一个排好序的数组作为结果。</p>
<p>大家发现没有，这里面并没有想之前一样，元素之间两两比较大小。</p>
<p>在看下动图：<br><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015231740840-6968181.gif"></p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计数排序</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CountingSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// [ 5, 3, 3, 2, 6, 7, 8, 9, 0, 4 ]   , 10</span></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums, <span class="type">int</span> maxValue) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 定义计数数组</span></span><br><span class="line">			<span class="type">int</span>[] countingArray = <span class="keyword">new</span> <span class="title class_">int</span>[maxValue];</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 把 nums 存放到计数数组中</span></span><br><span class="line">			<span class="comment">// [ 1, 0, 1, 2, 1, 1, 1, 1, 1, 1 ]</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> value : nums) &#123;</span><br><span class="line">				<span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> countingArray[value];</span><br><span class="line">				countingArray[value] = count + <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="type">int</span> <span class="variable">numsIndex</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">			<span class="comment">// 再把计数数组中的数据 反哺到nums中</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; countingArray.length; i++) &#123;</span><br><span class="line">				<span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> countingArray[i];</span><br><span class="line">				<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; count; j++) &#123;</span><br><span class="line">					nums[numsIndex] = i;</span><br><span class="line">					numsIndex++;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="9、桶排序（Bucket-Sort）"><a href="#9、桶排序（Bucket-Sort）" class="headerlink" title="9、桶排序（Bucket Sort）"></a>9、桶排序（Bucket Sort）</h2><p>大家学过了计数排序，有没有发现一个问题，如果数组中元素的大小跨越的过大的化，所需要的计数数组的大小就越大。非常浪费空间。</p>
<p>为了优化这个问题，随之诞生的桶排序可以很好的解决这个问题。</p>
<p>它的数据结构类似与Java中的HashMap，图解如下：</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/uK7jwj.png"></p>
<p>它的思想也是定义一个数组，数组的每一个位置当成一个桶，</p>
<p>但是每一个位置里面可以有很多元素。</p>
<p>再对每一个桶进行排序。</p>
<p>最后，通过这个桶数组，生成一个排好序的数组作为结果。</p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 桶排序</span></span><br><span class="line"><span class="comment">// 1、 定义桶</span></span><br><span class="line"><span class="comment">// 2、 按桶，对数组分组</span></span><br><span class="line"><span class="comment">// 3、 对每个桶进行排序</span></span><br><span class="line"><span class="comment">// 4、 组合每个桶</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BucketSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 1、 定义桶</span></span><br><span class="line">			<span class="type">int</span> <span class="variable">maxValue</span> <span class="operator">=</span> nums[<span class="number">0</span>], minValue = nums[<span class="number">0</span>];</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> v : nums) &#123;</span><br><span class="line">				maxValue = Math.max(maxValue, v); <span class="comment">// 47</span></span><br><span class="line">				minValue = Math.min(minValue, v); <span class="comment">// 1</span></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 桶对数量（不重要，大概就行）</span></span><br><span class="line">			<span class="type">int</span> <span class="variable">bucketCount</span> <span class="operator">=</span> (<span class="type">int</span>) Math.sqrt(nums.length); <span class="comment">// 8</span></span><br><span class="line">			List&lt;Integer&gt;[] buckets = <span class="keyword">new</span> <span class="title class_">List</span>[bucketCount];</span><br><span class="line">			<span class="comment">// 2、 按桶，对数组分组</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> v : nums) &#123; <span class="comment">// v =15</span></span><br><span class="line">				<span class="comment">// 找到对应对桶，这点要注意</span></span><br><span class="line">				<span class="type">int</span> <span class="variable">bucketIndex</span> <span class="operator">=</span> v * (bucketCount - <span class="number">1</span>) / maxValue;</span><br><span class="line">				List&lt;Integer&gt; bucket = buckets[bucketIndex];</span><br><span class="line">				<span class="keyword">if</span> (bucket == <span class="literal">null</span>) &#123;</span><br><span class="line">					bucket = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">					bucket.add(v);</span><br><span class="line">					buckets[bucketIndex] = bucket;</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">					bucket.add(v);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 3、 对每个桶进行排序</span></span><br><span class="line">			<span class="keyword">for</span> (List&lt;Integer&gt; bucket : buckets) &#123;</span><br><span class="line">				Collections.sort(bucket);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 4、 组合每个桶</span></span><br><span class="line">			<span class="keyword">return</span> Arrays.stream(buckets).flatMap(Collection::stream)</span><br><span class="line">					.mapToInt(Integer::intValue).toArray();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="10、基数排序（Radix-Sort）"><a href="#10、基数排序（Radix-Sort）" class="headerlink" title="10、基数排序（Radix Sort）"></a>10、基数排序（Radix Sort）</h2><p>基数排序对于桶排序来说，也是换汤不换药。</p>
<p>同样有一个桶数组，但是这个数组的长度固定，只有10。</p>
<p>通过从低位到最高位的循环，每次循环都做一次桶排序。</p>
<p>最终就会得到一个排序好的数组。</p>
<p>这种算法占用的额外空间更小，也更可控。</p>
<p>动图如下：</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/849589-20171015232453668-1397662527.gif"></p>
<p>思想很简单。</p>
<p>请看代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 基数排序</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 取得数组中的最大数，并取得位数；</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * arr为原始数组，从最低位开始取每个位组成radix数组；</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 对radix进行计数排序（利用计数排序适用于小范围数的特点）；</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RadixSort</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="type">int</span>[] sort(<span class="type">int</span>[] nums) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">//取得数组中的最大数，并取得位数</span></span><br><span class="line">			<span class="type">int</span> <span class="variable">digit</span> <span class="operator">=</span> getBiggestDigit(nums);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// i=1表示个位； i=2表示十位 ......</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= digit; i++) &#123;</span><br><span class="line">				<span class="comment">// 每一个位置都过一下桶数组</span></span><br><span class="line">				bucket(nums, i);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">return</span> nums;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// i=1表示个位； i=2表示十位 ......</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">bucket</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> i)</span> &#123;</span><br><span class="line">			List&lt;Integer&gt;[] buckets = <span class="keyword">new</span> <span class="title class_">List</span>[<span class="number">10</span>];</span><br><span class="line">			<span class="comment">// 把数组，放置到桶中</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> n : nums) &#123;</span><br><span class="line">				<span class="comment">// 获取对应位数的数值</span></span><br><span class="line">				<span class="type">int</span> <span class="variable">pos</span> <span class="operator">=</span> getPosition(n, i);</span><br><span class="line">				List&lt;Integer&gt; list = buckets[pos];</span><br><span class="line">				<span class="keyword">if</span> (list == <span class="literal">null</span>) &#123;</span><br><span class="line">					list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">					buckets[pos] = list;</span><br><span class="line">				&#125;</span><br><span class="line">				list.add(n);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 再把桶中到数据，恢复到原数组中</span></span><br><span class="line">			<span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (List&lt;Integer&gt; bucket : buckets) &#123;</span><br><span class="line">				<span class="keyword">if</span> (CollectionUtils.isNotEmpty(bucket)) &#123;</span><br><span class="line">					<span class="keyword">for</span> (Integer v : bucket) &#123;</span><br><span class="line">						nums[index] = v;</span><br><span class="line">						index++;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 获取对应位数的数值</span></span><br><span class="line">		<span class="keyword">private</span> <span class="type">int</span> <span class="title function_">getPosition</span><span class="params">(<span class="type">int</span> n, <span class="type">int</span> digit)</span> &#123;</span><br><span class="line">			<span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> String.valueOf(n);</span><br><span class="line">			<span class="comment">// 33   2</span></span><br><span class="line">			<span class="keyword">if</span> (s.length() &lt; digit) &#123;</span><br><span class="line">				<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> Integer.parseInt(s.substring(s.length() - digit, s.length() - digit + <span class="number">1</span>));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 取得数组中的最大数，并取得位数</span></span><br><span class="line">		<span class="keyword">private</span> <span class="type">int</span> <span class="title function_">getBiggestDigit</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">			<span class="type">int</span> <span class="variable">maxDigit</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> num : nums) &#123;</span><br><span class="line">				<span class="type">int</span> <span class="variable">d</span> <span class="operator">=</span> String.valueOf(num).length();</span><br><span class="line">				maxDigit = Math.max(maxDigit, d);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> maxDigit;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，我们的十大排序算法就学习完了。</p>
<p>希望大家都有所收获。</p>
<p>其中最重要的当属 快速排序 了，两种快速排序算法，大家一定要好好掌握。</p>
<p>还有希尔排序，也比较难想，需要大家好好理解。</p>
<p>结束！！！</p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Java之Netty.md</title>
    <url>/2021/12/25/java/Java%E4%B9%8BNetty/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Netty是一套支持NIO的客户端-服务器框架。<br>高性能、高并发。<br>支持异步通信。<br>他是使用Java编写的。<br>在Java领域中，他是IO界的老大，特别是网络IO。<br>很多项目都用它，比如Dubbo，RocketMQ，Cassandra等等。</p>
<p>在这片文章中，我们会学习到：</p>
<ol>
<li>常见的IO模型</li>
<li>Netty项目</li>
<li>Netty实战</li>
<li>Netty在我司生产中的应用</li>
</ol>
<p>那我们开始吧！</p>
<span id="more"></span>

<h2 id="常见的IO模型"><a href="#常见的IO模型" class="headerlink" title="常见的IO模型"></a>常见的IO模型</h2><h3 id="BIO，阻塞IO"><a href="#BIO，阻塞IO" class="headerlink" title="BIO，阻塞IO"></a>BIO，阻塞IO</h3><blockquote>
<p>排队</p>
</blockquote>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/PGtSwc.png"></p>
<p>当一个IO请求过来，客户端进入等待，服务端处理数据，并保持阻塞（其他的客户端访问不了）。</p>
<p>等到服务端处理完数据，返回给等待中的客户端。</p>
<p>很像我们排队买鸭子的过程（没错，我在南京）。一个一个来。</p>
<p>他的优点是，模型很简单，容易实现，且不容易出问题。<br>确定也很明显，在客户多了的时候，体验会很不好。</p>
<h3 id="NIO，非阻塞IO"><a href="#NIO，非阻塞IO" class="headerlink" title="NIO，非阻塞IO"></a>NIO，非阻塞IO</h3><blockquote>
<p>轮询</p>
</blockquote>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/F7rzu9.png"></p>
<p>客户端在执行了IO请求之后，会立刻返回结果，要不返回结果，要不还需等待。<br>如果还需要等待的话，客户会发起轮询，不断的请求服务端，直到返回结果。</p>
<p>比如我去买一个手抓饼，我下单了之后，需要等待，并且过一段时间，我会问一下老板，<br>我的手抓饼好了没，如果没有，再过一段时间，再问下老板，我的手抓饼好了没。<br>直到老板把手抓饼给我。</p>
<p>他的优势是它不会再阻塞了，不用排队等在那里。我可以干一些别的事情。</p>
<p>缺点也是有的，我需要不断的询问，这样也很消耗性能。<br>而且如果我需要的结果（手抓饼）已经准备好，但是我没有及时询问，<br>这种情况，客户端拿到数据的时间会晚于真实的数据时间。</p>
<h3 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h3><blockquote>
<p>事件处理</p>
</blockquote>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/BqbARO.png"></p>
<p>IO多路复用，它是接受各种事件（比如连接、读取或写入、错误发生等)。<br>接受到各种事件消息后，记录下来，并返回一个描述符。</p>
<p>等到数据准备完成，再根据描述符找到是哪个客户端，并通知客户端来取数据。</p>
<p>打个比方，就像我们排队买奶茶，下单之后，拿到一个号码。<br>等到奶茶做好来之后，奶茶店会叫号，让我们去取奶茶。</p>
<p>它的优点是可以释放客户端，不需要阻塞。<br>因为仅仅是接受事件，一个线程就够了，不要很多线程来处理请求。</p>
<p>像Redis，Nginx都是使用的IO多路复用模型。</p>
<h3 id="AIO、异步IO模型"><a href="#AIO、异步IO模型" class="headerlink" title="AIO、异步IO模型"></a>AIO、异步IO模型</h3><blockquote>
<p>回调</p>
</blockquote>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/FZRyq2.png"></p>
<p>这种IO模型很像JS中的AJAX，发起一个请求之后，继续往下之后后续逻辑。<br>等到数据返回之后，走到回调方法，并发数据结果带过来。</p>
<p>这种就像点外卖，下单之后，等到外卖准备好，直接把外卖送到家。</p>
<p>优点就是，非常高效，客户端有着最佳的性能。<br>缺点就是，模型结构复杂，不是所有操作系统都能支持。</p>
<h2 id="Netty项目结构"><a href="#Netty项目结构" class="headerlink" title="Netty项目结构"></a>Netty项目结构</h2><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/7qmm3O.png"></p>
<p>Netty是一个大而全的IO框架，它支持各种各样的协议。<br>对各种IO模型都有封装。<br>更友好的操作API。<br>更高效的性能。</p>
<p>接下来，我们自己看一下它。</p>
<h3 id="Netty-IO-模型"><a href="#Netty-IO-模型" class="headerlink" title="Netty IO 模型"></a>Netty IO 模型</h3><p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/CqK8RW.png"></p>
<p>Netty使用的是反应模型的一种，有主线程组和工作线程组。<br>主线程组负责处理各种连接，并分发任务给工作线程组。<br>工作线程组就负责处理各种输入输出请求。并执行定义好的pipeline。</p>
<h3 id="三大核心"><a href="#三大核心" class="headerlink" title="三大核心"></a>三大核心</h3><h4 id="1、ChannelBuffer-缓冲区"><a href="#1、ChannelBuffer-缓冲区" class="headerlink" title="1、ChannelBuffer 缓冲区"></a>1、ChannelBuffer 缓冲区</h4><p>可以自定义的，多类型，API友好的缓冲区类型。</p>
<p>我们在使用IO的时候，都会使用到buffer，为解决速率不一致。<br>但是在操作系统层面和Java原生层面，只提供了ByteBuffer。字节缓冲区。<br>非常的单一，而且操作起来很不方便。</p>
<p>在Netty中，对缓冲区有了更好的封装。自动的装包和拆包。</p>
<p>而且ChannelBuffer支持zero-copy，这里的零拷贝，不是操作系统的零拷贝。<br>它的原理是在用户模式直接维护一个内核模式的buffer地址，直接进行操作。<br>不需要再进行内核模式切换，把buffer拷贝到用户模式里面来。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/lkHtRv.png"></p>
<h4 id="2、通用API"><a href="#2、通用API" class="headerlink" title="2、通用API"></a>2、通用API</h4><p>对BIO和NIO的通用抽象。<br>支持不同的通讯协议（TCP&#x2F;UDP）</p>
<p>如果我们使用Java原生的IO&#x2F;NIO接口编写，<br>会相当复杂繁琐。</p>
<p>更糟糕的是，如果我们需要把系统从BIO升级到NIO，<br>基本上需要重新开发一边</p>
<p>而如果我们一开始使用Netty开发，<br>IO模型、通讯协议都可以的切换得更加顺滑</p>
<h4 id="3、事件模型"><a href="#3、事件模型" class="headerlink" title="3、事件模型"></a>3、事件模型</h4><blockquote>
<p>基于拦截器链模式的事件模型</p>
</blockquote>
<p>Netty使用pipeline，实现了一个结构清晰得事件模型。</p>
<p>每当一个Channel被创建的时候，就会同时创建一个ChannelPipeline，<br>并永久的绑定到这个Channel上。</p>
<p>一个Event事件被加入到，触发一个pipeline，其中很多的Handler执行操作。</p>
<p>我们还可以实现自己的Handler来处理自己的业务逻辑。<br>而不会破坏代码。</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/HgrHQm.png"></p>
<p>而对于我们开发Netty应用，我们只需要配置好Netty，<br>然后写好自己的业务逻辑Handler，并加入到Pipeline中。<br>其他的交给Netty就好了，非常的方便。</p>
<h3 id="传输服务"><a href="#传输服务" class="headerlink" title="传输服务"></a>传输服务</h3><blockquote>
<p>处理基于流的传输</p>
</blockquote>
<p>在基于TCP&#x2F;IP的基于流的协议中，数据包都是基于字节流的。<br>所以在一个数据包中，可能不是一个完整的我们需要的数据包。</p>
<p>所以在数据包的处理上，就会有很多繁琐的工作内容。<br>拆包、装包</p>
<p>所以Netty提供了一个可以扩展的类<code>ByteToMessageDecoder</code><br>里面提供很多开箱即用的编码、解码器。<br>初次之外，我们还可以编写自己的定制编码、解码器。</p>
<p>在TCP的世界中，所有的数据传输都是基于字节流的。<br>但是Netty提供了一种封装，<br>可以同时解决粘包、拆包的问题，还可以给转换成POJO对象。<br>这样解码器直接解出来的就是一个Java对象。更优雅。</p>
<h3 id="协议支持"><a href="#协议支持" class="headerlink" title="协议支持"></a>协议支持</h3><p>Netty实现了各种高级的传输协议。<br>比如：HTTP、SSL、WebSockets等等。<br>我们甚至可以编写自己的协议。</p>
<h2 id="Netty实战"><a href="#Netty实战" class="headerlink" title="Netty实战"></a>Netty实战</h2><p>接下来  我们简单写一个Netty的服务端和客户端的demo。<br>我们使用SpringBoot来快速架构项目。<br>使用Gradle构建<br>这里是使用的是Netty 4.1.77，比较稳定的版本。</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    implementation <span class="attr">group:</span> <span class="string">&#x27;io.netty&#x27;</span>, <span class="attr">name:</span> <span class="string">&#x27;netty-all&#x27;</span>, <span class="attr">version:</span> <span class="string">&#x27;4.1.77.Final&#x27;</span></span><br><span class="line">    compileOnly <span class="attr">group:</span> <span class="string">&#x27;org.projectlombok&#x27;</span>, <span class="attr">name:</span> <span class="string">&#x27;lombok&#x27;</span>, <span class="attr">version:</span> <span class="string">&#x27;1.18.24&#x27;</span></span><br><span class="line">    annotationProcessor <span class="string">&#x27;org.projectlombok:lombok:1.18.24&#x27;</span></span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter&#x27;</span></span><br><span class="line">    testImplementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-test&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><p>我们写一个Netty服务，主要是以下几步：</p>
<ol>
<li>构建一个启动器</li>
<li>创建EventLoopGroup</li>
<li>构建ChildHandlers和Pipeline</li>
<li>编写自己的业务Handler并加入Pipeline</li>
<li>启动器绑定端口</li>
</ol>
<p>具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.easychat.server.server;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io.netty.bootstrap.ServerBootstrap;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.Channel;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelFuture;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelHandler;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelHandlerContext;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelInitializer;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelOption;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelPipeline;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.SimpleChannelInboundHandler;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.nio.NioEventLoopGroup;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.socket.nio.NioServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.HttpObjectAggregator;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.HttpServerCodec;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.websocketx.TextWebSocketFrame;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.stream.ChunkedWriteHandler;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ws://localhost:8080/chat</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebSocketServer</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> NioEventLoopGroup boss;</span><br><span class="line">	<span class="keyword">private</span> NioEventLoopGroup workers;</span><br><span class="line">	<span class="keyword">private</span> ServerBootstrap serverBootstrap;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.init();</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			<span class="type">ChannelFuture</span> <span class="variable">future</span> <span class="operator">=</span> serverBootstrap.bind(<span class="number">8080</span>);</span><br><span class="line">			log.info(<span class="string">&quot;server start success.&quot;</span>);</span><br><span class="line">			future.channel().closeFuture().sync();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">			log.error(e.getMessage(), e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="comment">// 配置启动器</span></span><br><span class="line">		serverBootstrap = <span class="keyword">new</span> <span class="title class_">ServerBootstrap</span>();</span><br><span class="line">		serverBootstrap.option(ChannelOption.SO_KEEPALIVE, <span class="literal">true</span>);</span><br><span class="line">		serverBootstrap.option(ChannelOption.TCP_NODELAY, <span class="literal">true</span>);</span><br><span class="line">		serverBootstrap.option(ChannelOption.SO_BACKLOG, <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">		boss = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>();</span><br><span class="line">		workers = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>(<span class="number">7</span>);</span><br><span class="line"></span><br><span class="line">		serverBootstrap.group(boss, workers)</span><br><span class="line">				.channel(NioServerSocketChannel.class)</span><br><span class="line">				.childHandler(getChildHandlers());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> ChannelHandler <span class="title function_">getChildHandlers</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ChannelInitializer</span>&lt;&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">initChannel</span><span class="params">(Channel ch)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">				<span class="type">ChannelPipeline</span> <span class="variable">pipeline</span> <span class="operator">=</span> ch.pipeline();</span><br><span class="line">				pipeline.addLast(<span class="keyword">new</span> <span class="title class_">HttpServerCodec</span>());<span class="comment">// http协议的编解码器</span></span><br><span class="line">				pipeline.addLast(<span class="keyword">new</span> <span class="title class_">ChunkedWriteHandler</span>());<span class="comment">// 大数据流支持， 切成小块传输</span></span><br><span class="line">				pipeline.addLast(<span class="keyword">new</span> <span class="title class_">HttpObjectAggregator</span>(<span class="number">64</span>*<span class="number">1024</span>));<span class="comment">// 聚合器，对应上面的切块</span></span><br><span class="line">				pipeline.addLast(<span class="keyword">new</span> <span class="title class_">WebSocketServerProtocolHandler</span>(<span class="string">&quot;/chat&quot;</span>));<span class="comment">// 握手 心跳处理</span></span><br><span class="line">				pipeline.addLast(<span class="keyword">new</span> <span class="title class_">MyWebSocketHandler</span>());<span class="comment">// 我的业务处理Handler</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 我的业务处理逻辑</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyWebSocketHandler</span> <span class="keyword">extends</span> <span class="title class_">SimpleChannelInboundHandler</span>&lt;Object&gt; &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 上线</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handlerAdded</span><span class="params">(ChannelHandlerContext ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">			log.info(<span class="string">&quot;⬆ new connection from &#123;&#125;&quot;</span>, ctx.channel().remoteAddress());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 下线</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handlerRemoved</span><span class="params">(ChannelHandlerContext ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">			log.info(<span class="string">&quot; ⬇️️ up connection close from &#123;&#125;&quot;</span>, ctx.channel().remoteAddress());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 读取消息，并返回</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">channelRead0</span><span class="params">(ChannelHandlerContext ctx, Object msg)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">			log.info(<span class="string">&quot; 🆕 New Message: &#123;&#125;, from &#123;&#125;&quot;</span>, msg, ctx.channel().remoteAddress());</span><br><span class="line">			<span class="keyword">if</span> (! (msg <span class="keyword">instanceof</span> TextWebSocketFrame)) &#123;</span><br><span class="line">				log.error(<span class="string">&quot;message is not text, &#123;&#125;&quot;</span>, msg);</span><br><span class="line">				<span class="keyword">return</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="type">TextWebSocketFrame</span> <span class="variable">request</span> <span class="operator">=</span> (TextWebSocketFrame) msg;</span><br><span class="line">			log.info(<span class="string">&quot;received text message : &#123;&#125;&quot;</span>, request);</span><br><span class="line"></span><br><span class="line">			ctx.writeAndFlush(<span class="keyword">new</span> <span class="title class_">TextWebSocketFrame</span>(<span class="string">&quot;server send :&quot;</span> + request.text()));</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>编写完成之后，我们可以启动服务器，<br>并使用在线Websocket工具调用测试一下</p>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>客户端的编写和服务端类似，<br>但是有些地方不一样。<br>需要服务端主动发起连接。</p>
<p>具体步骤如下：</p>
<ol>
<li>构建一个启动器</li>
<li>创建EventLoopGroup</li>
<li>构建ChildHandlers和Pipeline</li>
<li>在业务Handler中，需要添加发起握手操作</li>
<li>启动器发起连接</li>
</ol>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.client.client;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> io.netty.bootstrap.Bootstrap;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.Channel;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelHandler;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelHandlerContext;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelInitializer;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelOption;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelPipeline;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.ChannelPromise;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.EventLoopGroup;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.SimpleChannelInboundHandler;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.nio.NioEventLoopGroup;</span><br><span class="line"><span class="keyword">import</span> io.netty.channel.socket.nio.NioSocketChannel;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.FullHttpResponse;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.HttpClientCodec;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.HttpObjectAggregator;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.websocketx.TextWebSocketFrame;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.websocketx.WebSocketClientHandshaker;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.websocketx.WebSocketClientHandshakerFactory;</span><br><span class="line"><span class="keyword">import</span> io.netty.handler.codec.http.websocketx.WebSocketVersion;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebsocketClient</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> URI uri;</span><br><span class="line">	<span class="keyword">private</span> Bootstrap bootstrap;</span><br><span class="line">	<span class="keyword">private</span> EventLoopGroup eventLoopGroup;</span><br><span class="line">	<span class="keyword">private</span> ChannelPromise channelPromise;</span><br><span class="line">	<span class="keyword">private</span> Channel channel;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">WebsocketClient</span><span class="params">(URI uri)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.uri = uri;</span><br><span class="line">		<span class="built_in">this</span>.init();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">connect</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			channel = bootstrap.connect(uri.getHost(), uri.getPort()).sync().channel();</span><br><span class="line">			channelPromise.sync();</span><br><span class="line">			log.info(<span class="string">&quot;connect success and handshake complete.&quot;</span>);</span><br><span class="line">		&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">			log.error(<span class="string">&quot;connect error, &quot;</span> + e.getMessage(), e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">		bootstrap = <span class="keyword">new</span> <span class="title class_">Bootstrap</span>();</span><br><span class="line">		bootstrap.option(ChannelOption.SO_KEEPALIVE, <span class="literal">true</span>);</span><br><span class="line">		bootstrap.option(ChannelOption.TCP_NODELAY, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">		eventLoopGroup = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>();</span><br><span class="line"></span><br><span class="line">		bootstrap.group(eventLoopGroup)</span><br><span class="line">				.channel(NioSocketChannel.class)</span><br><span class="line">				.handler(getHandlers());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> ChannelHandler <span class="title function_">getHandlers</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ChannelInitializer</span>&lt;&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">initChannel</span><span class="params">(Channel ch)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">				<span class="type">ChannelPipeline</span> <span class="variable">channelPipeline</span> <span class="operator">=</span> ch.pipeline();</span><br><span class="line">				channelPipeline.addLast(<span class="keyword">new</span> <span class="title class_">HttpClientCodec</span>());</span><br><span class="line">				channelPipeline.addLast(<span class="keyword">new</span> <span class="title class_">HttpObjectAggregator</span>(<span class="number">1048576</span>));</span><br><span class="line">				channelPipeline.addLast(<span class="keyword">new</span> <span class="title class_">MyWebSocketHandler</span>(getHandShaker(uri)));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">private</span> WebSocketClientHandshaker <span class="title function_">getHandShaker</span><span class="params">(URI uri)</span> &#123;</span><br><span class="line">				<span class="keyword">return</span> WebSocketClientHandshakerFactory</span><br><span class="line">						.newHandshaker(uri, WebSocketVersion.V13, <span class="literal">null</span>, <span class="literal">false</span>, <span class="literal">null</span>);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyWebSocketHandler</span> <span class="keyword">extends</span> <span class="title class_">SimpleChannelInboundHandler</span>&lt;Object&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">final</span> WebSocketClientHandshaker handShaker;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">public</span> <span class="title function_">MyWebSocketHandler</span><span class="params">(WebSocketClientHandshaker handShaker)</span> &#123;</span><br><span class="line">			<span class="built_in">this</span>.handShaker = handShaker;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handlerAdded</span><span class="params">(ChannelHandlerContext ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">			channelPromise = ctx.newPromise();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">channelActive</span><span class="params">(ChannelHandlerContext ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">			log.info(<span class="string">&quot;handshake to : &#123;&#125;&quot;</span>, ctx.channel().remoteAddress());</span><br><span class="line">			<span class="built_in">this</span>.handShaker.handshake(ctx.channel());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">channelRead0</span><span class="params">(ChannelHandlerContext ctx, Object msg)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">			log.info(<span class="string">&quot;receive data &#123;&#125; from &#123;&#125;&quot;</span>, msg, ctx.channel().remoteAddress());</span><br><span class="line">			<span class="keyword">if</span> (handShaker.isHandshakeComplete()) &#123;</span><br><span class="line">				finishHandShaker(ctx, msg);</span><br><span class="line">				<span class="keyword">return</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// handle business data</span></span><br><span class="line">			<span class="keyword">if</span> (!(msg <span class="keyword">instanceof</span> TextWebSocketFrame)) &#123;</span><br><span class="line">				log.warn(<span class="string">&quot;&#123;&#125; is not a text message.&quot;</span>, msg);</span><br><span class="line">				<span class="keyword">return</span>;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="type">TextWebSocketFrame</span> <span class="variable">textMsg</span> <span class="operator">=</span> (TextWebSocketFrame) msg;</span><br><span class="line">			log.info(<span class="string">&quot;client receive a message: &#123;&#125;&quot;</span>, textMsg.text());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">finishHandShaker</span><span class="params">(ChannelHandlerContext ctx, Object msg)</span> &#123;</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				handShaker.finishHandshake(ctx.channel(), (FullHttpResponse) msg);</span><br><span class="line">				channelPromise.setSuccess();</span><br><span class="line">				log.info(<span class="string">&quot;handShake success.&quot;</span>);</span><br><span class="line">			&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">				log.error(e.getMessage(), e);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>完整代码请点击<a href="https://github.com/CPyeah/easy-chat">这里</a></p>
<h2 id="Netty在开放平台中的应用"><a href="#Netty在开放平台中的应用" class="headerlink" title="Netty在开放平台中的应用"></a>Netty在开放平台中的应用</h2><p>在我们的开放平台中，我们需要通过Websocket对客户端推送一下消息。<br>所以我们使用Netty搭建了一个Webscoket服务器。</p>
<p>具体搭建步骤跟上面差不多。</p>
<p>但是对于生产环境，权限的校验很重要。</p>
<p>所以在每一个链接建立之后，客户端会发起登录操作。<br>如果登录成功，服务端会把客户端的信息保存下来，维持会话。</p>
<p>在正常的业务逻辑中，我们首先监听业务中台的MQ消息。<br>如果消息有对应的客户端在线，我们把消息内容，<br>封装成<code>Message</code>对象，推送给客户端。</p>
<p>然后客户端接受到消息之后，会发起一个消息确认，以保证消息顺利被接收。</p>
<p>流程如下：</p>
<p><img src="https://cp-images.oss-cn-hangzhou.aliyuncs.com/5cnd8k.png"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>至此，我们学习了Netty的相关知识。并实操练习了一下。<br>我们知道了Netty是Java世界中最重要的NIO框架。<br>它对java.nio的封装，它的事件，反应模型都对我们开发NIO服务器非常有用。<br>它的多路复用的模型也非常重要。</p>
<p>我们还一起搭建了一个简单的Netty服务，<br>并使用Netty编写了一个简单的Netty客户端。<br>帮助大家上手入门。</p>
<p>还有我司在生产环境中是如何使用Netty搭建一个开放平台的消息推送系统的。<br>供大家参考。</p>
<p>希望这片文章能让大家有所收获！</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://netty.io/">https://netty.io/</a></li>
<li><a href="http://www.kegel.com/c10k.html">http://www.kegel.com/c10k.html</a></li>
<li><a href="https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf</a></li>
<li><a href="https://github.com/netty/netty">https://github.com/netty/netty</a></li>
<li><a href="https://github.com/netty/netty/wiki/User-guide-for-4.x">https://github.com/netty/netty/wiki/User-guide-for-4.x</a></li>
<li><a href="https://netty.io/3.8/guide/#architecture">https://netty.io/3.8/guide/#architecture</a></li>
<li><a href="https://www.youtube.com/watch?v=I8yy2Cy7dDI">https://www.youtube.com/watch?v=I8yy2Cy7dDI</a></li>
<li><a href="https://alibaba-cloud.medium.com/essential-technologies-for-java-developers-i-o-and-netty-ec765676fd21">https://alibaba-cloud.medium.com/essential-technologies-for-java-developers-i-o-and-netty-ec765676fd21</a></li>
<li><a href="https://liakh-aliaksandr.medium.com/java-sockets-i-o-blocking-non-blocking-and-asynchronous-fb7f066e4ede">https://liakh-aliaksandr.medium.com/java-sockets-i-o-blocking-non-blocking-and-asynchronous-fb7f066e4ede</a></li>
</ul>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>netty</tag>
      </tags>
  </entry>
</search>
